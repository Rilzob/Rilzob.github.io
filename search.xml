<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[跟我一起写Makefile读书笔记(一)]]></title>
    <url>%2F2019%2F03%2F28%2F%E8%B7%9F%E6%88%91%E4%B8%80%E8%B5%B7%E5%86%99Makefile%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[第一部分 概述第二部分 关于程序的编译和链接第三部分 Makefile介绍第四部分 Makefile总述第五部分 书写规则 概述 Makefile文件定义了一些列的规则来指定，一个工程中哪些源文件需要先编译，哪些文件需要后编译，哪些文件需要重新编译，甚至与进行更复杂的功能操作。 Makefile像Shell脚本一样，”自动化编译”整个工程，其中也可以执行操作系统的命令。 Make是一个解释makefile中指令的命令工具。 关于程序的编译和链接 一般来说，无论是C、C++，首先要把源文件编译成中间代码文件，在Windos下是.obj文件，UNIX下是.o文件，即ObjectFile，这个动作叫编译(compile)。然后再把大量的Object File合成执行文件，这个动作叫做链接(link)。 编译时，编译器只检查程序语法，和函数、变量是否被声明。如果未被声明，编译器则会给出一个warning，但可以生成Object File。链接程序时，主要是链接函数和全局变量，链接器只会在Object File中找寻函数的实现，而并不管函数所在的源文件，如果找不到就会报链接错误码(Linker Error)，意思是链接器未能找到函数的实现，你需要指定函数的Object File。 大多数时候，由于源文件太多，编译生成的中间目标文件太多，而在链接时需要明显地指出中间目标文件名，这对于编译很不方便，所以要给中间目标文件打包，在Windows下这种包叫”库文件”(Library File)，也就是.lib文件，在UNIX下，是Archive File，也就是.a文件。 Makefile介绍 make命令执行时，需要一个Makefile文件，以告诉make命令需要怎么样的去编译和链接程序。 Makefile的规则1234target ... : prerequistes ...command...... target就是一个目标文件，可以是ObjectFile，也可以是执行文件。还可以是一个标签(Label)，对于标签这种特性，在后序的”伪指标”章节中会有叙述。 prerequistes就是要生成那个target所需要的文件或是目标。 command就是make需要执行的命令(任意的Shell命令)。 这是一个文件的依赖关系，也就是说，target这一个或多个的目标文件依赖于prerequisites中的文件，其生成规则定义在command中。说白一点就是说，prerequisites中如果有一个以上的文件比target文件要新的话，command所定义的命令就会被执行。这就是Makefile的规则。也就是Makefile中最核心的内容。 一个示例 假设一个工程有3个头文件，和8个C文件，并假定有3个规则： 如果这个工程没有编译过，那么所有C文件都要编译并被链接。 如果这个工程的某几个C文件被修改，那么只编译被修改的C文件，并链接目标程序。 如果这个工程的头文件被修改了，那么需要编译引用这些头文件的C文件，并链接目标程序。 基于上述条件和规则编写Makefile文件来高速make命令如何编译和链接这些文件。12345678910111213141516171819202122edit : main.o kbd.o command.o display.o \insert.o search.o files.o utils.occ -o edit main.o kbd.o command.o display.o \insert.o search.o files.o utils.omain.o : main.c defs.hcc -c main.ckbd.o : kbd.c defs.h command.hcc -c command.cdisplay.o : display.c defs.h buffer.hcc -c display.cinsert.o : insert.c defs.h buffer.hcc -c insert.csearch.o : search.c defs.h buffer.hcc -c search.cfiles.o : files.c defs.h buffer.h command.hcc -c files.cutils.o : utils.c defs.hcc -c utils.cclean:rm edit main.o kbd.o command.o display.o \insert.o search.o files.o utils.o 反斜杠(\)代表换行。 将上述代码保存在名为”makefile”或”Makefile”的文件中，然后再该目录下直接输入命令make就可以生成执行文件edit。执行make clean可以删除执行文件和所有的中间目标文件。 在这个makefile中，目标文件（target）包含:执行文件edit和中间目标文件（*.o），依赖文件（prerequisites）就是冒号后面的那些.c文件和.h文件。每一个.o文件都有一组以来文件，而这些.o文件又是执行文件edit的依赖文件。依赖关系的实质上就是说明了目标文件是由哪些文件生成的，换言之，目标文件是哪些文件更新的。 在定义好依赖关系后，后续的那一行定义了如何生成目标文件的操作系统指令，一定要以Tab键作为开头。make不管命令是怎么工作的，它只管执行所定义的命令。make会比较targets文件和prerequisites文件的修改日期，如果prerequisites文件的日期要比targets文件的日期要新，或者target不存在的话，那么make就会执行后续定义的命令。 特别说明clean并不是一个文件，它只不过是一个动作名字，类似C语言中的label，冒号后面什么也没有，那么，make就不会自动去找文件的依赖性，也就是不会自动执行其后所定义的命令。要执行其后的命令，就要在make命令后明显的指出这个label的名字，这里就是make clean。这样的方法可以让我们在一个makefile中定义不用的编译或是和编译无关的命令，比如程序的打包，程序的备份等等。 make是如何工作的 默认方式下make的工作流程(即只输入make命令)： make会在当前目录下寻找名字为”Makefile”或”makefile”的文件。 若找到，它会找文件中的第一个目标文件(target)，并把这个文件作为最终的目标文件。上例中是”edit”这个文件。 若edit文件不存在，或是edit所依赖的后面的.o文件的文件修改时间比edit文件新，那么它就会执行后面所定义的命令来生成edit文件。 若edit文件所依赖的.o文件也不存在，那么make会在当前文件中寻找目标为.o文件的文件(即.o文件所依赖的文件)，如果找到则再根据那一个规则生成.o文件(有点像堆栈的过程)。 由于源文件C文件和H文件是存在的，于是make会生成.o文件，然后再利用.o文件生成执行文件edit即最终的目标文件。 这就是整个make的依赖性，make会一层又一层地找文件的依赖关系，直到最终编译出第一个目标文件。在找寻的过程中，如果出现错误，比如最后被依赖的文件找不到，那么make就会直接退出并报错，而对于所定义的命令的错误，或是编译不成功，make根本不理，make只管文件的依赖性，即make只负责找到依赖关系，冒号后面的文件若不存在则直接停止工作。因此像clean这种没有被第一个目标文件或间接关联的，它后面所定义的命令将不会被自动执行，但若希望make执行则使用命令make clean(指令形式:make label)。 在上例中若整个工程已经被编译过了，当其中一个源文件被修改了，例如file.c，那么根据依赖性可知file.o文件会被重新编译（也就是在这个依赖关系后面所定义的命令），又因为此时file.o修改时间比edit新，所以edit文件也会被重新链接（详见edit目标文件后定义的命令)。 makefile中使用变量 为了保证makefile的易维护，在makefile中可以使用变量。比如工程中需要加入新的.o文件，若不使用变量则需要在多处进行修改并有可能出现错误。 makefile中的变量是一个字符串，可以理解成C语言中的宏。 声明一个变量叫objects12objects = main.o kbd.o command.o display.o \insert.o search.o files.o utils.o 之后在makefile中以$(objects)的方式使用这个变量，改良后的makefile文件如下：12345678910111213141516171819202122objects = main.o kbd.o command.o display.o \insert.o search.o files.o utils.oedit: $(objects)cc -o edit $(objects)main.o : main.c defs.hcc -c main.ckbd.o : kbd.c defs.hcommand.hcc -c kbd.ccommand.o : command.c defs.h command.hcc -c command.cdisplay.o : display.c defs.h buffer.hcc -c display.cinsert.o : insert.c defs.h buffer.hcc -c insert.csearch.o : search.c defs.h buffer.hcc -c files.cutils.o : utils.c defs.hcc -c utils.cclean: rm edit $(objects) 如果有新的.o文件加入，只需简单地修改objects变量即可。 让make自动推导 GNU的make可以自动推导文件以及文件依赖关系后面的命令，因此每个.o文件后不需要再写上类似的命令。 只要make看到一个.o文件，它就会自动的把.c文件加在依赖关系中。于是再修改makefile文件如下。123456789101112131415161718objects = main.o kbd.o command.o display.o \insert.o search.o files.o utils.oedit: $(objects)cc -o edit $(objects)main.o : defs.hkbd.o : defs.h command.hcommand.o : defs.h command.hdisplay.o : defs.h buffer.hinsert.o : defs.h buffer.hsearch.o : defs.h buffer.hfiles.o : defs.h buffer.h command.h utils.o : defs.h.PHONY : cleanclean :rm edit $(objects) 这种方法，就是make的”隐晦规则”。.PHONY用来在文件内容中表示clean是个伪目标文件。 另类风格的makefile makefile文件可以通过将重复的.h和.o文件收拢起来做到更进一步的简化。12345678910111213objects = main.o kbd.o command.o display.o \insert.o search.o files.o utils.oedit : $(objects)cc -o edit $(objects)$(objects) : defs.hkbd.o command.o files.o : command.hdisplay.o insert.o search.o files.o : buffer.h.PHONY : cleanclean :rm edit $(objects) 对比之前的makefile文件很容易发现这种风格的makefile文件的书写规则。此书的作者并不喜欢这种风格，他认为之后可能会有两个问题：一是文件的依赖关系看不清楚；二是如果文件一多，要加入几个新的.o文件很难理清楚。 清空目标文件的规则 每个makefile中都需要写一个清空目标文件(.o和执行文件)的规则。这不仅便于重编译，还有利于保持文件的清洁。一般的风格：12clean :rm edit $(objects) 更稳稳健的做法是:123.PHONY : cleanclean :-rm edit $(objects) .PHONY表示clean是一个”伪目标”。在rm命令前面加上一个-(小减号)的意思是，也许某些文件出现问题，但不要管，继续做后面的事情。 clean的规则不要放在文件的开头，不然会变成make的默认目标。不成文的规矩是”clean从来都是放在文件的最后”。 Makefile 总述Makefile里有什么？ Makefile里主要包含了五个东西：显式规则、隐晦规则、变量定义、文件指示和注释。 显式规则 显式规则说明，如何生成一个或多个的目标文件。这是由Makefile的书写者明显指出，要生成的文件，文件的依赖文件，生成的命令。(Makefile文件的主体) 隐晦规则 因为make具有自动推导的规则，所以隐晦的规则可以让我们比较粗糙地简略地书写Makefile，这是由make所支持的。 变量的定义 在Makefile中定义的变量，一般都是字符串，类似C语言中的宏，当Makefile被执行时，其中的变量都会被扩展到相应的引用位置上。 文件指示 包括了三个部分，一个是在一个Makefile中引用另一个Makefile，类似C语言中的include；另一个是根据某些情况指定Makefile中的有效部分，类似C语言中的预编译#if；还有一个就是定义一个多行的命令。文件指示部分后面后更详细的介绍。 注释 Makefile中只有行注释，和UNIX的Shell脚本一样，其注释是用”#”字符，与Python语言的注释符号相同。如果在Makefile中使用”#”字符，可以用反斜杠进行转移”#“。 特别注意，Makefile中的命令必须要以[Tab]键开始 Makefile的文件名 默认情况下，make指令会在当前目录下按顺序寻找文件名为”GNUmakefile”、”makefile”、”Makefile”的文件，解释这个名字。作者建议最好使用”Makefile”这个文件名。最好不要使用”GNUmakerfile”，这个文件是GNU的make识别的。有些make只对全小写的”makefile”文件名敏感，但是基本上来说，大多数的make都支持”makefile”和”Makefile”这两种默认文件名。 此外还可以使用别的文件名来书写Makefile，比如:”Make.Linux”，”Make.Solaris”，”Make.AIX”等。如果要指定特定的Makefile，可以使用make的-f和--file参数，如：make -f Make.Linux或make --file Make.AIX。 引用其它的Makefile 在Makefile使用include关键字可以把别的Makefile包含金来，类似C语言的#include，被包含的文件会原模原样的放在当前文件的包含位置。 include的语法是：include &lt;filename&gt; filename可以是当前操作系统Shell的文件模式(可以包含路径和通配符)在include前面可以有一些空字符，但是绝不能是[Tab]键开始。include和&lt;filename&gt;可以用一个或多个空格隔开。 举例有一些Makefile：a.mk、b.mk、c.mk和foo.make，以及一个变量$(bar)，其中包含了e.mk和f.mk，那么include foo.make *.mk $(bar)等价于include foo.make a.mk b.mk c.mk e.mk f.mk make指令开始时会首先寻找include所指出的其它Makefile，并把其内容安置在对应位置，如果文件中没有指定其这些Makefile文件的绝对路径或是相对路径，make会在当前目录下首先寻找，如果当前目录下没有找到，那么make还会在下面几个目录下找： 如果make执行时有-I或--include-dir参数，那么make就会在这个参数所指定的目录下去寻找。 如果目录\/include(一般是：/usr/local/bin或/usr/include)存在的话，make也会去找。如果有文件没有找到，make会生成一条警告信息，但不会马上出现致命错误。它会继续载入其它的文件，一旦完成Makefile的读取，make会再重试这些没有找到，或是不能读取的文件，如果还是不行，make才会出现一条致命信息。可以通过在include前加一个减号”-“让make不理会那些无法读取的文件而继续执行。如：-include &lt;filename&gt;其表示无论include过程中出现什么错误，都不要报错继续执行。和其它版本make兼容的相关命令是sinclude，其作用和-include是一样的。 环境变量 MAKEFILES 如果在当前环境中定义了环境变量MAKEFILES，那么make会把这个变量中的值当作一个类似include的动作。这个动作中的值是其它的Makefile用空格分隔。只是，它和include不同的是，从这个环境变量中引入的Makefile的”目标”不会起作用，如果环境变量中定义的文件发现错误，make也不会理会。 作者建议不使用这个环境变量，因为只要这个环境变量一旦被定义，那么使用make时所有的Makefile都会受到它的影响。如果Makefile出现了怪事，可以查看当前环境中是不是定义这个变量。 make的工作方式 GNU的make工作时的执行步骤如下： 读入所有的Makefile； 读入被include的其它Makefile； 初始化文件中的变量； 推导隐晦规则，并分析所有规则； 为所有的目标文件创建依赖关系链； 根据依赖关系，决定哪个目标要重新生成； 执行生成命令； 1-5步为第一个阶段，6-7为第二个阶段。第一个阶段中，如果定义的变量被使用了，make将使用拖延战术将其展开在使用的位置(即不会立即展开)，如果变量出现在已改关系的规则中，那么仅当这条依赖被决定要使用了，变量才会在其内部展开。 书写规则 规则包含两个部分，一个是依赖关系，一个是生成目标的方法。 在Makefile中，规则的顺序是很重要的。因为Makefile中只应有一个最终目标，其它的目标都是被这个目标所连带出来的，所以一定要让make知道最终目标是什么。Makefile中第一条规则中的第一个目标被确立为最终的目标，make完成的就是这个目标。 规则举例12foo.o : foo.c defs.h # foo模块cc -c -g foo.c 在这个例子中，foo.o是我们的目标，foo.c和defs.h是目标所依赖的源文件并且只有一个命令cc -c -g foo.c(以Tab键开头)。此例说明两个问题： 文件的依赖关系，foo.o依赖于foo.c和defs.h的文件，如果foo.c和defs.h的文件日期比foo.o文件日期新，或是foo.o不存在，那么依赖关系发生。 如果生成(更新)foo.o文件。cc命令说明了如何生成foo.o这个文件。 规则的语法123targets : prerequisitescommand... 或是这样:12targets : prerequisites ; commandcommand targets是文件名，以空格分开，可以使用通配符，目标文件可以是一个或多个。command是命令行，如果其不与target:prerequisites在一行，那么必须以[tab键开头]，如果和prerequisites在一行，那么可以用分号作为分隔。prerequisites是目标所依赖的文件（或依赖目标）。 在规则中使用通配符 make支持三个通配符:”*“，”?”和”[…]”。和Unix的B-Shell是相同的。波浪号”~”与Unix下表示目录的功能相同。而在Windows或是MS-DIS下，用户没有宿主目录，那么波浪号所指的目录则根据环境变量”HOME”而定。 如果文件名中有通配符，可以使用转义字符”\”。 1objects = *.o 上面这个例子中表示通配符同样可以用在变量中。并不是说[.o]会展开，不！objects的值就是”.o”。Makefile中的变量其实就是C/C++中的宏。如果要让通配符在变量中展开，也就是说objects的值是所有.o文件名的集合，可以使用关键字wildcard： 1objects := $(wildcard *.o) 文件搜寻 设置文件搜索路径的方法有两种，一种是Makefile文件中的特殊变量VPATH;另一种是vpath关键字（全小写）。 特殊变量VPATH Makefile文件中的特殊变量VPATH可以实现指定寻找依赖文件时的路径。如果没有这个变量，make只会在当前的目录中寻找依赖文件和目标文件，通过定义VPATH可以使得make在当前目录找不到的情况下到指定的目录下寻找文件。 1VPATH = src:../headers 上面的定义指定了两个目录”src”和”../headers”，make会按照这个顺序进行搜索。目录有“冒号”分隔（当前目录永远是最高优先搜索的地方）。 关键字vpath vpath不是变量，而是make的关键字，虽然它和上面提到的VPATH变量类似，但是实际它更为灵活。它可以指定不同的文件在不同的搜索目录。它的使用方法有三种： vpath &lt;pattern&gt; &lt;directories&gt; 为符合模式的&lt;pattern&gt;的文件指定搜索目录&lt;directories&gt;； vpath &lt;pattern&gt; 清除符合模式&lt;pattern&gt;的文件的搜索目录； vpath 清除所有已被设置好了的文件搜索目录； vpath使用方法中的&lt;pattern&gt;需要包含“%”字符。“%”的意思是匹配零活若干字符。&lt;pattern&gt;指定了搜索的文件集，而&lt;directories&gt;则指定了&lt;pattern&gt;的文件集的搜索的目录。例如： vpath %.h ../headers 该语句表示，要求make在“../headers”目录下搜索所有以“.h”结尾的文件（如果某文件在当前目录没有找到的话）。 可以连续地使用vpath语句，以指定不同搜索策略。如果连续的vpath语句中出现了相同的&lt;pattern&gt;，或是被重复了的&lt;pattern&gt;，那么make会按照vpath语句的先后顺序来执行搜索。比如： 123vpath %.c foovpath % blishvpath %.c bar 其表示“.c”结尾的文件，先在“foo”目录，然后是“blish”，最后“bar”目录。 12vpath %.c foo:barvpath % blish 而上路的语句则表示“.c”结尾的文件，先在“foo”目录，然后是“bar”目录，最后才是“blish”目录。 伪目标 之前提到clean的目标是一个“伪目标”，因为并不生成“clean”这个文件。“伪目标”并不是一个文件，只是一个标签，由于“伪目标”不是文件，所以make无法生成它的依赖关系和决定它是否要执行。只能通过显示地指明这个“目标”才能让其生效。“伪目标”的取名不能和文件名重名，不然去就失去了“伪目标”的意义了。 为了避免和文件重名的情况出现，可以使用一个特殊标记.PHONY来显示地指明一个目标是“伪目标”，向make说明不管是否有这个文件，这个目标就是“伪目标”。只要有这个声明，不管是否有“clean”文件，要运行“clean”这个目标，只有“make clean”，整个过程可以这么写123.PHONY : cleanclean :rm *.o temp 伪目标一般没有依赖的文件，但却可以为伪目标指定所依赖的文件。伪目标同样可以作为“默认目标”，只要将其放在第一个。如果Makefile需要生成若干个可执行文件，但只想执行一次make命令，并且所有的目标文件都写在一个Makefile中，那么可以使用“伪目标”这个特性：1234567891011all : prog1 prog2 prog3.PHONY : allprog1 : prog2.o utils.occ -o prog1 prog1.o utils.oprog2 : prog2.occ -o prog2 prog2.oprog3 : prog3.o sort.o utils.occ -o prog3 prog3.o sort.o utils.o 因为Makefile中的第一个目标会被作为默认目标，所以声明·一个“all”作为伪目标，其依赖于其它三个目标。由于伪目标的特性是，总是被执行的，所以其依赖的那三个目标就总是不如“all”这个目标新。所以，其它三个目标的规则总是会被决议，也就达到了一次生成多个目标的目的。（这部分书中介绍的不是很详尽，翻看这篇文章Makefile伪目标 - 作业部落 Cmd Markdown 编辑阅读器才真正理解，引用部分片段这书中这部分加以解释) 执行make时，目标all被作为终极目标。为了完成对它的更新，make会创建（不存在）或者重建（虽存但旧）目标all的所有依赖文件prog1、prog2、prog3。当需要单独更新某一个程序时，可以通过make的命令行选项来明确指定需要重建的程序，例如make prog1。 由上例可以看出目标可以成为依赖。所以，伪目标同样也可成为依赖。当一个伪目标作为另外一个伪目标依赖时，make将其作为另外一个伪目标的子例程来处理（可以这样理解：其作为另外一个伪目标必须执行的部分，就像C语言中的函数调用一样）。见下例：12345678910.PHONY : cleanall cleanobj cleandiffcleanall : cleanobj cleandiffrm programcleanobj : rm *.ocleandiff :rm *.diff make clean将清除所有要被清除的文件。cleanobj和cleandiff这两个伪目标有点像“子程序”的意思。可以通过输入make cleanall和make cleanobj和make cleandiff命令来达到清除不同种类文件的目的。 说明：通常在清除文件的伪目标所定义的命令中rm使用选项-f（--force）来防止在缺少删除文件时出错并退出，使make clean过程失败。也可以在rm之前加上-来方式rm错误退出，使用这种方式时make会提示错误信息但不会退出。为了不看到这些错误信息，需要使用上述的第一种方式。另外make存在一个内嵌隐含变量RM（全大写），它被定义为：RM = rm -f。因此，在书写clean规则的命令行时，可以使用变量$(RM)来代替rm，这样可以避免出现一些不必要的麻烦！是推荐的用法。 多目标 书中这部分内容有些难理解，因此引用文章makefile 多目标和多规则 - iosxiaoming的博客 - CSDN博客中关于Makefile多目标的介绍并与书中内容结合整理，文章中使用的示例与书中使用的示例相同。 Makefile的一个规则中可以有多个目标，规则所定义的命令对所有目标有效。多目标意味着所有的目标具有相同的依赖文件，多目标通常用在以下两种情况: 仅需要一个描述依赖关系的规则，不需要在规则中命令。例如：kbd.o command.o files.o : command.h这个规则实现了同时给三个目标文件制定一个依赖文件。 对于多个具有类似重建命令的目标。重建这些目标的命令不需要完全相同。因为可以在命令行中使用自动化变量$@(关于自动化变量在后面讲述，这个变量表示目前规则中所有目标的集合)来引用具体的目标，完成重建。例如 12bigoutput littleoutput : text.ggenerate text.g -$(subst output,,$@) &gt; $@ 上述规则等价于： 1234bigoutput : text.ggenerate text.g -big &gt; bigoutputlittleoutput : text.ggenerate text.g -little &gt; littleoutput 其中，-$(subst output,,$@)中的“$”表示执行一个Makefile的函数，函数名为subst，后面的为参数。关于函数也在后面讲述，subst函数的作用是替换（subst函数的具体用法：makefile中函数subst函数 - Yriuo - CSDN博客），$@表示目标的集合，就像一个数组，$@依次取出目标，并执行命令。 例子中的generate根据命令行参数来决定输出文件的类型。使用make的字符串处理函数subst来根据目标产生对应的命令行选项。 虽然在多目标的规则中，可以根据不同目标使用不同的命令（在命令行中使用自动化变量$@）。但是，多目标规则并不能根据目标文件自动改变依赖文件（上边例子中使用自动化变量$@改变规则的命令一样）。需要实现这个目的要用到make的静态模式。 静态模式 静态模式可以更加容易地定义多目标的规则，可以让规则变得更加有弹性和灵活。 语法如下：123&lt;targets...&gt;: &lt;target-pattern&gt;: &lt;prereq-patterns...&gt;&lt;commands&gt;... target定义了一系列的目标文件，可以有通配符，是目标的一个集合。target-pattern是指明了targets的模式，也就是目标集模式。prereq-patterns是目标的依赖模式，它对target-pattern形式的模式再进行一次依赖目标的定义。 举例说明，若把&lt;target-pattern定义为“%.o”，意思是&lt;target&gt;集合中都是以“.o”结尾的，而若把&lt;prereq-patterns&gt;定义为“%.c”，意思是对&lt;target-pattern&gt;所形成的目标集进行二次定义，其计算方法是取&lt;target-pattern&gt;模式中的“%”（也就是去掉了.o这个结尾），并为其加上.c这个结尾形成新集合。 因此“目标模式”或是“依赖模式”中都应该有“%”这个字符，如果文件名中有“%”，那么可以使用反斜杠“\”进行转义，来标明真实的“%”字符。 看一个例子:123456objects = foo.o bar.oall : $(objects)$(objects): %.o: %.c$(CC) -c $(CFLAGS) $&lt; -o $@ 上例中指明了我们的目标从$object中获取（对应语法中&lt;targets…&gt;），“%.o”表明要所有以“.o”结尾的目标（对应语法中&lt;target-pattern…&gt;，也就是“foo.o bar.o”，也就是变量$object集合的模式，而依赖模式（&lt;prereq-patterns…&gt;）“%.c”则取模式“%.o”的“%”，也就是“.foo bar”，并为其加上“.c”的后缀，因此依赖目标就是“foo.c bar.c”。而命令中的$&lt;和$@则是自动化变量，$&lt;表示所有的依赖目标集（也就是“foo.c bar.c”），$@表示目标集（也就是“foo.o bar.o”。因此上面的规则展开后等价于下面的规则：1234foo.o : foo.c$(CC) -c $(CFLAGS) foo.c -o foo.obar.o : bar.c$(CC) -c $(CFLAGS) bar.c -o bar.o 若“%.o”有几百个，通过使用这种静态模式规则可以很有效率的写完一堆规则。再看一个例子：123456files = foo.elc bar.o lose.o$(filter %.o,$(files)): %.o: %.c$(CC) -c $(CFLAGS) $&lt; -o $@$(filter %.elc,$(files)): %.elc: %.elemacs -f batch-byte-compile $&lt; $(filter %.o,$(files))表示调用Makefile的filter函数，过滤$filter集，只要其中模式为“%.o”的内容。 自动生成依赖性 在Makefile中，依赖关系可能会需要包含一系列的头文件。大多数的C/C++编译器都支持一个-M的选项，即自动寻找源文件中包含的头文件，并生成一个依赖关系。例如main.c中有#include &quot;defs.h&quot;，那么可以执行： 1cc -M main.c 其输出是： 1main.o : main.c defs.h 由编译器自动生成依赖关系，这样就不必再手动书写若干文件的依赖关系。需要特别说明一下，如果使用GNU的C/C++编译器，得用-MM参数。不然，-M参数会把一些标准库的头文件也包含进来。 如何将编译器自动生成依赖关系的功能与Makefile联系在一起? GNU组织建议把编译器为每个源文件的自动生成的依赖关系放到一个文件中，为每一个“name.c”的文件都生成一个“name.d”的Makefile文件，.d文件中存放对应.c文件的依赖关系。 书中给出一个模式规则来生成.d文件：12345%.d: %.c @set -e; rm -f $@; \ $(CC) -M $(CPPFLAGS) $&lt; &gt; $@.$$$$; \ sed &apos;s,\($*\)\.o[ :]*,\1.o $@ : ,g&apos; &lt; $@.$$$$ &gt; $@; \ rm -f $@.$$$$ 这个规则的意思是，所有的.d文件依赖于.c文件，rm -f $@的意思是删除所有的目标，也就是.d 文件，第二行的意思是，为每个依赖文件$&lt;，也就是.c文件生成依赖文件，$@表示模式%.d文件，如果有一个C文件是name.c，那么%就是name，$$$$意为一个随机编号，第二行生成的文件有可能是“name.d.12345”，第三行使用sed命令做了一个替换，关于sed命令的用法请参看相关的使用文档。第四行就是删除临时文件。 总而言之，这个模式规则要做的事就是在编译器生成的依赖关系中加入.d文件的依赖，即把依赖关系: 1main.o : main.c defs.h 转换成： 1main.o main.d : main.c defs.h 因此.d文件会自动更新并会自动生成。除了可以在这个.d文件中加入依赖关系，还可以加入生成的命令，让每个.d文件都包含一个完整的规则。完成这个工作后需要将这些自动生成的规则放进主Makefile中。可以使用Makefile的include命令，来引入别的Makefile文件，例如： 12sources = foo.c bar.cinclude $(sources: .c =.d) 上述语句中的$(sources: .c =.d)中的.c = .d的意思是做一个替换，把变量$(sources)中所有.c的字串都替换成.d，关于这个“替换”的内容，书中后面会有更为详细的讲述。此外还需要注意次序，因为include是按次序来载入文件，最先载入的.d文件中的目标会成为默认目标。]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第三章 列表]]></title>
    <url>%2F2019%2F03%2F26%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC%E4%B8%89%E7%AB%A0%20%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[本章围绕列表结构的高效实现逐步展开，包括其ADT接口规范以及对应的算法。此外还针对有序列表，系统地介绍排序等经典算法，并就其性能做一分析和对比。 上一章介绍的向量结构中，各数据项的物理存放位置与逻辑次序完全对应，故可通过秩(Rank)访问对应的元素，此即所谓”循秩访问”(call-by-rank)。本章介绍的列表，与向量同属序列结构的范畴，其中的元素也构成一个线性逻辑次序；但与向量极为不同的是，元素的物理地址可以任意。 为保证对列表元素访问的可行性，逻辑上互为前驱和后继的元素之间，应维护某种索引关系。这种索引关系，可抽象地理解为被索引元素的位置(position)，故列表元素是“循位置访问”(call-by-position)的；也可形象地理解为通往被索引元素的链接(link)，故也称”循链接访问“(call-by-link)。 注意，向量中的秩同时对应于逻辑和物理次序，而位置仅对应于逻辑次序。 3.1 从向量到列表3.1.1 从静态到动态 数据结构支持的操作分为静态和动态两种：前者仅从中获取信息，后者则会修改数据结构的局部甚至整体。以第二章基于数组实现的向量结构为例，其size()和get()等静态操作均可在常数时间内完成，而insert()和remove()等动态操作却都可能需要线性时间。其原因在于”各元素物理地址连续”的约定——此即所谓的“静态存储”策略。 在静态策略下，静态操作的效率可达到极致，但就动态操作而言，局部的修改可能引起大范围甚至整个数据结构的修改，比如在静态策略下在$O(1)$时间内由秩确定向量元素的物理地址，但插入某个元素可能需要移动$O(n)$个后继元素。 列表(list)结构虽然也要求各元素在逻辑上具有线性次序，但对其物理地址未作任何限制——此即所谓“动态存储”策略。具体地，在其生命期内，此类数据结构将随着内部数据的需要，相应地分配或回收局部的数据空间。如此，元素之间的逻辑关系得以延续，却不必与其物理次序相关。作为补偿，此类结构将通过指针或引用等机制，来确定各元素的实际物理地址。采用动态存储策略，可以大大降低动态操作的成本。 3.1.2 由秩到位置 改用动态存储策略之后，在提高动态操作效率的同时，却又不得不舍弃原静态存储策略中循秩访问的方式，从而造成静态操作性能的下降。 以采用动态存储策略的线性结构(链表)为例。每个数据元素虽然仍有秩，但为了访问秩为r的元素，只能顺着相邻元素之间的指针，从某一端出发逐个扫描各元素，经过r步迭代后才能确定该元素的物理存储位置。原先只需$O(1)$时间的静态操作，此时的复杂度也将线性正比于被访问元素的秩，在最坏情况下等于元素总数n；即便在各元素被访问效率相等的情况下，平均而言也需要$O(n)$时间。 对数据结构的访问方式，应与其存储策略相一致。此时应更多地习惯于通过位置，来指代并访问动态存储结构中的数据元素。列表中的位置与向量中秩的地位与功能类似，也是指代各数据元素的一个标识性指标，借助它可以便捷地(比如在常熟时间内)得到元素的物理存储地址。各元素的位置，通常可表示和实现为联接在于元素之间的指针或引用。 3.1.3 列表 与向量一样，列表也是由具有线性逻辑次序的一组元素构成的集合: $L = { a_0, a_1, … , a_{n-1} } $ 列表是链表结构的一般化推广，其中的元素称作节点(node)，分别由特定的位置或链接指代。与向量一样，在元素之间，也可定义前驱、直接前驱、以及后继、直接后继等关系；相对于任意元素，也有定义对应的前缀、后缀等子集。没有前驱/后继的节点称作首(first/front)/末(last/rear)节点。 3.2 接口 列表节点(listnode)是列表的基本组成单位，列表节点应保存对应的数据项，还应记录其前驱和后继的位置。 3.2.1 列表节点ADT接口作为一种抽象数据类型，列表节点对象应支持以下操作接口。 操作接口 功能 data() data() pred() 当前节点前驱节点的位置 succ() 当前节点后继节点的位置 insertAsPred() 插入前驱节点，存入被引用对象e，返回新节点位置 insertAsSucc() 插入后继节点，存入被引用对象e，返回新节点位置 ListNode模板类 按照上表所定义的ADT接口，可定义列表节点模板类如下。出于简洁与效率的考虑，这里并未对ListNode对象做封装处理。列表节点数据项的类型，通过模板参数T指定。 1234567891011121314151617listNode.h代码3.1 列表节点模板类 typedef int Rank; // 秩#define ListNodePosi(T) ListNode&lt;T&gt;* // 列表节点位置template &lt;typename T&gt; struct ListNode &#123; // 列表节点模板类(以双向链表形式实现) // 成员 T data; ListNodePosi(T) pred; ListNodePosi(T) succ; // 数值、前驱、后继 // 构造函数 ListNode()&#123;&#125; // 针对header和trailer的构造 ListNode(T e, ListNodePosi(T) p = NULL, ListNodePosi(T) s = NULL) : data(e), pred (p), succ(s) &#123;&#125; // 默认构造器 // 操作接口 ListNodePosi(T) insertAsPred(T const&amp; e); // 紧靠当前节点之前插入新节点 ListNodePosi(T) insertAsSucc(T const&amp; e); // 紧靠当前节点之后插入新节点&#125;; 每个节点都存有数据对象data。还设有指针pred和succ，分别指向其前驱和后继，默认取作NULL。 3.2.2 列表ADT接口 作为一种抽象数据类型，列表对象应支持以下操作接口。 操作接口 功能 适用对象 size() 报告列表当前的规模(节点总数) 列表 first()、last() 返回值、末节点的位置 列表 insertAsFirst(e) insertAsLast(e) 将e当作首、末节点插入 列表 insertA(p, e) insertB(p, e) 将e当作节点p的直接后继、前驱插入 列表 remove(p) 删除位置p处的节点，返回其数值 列表 disordered() 判断所有节点是否已按非降序排列 列表 sort() 调整各节点的位置，使之按非降序排列 列表 find(e) 查找目标元素e，失败时返回NULL 列表 search(e) 查找目标元素e，返回不大于e且秩最大的节点 有序列表 deduplicate() 剔除重复节点 列表 uniquify() 剔除重复节点 有序列表 traverse() 遍历并统一处理所有节点，处理方法由函数对象指定 列表 注意用以指示插入和删除操作位置的结点p。这里约定它或者在此前经查找已经确定，或者从此前的其它操作返回或沿用。这些也是列表类结构的典型操作方式。 与向量一样，有序列表的唯一化，比无序列表效率更高。然而由于只能通过位置指针以局部移动的方式访问节点，尽管有序列表中节点在逻辑上时钟按照大小次序排列，其查找操作的效率并没实质改进。 List模板类 根据上表定义的ADT接口，可定义List模板类如下。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364list.h代码3.2 列表模板类#include "listNode.h"template &lt;typename T&gt; class List &#123; // 列表模板类private: int _size; ListNodePosi(T) header; ListNodePosi(T) trailer; // 规模、头哨兵、尾哨兵protected: void init(); // 列表创建时的初始化 int clear(); // 清除所有节点 void copyNodes(ListNodePosi(T), int); // 复制列表中自位置p起的n项 void merge ( ListNodePosi(T)&amp;, int, List&lt;T&gt;&amp;, ListNodePosi(T), int); // 归并 void mergeSort(ListNodePosi(T)&amp;, int); // 对从p开始连续的n个节点归并排序 void selectionSort(ListNodePosi(T), int); // 对从p开始连续的n个节点选择排序 void insertionSort(ListNodePosi(T), int); // 对从p开始连续的n个节点插入排序public: // 构造函数 List()&#123; init(); &#125; // 默认 List(List&lt;T&gt; const&amp; L); // 整体复制列表L List(List&lt;T&gt; const&amp; L, Rank r, int n); // 复制列表L中自第r项起的n项 List(ListNodePosi(T) p, int n); // 复制列表中自位置p起的n项 // 析构函数 ~List(); // 释放(包含头、尾哨兵在内的)所有节点 // 只读访问接口 Rank size() const &#123; return _size; &#125; // 规模 bool empty() const &#123; return _size &lt;= 0; &#125; // 判空 T&amp; operator[](Rank r) const; // 重载，支持循秩访问(效率低) ListNodePosi(T) first() const &#123; return header-&gt;succ; &#125; // 首节点位置 ListNodePosi(T) last() const &#123; return trailer-&gt;pred; &#125; // 末节点位置 bool valid(ListNodePosi(T) p) // 判断位置p是否对外合法 &#123; return p &amp;&amp; (trailer != p) &amp;&amp; (header != p); &#125; // 将头、尾节点等同于NULL int disordered() const; // 判断列表是否已排序 ListNodePosi(T) find(T const&amp; e) const // 无序列表查找 &#123; return find(e, _size, trailer); &#125; ListNodePosi(T) find(T const&amp; e, int n, ListNodePosi(T) p) const; // 无序区间查找 ListNodePosi(T) search(T const&amp; e) const // 有序列表查找 &#123; return search(e, _size, trailer); &#125; ListNodePosi(T) search(T const&amp; e, int n, ListNodePosi(T) p) const; // 有序区间查找 ListNodePosi(T) selectMax(ListNodePosi(T) p, int n); // 在p及其n-1个后继中选出最大者 ListNodePosi(T) selectMax()&#123; return selectMax(header-&gt;succ, _size); &#125; // 整体最大者 // 可写访问接口 ListNodePosi(T) insertAsFirst(T const&amp; e); // 将e当作首节点插入 ListNodePosi(T) insertAsLast(T const&amp; e); // 将e当作末节点插入 ListNodePosi(T) insertA(ListNodePosi(T) p, T const&amp; e); // 将e当作p的后继插入 ListNodePosi(T) insertB(ListNodePosi(T) p, T const&amp; e); // 将e当作p的前驱插入 T remove(ListNodePosi(T) p); // 删除合法位置p处的节点，返回被删除节点 void merge(List&lt;T&gt;&amp; L)&#123; merge(first(), size, L, L.first(), L._size); &#125; // 全列表归并 void sort(ListNodePosi(T) p, int n); // 列表区间排序 void sort()&#123; sort(first(), _size); &#125; // 列表整体排序 int deduplicate(); // 无序去重 int uniquify(); // 有序去重 void reverse(); // 前后倒置(习题) // 遍历 void traverse(void(*) (T&amp;)); // 遍历，依次实施visit操作(函数指针，只读或局部性修改) template &lt;typename VST&gt; // 操作器 void traverse(VST&amp;); // 遍历，依次实施visit操作(函数对象，可全局性修改)&#125;; // List 由上述代码可见，列表结构的实现方式与第二章的向量结构颇为相似：通过模板参数T指定列表元素的类型；在内部设置私有变量以记录当前规模等状态信息；基于多种排序算法提供统一的sort()接口，以将列表转化为有序列表。 等效地，头、首、末、尾节点的秩可分别理解为-1、0、n-1、n。头节点和尾节点是与生俱来的，而且二者并不相同first和last并不见得不相同，甚至不能保证他们存在，对外first、last可见，header和trailer不可见。 3.3 列表3.3.1 头、尾节点 List对象中私有的头节点(header)和尾节点(trailer)始终存在，但对外并不可见。对外部可见的数据节点如果存在，则其中的第一个和最后一个分别称作首节点(first node)和末节点(last node)。 就内部结构而言，头节点紧邻于首节点之前，尾节点紧邻于末节点之后。这类经封装之后从外部不可见的节点，称作哨兵节点(sentinel node)。由于哨兵节点对外并不可见，因此两个哨兵节点从外部被等效地视作NULL。 设置哨兵节点之后，对于从外部可见的任一节点而言，其前驱和后继在列表内部都必然存在，故可简化算法的描述与实现。此外更重要地，哨兵节点的引入，也使得相关算法不必再对各种便捷退化情况做专门的处理，从而避免出错的可能。 尽管哨兵节点也需占用一定的空间，但只不过是常数规模，其成本远远低于由此带来的便利。 3.3.2 默认构造方法创建List对象时，默认构造方法调用统一初始化过程init()，在列表内部创建一对头、尾哨兵节点，并适当地设置其前驱、后继指针构成一个双向链表。12345678910list_initialize.h代码3.3 列表类内部方法init()template &lt;typename T&gt; void List&lt;T&gt;::init() &#123; // 列表初始化，在创建列表对象时统一调用 header = new ListNode&lt;T&gt;; // 创建头哨兵节点 trailer = new ListNode&lt;T&gt;; // 创建尾哨兵节点 header-&gt;succ = trailer; header-&gt;pred = NULL; trailer-&gt;pred = header; trailer-&gt;succ = NULL; _size = 0; // 记录规模&#125; 该链表对外的有效部分初始化为空，哨兵节点对外不可见，此后引入的新节点都将陆续插入于这对哨兵节点之间。 该过程仅涉及常数次基本操作，共需运行常数时间。 3.3.3 由秩到位置的转换 通过重载操作符”[]”来实现通过秩来指定列表节点，提供一个转换接口。123456789list_bracket.h代码3.4 重载列表类的下标操作符template &lt;typename T&gt; // 重载下标操作符，以通过秩直接访问列表节点(虽方便，效率低，需慎用)T&amp; List&lt;T&gt;::operator[](Rank r) const &#123; // assert: 0 &lt;= r &lt; size ListNodePosi(T) p = first(); // 从首节点出发 while (0 &lt; r--) p = p -&gt; succ; // 顺数第r个节点即是 return p -&gt; data; // 目标节点，返回其中所存元素&#125; // 从任一节点的秩，亦即其前驱的总数 从首节点出发，顺着后继指针前进r步。其中每步迭代仅需常数时间，故该算法的总体运行时间应为$O(r + 1)$，线性正比于目标节点的秩。 相比于向量同类接口的$O(1)$复杂度，列表的这一效率十分低下——根源在于，列表的存储和访问方式不同。虽然当r大于n/2时，从trailer出发沿pred指针逆行查找，可以在一定程度上减少迭代次数，但就总体的平均效率而言，这一改进并无实质意义。 3.3.4 查找实现代码3.2中列表ADT针对整体和区间查找，重载了操作接口find(e)和find(e, p, n)。其中，前者作为特例，可以直接调用后者。因此只需实现后一接口123456789list_find.h代码3.5 无序列表元素查找接口find()template &lt;typename T&gt; // 在无序列表内节点p(trailer)的n个(真)前驱中，找到等于e的最后者ListNodePosi(T) List&lt;T&gt;::find(T const&amp; e, int n, ListNodePosi(T) p) const &#123; // O(n) while (0 &lt; n--) // (0 &lt;= n &lt;= rank(p) &lt; _size)对于p的最近的n个前驱，从右向左 if (e == (p = p -&gt; pred) -&gt; data) return p; // 逐个比对，直至命中或范围越界(这里假定类型T已重载操作符"==") return NULL; // p越出左边界意味着区间内不含e，查找失败&#125; // 失败时，返回NULL 复杂度 以上算法的思路及过程与无序向量的顺序查找算法Vector::find()(代码2.10)相仿，故时间复杂度也应是$O(n)$，线性正比于查找区间的宽度。 3.3.5 插入接口12345678910111213141516171819202122list_insert.h代码3.6 列表节点插入接口template &lt;typename T&gt; ListNodePosi(T) List&lt;T&gt;::insertAsFirst(const T &amp;e) &#123; _size++; return header -&gt; insertAsSucc(e); // e当作首节点插入&#125;template &lt;typename T&gt; ListNodePosi(T) List&lt;T&gt;::insertAsLast(const T &amp;e) &#123; _size++; return trailer -&gt; insertAsPred(e); // e当作末节点插入&#125;template &lt;typename T&gt; ListNodePosi(T) List&lt;T&gt;::insertA(ListNodePosi(T) p, T const&amp; e)&#123; _size++; return p -&gt; insertAsSucc(e); // e当作p的后继插入(After)&#125;template &lt;typename T&gt; ListNodePosi(T) List&lt;T&gt;::insertB(ListNodePosi(T) p, T const&amp; e)&#123; _size++; return p -&gt; insertAsPred(e); // e当作p的前缀插入(Before)&#125; 这些接口的实现都可转化为列表节点对象的前插入或后插入接口。 前插入 将新元素e作为当前节点的前驱插至列表。 123456789listnode_insertAsPred()算法代码3.7 ListNode::insertAsPred()算法 template &lt;typename T&gt; // 将e紧靠当前节点之前插入于当前节点所属列表(设有哨兵头节点header)ListNodePosi(T) ListNode&lt;T&gt;::insertAsPred(const T &amp;e) &#123; ListNodePosi(T) x = new ListNode(e, pred, this); // 创建新节点 pred -&gt; succ = x; pred = x; // 设置正向链接(次序不可颠倒) return x; // 返回新节点的位置&#125; // 得益于哨兵，即便this为首节点亦不必特殊处理——此时等效于insertAsFirst(e) 该算法首先创建新节点new，构造函数同时将其数据项置为e，并令其后继链接succ指向当前节点，令其前驱链接pred指向当前节点的前驱节点。随后使new成为当前节点前驱节点的后继，使new成为当前节点的前驱(次序不能颠倒)。最终，经过如此调整，新节点即被顺利地插至列表的这一局部。 得益于头哨兵节点的存在，即便当前节点为列表的首节点，其前驱也必然存在，故不必另做特殊处理。 后插入 将新元素e作为当前节点的后继插至列表的过程。123456789listnode_insertassucc.h代码3.8 ListNode::insertAsSucc()算法template &lt;typename T&gt; // 将e紧随当前节点之后插入于当前节点所属列表(设有哨兵尾节点trailer)ListNodePosi(T) ListNode&lt;T&gt;::insertAsSucc(const T &amp;e) &#123; ListNodePosi(T) x = new ListNode(e, this, succ); // 创建新节点 succ -&gt; pred = x; succ = x; // 设置逆向链接 return x; // 返回新节点的位置&#125; 后插入的操作过程以及最终效果与前插入完全对称。 复杂度 上述两种插入操作过程，仅涉及局部的两个原有节点和一个新节点，且不含任何迭代或递归。若假设当前节点已经定位，不计入此前的查找所消耗的时间，则它们都可在常数时间内完成。 3.3.6 基于复制的构造copyNodes() List模板类中提供的多种形式的对原列表的整体或列表的构造函数都可概括和转化为底层内部方法copyNodes()。12345678list_copynodes.h代码3.9 列表类内部方法copyNodes()template &lt;typename T&gt; // 列表类内部方法:复制列表中自位置p起的n项void List&lt;T&gt;::copyNodes(ListNodePosi(T) p, int n) &#123; // p合法，且至少有n-1个真后继节点 init(); // 创建头，尾哨兵节点并做初始化 while (n--)&#123; insertAsLast(p -&gt; data); p = p -&gt; succ; &#125; // 将起始自p的n项依次作为末节点插入&#125; 在输入参数合法的前提下，copyNodes()首先调用init()方法，创建头、尾哨兵节点并做相应的初始化处理，然后自p所指节点起，从原列表中取出n个相邻的节点，并逐一作为末节点插至新列表中。 init()操作以及各步迭代中的插入操作均只需常数时间，故copyNodes()过程总体的运行时间应为$O(n + 1)$，线性正比于待复制列表区间的长度n。 基于复制的构造 基于上述copyNodes()方法可以实现多种接口，通过复制已有列表的区间或整体，构造出新列表。1234567891011list_constructor_by_copying.h代码3.10 基于复制的列表构造方法template &lt;typename T&gt; // 复制列表中自位置p起的n项(assert: p为合法位置，且至少有n-1个后继节点)List&lt;T&gt;::List(ListNodePosi(T) p, int n)&#123; copyNodes(p, n); &#125;template &lt;typename T&gt; // 整体复制列表LList&lt;T&gt;::List(List&lt;T&gt; const&amp; L)&#123; copyNodes(L.first(), L._size); &#125;template &lt;typename T&gt; // 复制L中自第r项起的n项(assert: r+n &lt;= L._size)List&lt;T&gt;::List(List&lt;T&gt; const&amp; L, int r, int n)&#123; copyNodes(L[r], n); &#125; 其中为了复制列表L中自秩r起的n个相邻节点，List(L, r, n)需借助重载后的下标操作符，找到待复制区间起始节点的位置，然后再以此节点作为参数调用copyNodes()。根据由秩到位置的转换这节分析出的结论，需要花费$O(r + 1)$的时间才能将r转换为起始节点的位置，故该复制接口的总体复杂度应为$O(r + n + 1)$，线性正比于被复制节点的最高秩。由此也可再次看出，在诸如列表之类采用动态存储策略的结构中，循秩访问远非有效的方式。 3.3.7 删除实现 在列表中删除指定节点p的算法。123456789list_remove.h代码3.11 列表节点删除接口remove()template &lt;typename T&gt; T List&lt;T&gt;::remove(ListNodePosi(T) p)&#123; // 合法删除节点p，返回其数值 T e = p -&gt; data; // 备份待删除节点的数值(假定T类型可直接赋值) p -&gt; pred -&gt; succ = p -&gt; succ; p -&gt; succ -&gt; pred = p -&gt; pred; // 后继、前驱 delete p; _size++; // 释放节点，更新规模 return e; // 返回备份的数值&#125; 为了删除位置p处的节点，令其前驱节点与后继节点相互链接。然后释放掉已经孤立出来的节点p，同时相应地更新列表规模计数器_size()。最终经过如此调整后之后，原节点p即被顺利地从列表中摘除。 在这里也能体会到哨兵节点的作用，即便p所指的是列表中唯一对外的节点(其前驱和后继都是哨兵节点)，remove()算法依然可以正常运转。 复杂度 以上过程仅涉及常数次基本操作，故若不计入此前为查找并确定位置p所消耗的时间，列表的节点删除操作可在常数时间内完成。 3.3.8 析构释放资源及清除节点123456list_destructor.h代码3.12 列表析构方法template &lt;typename T&gt; List &lt;T&gt;::~List() &#123; // 列表析构器 clear(); delete header; delete trailer; // 清空列表，释放头，尾哨兵节点&#125; 列表的析构需要首先调用clear()接口删除并释放所有对外部有效的节点，然后释放内部的头、尾哨兵节点。12345678list_clear.h代码3.13 列表清空方法clear()template &lt;typename T&gt; int List&lt;T&gt;::clear() &#123; // 清空列表 int oldSize = _size; while (0 &lt; _size) remove(header -&gt; succ); // 反复删除首节点，直至列表变空 return oldSize;&#125; 复杂度 这里的时间消耗主要来自clear()操作，该操作通过remove()接口反复删除列表的首节点。因此，clear()方法以及整个析构方法的运行时间应为$O(n)$，线性正比于列表原先的规模。 3.3.9 唯一化实现 剔除无序列表中重复元素的接口dedupulicate()。12345678910111213list_deduplicate.h代码3.14 无序列表剔除重复节点接口dedupulicate()template &lt;typename T&gt; int List&lt;T&gt;::deduplicate() &#123; // 剔除无序列表中的重复节点 if (_size &lt; 2) return 0; // 平凡列表自然无重复 int oldSize = _size; // 记录原规模 ListNodePosi(T) p = header; Rank r = 0; // p从首节点开始 while (trailer != (p = p -&gt; succ))&#123; // 依次直到末节点 ListNodePosi(T) q = find(p -&gt; data, r, p); // 在p的r个(真)前驱中查找雷同者(r为整个前缀的长度) q ? remove(q) : r++; // 若的确存在，则删除之；否则秩加一 &#125; // assert: 循环过程中的任意时刻，p的所有前驱互不相同 return oldSize - _size; // 列表规模变化量，即被删除元素总数&#125; 与算法Vector::deduplicate()类似，这里也是自前向后一次处理各节点p，一旦通过find()接口在p的前驱中查到雷同者，则随即调用remove()接口将其删除。 上述代码while循环中能否remove(p)而不是remove(q)? 不可以，因为下次迭代中p = p-&gt;succ操作存在风险，这时p已经没有明确指向很有可能发生错误。 正确性 向量与列表中元素的逻辑次序一致，故二者的deduplicate()算法亦具有类似的不变性和单调性，故正确性均可保证。 复杂度 与无序向量的去重算法一样，该算法总共需要做$O(n)$步迭代。每一步迭代中find()操作所需的时间线性正比于查找区间宽度，即当前节点的秩；列表节点每次remove()操作仅需常数时间。因此，总体执行时间应为: $1 + 2 + 3 + … + n = n \cdot (n + 1) /2 = O(n^2) $ 相对于无序向量，尽管此处节点删除操作所需的时间减少，但总体渐进复杂度并无改进。 3.3.10 遍历12345678910111213list_traverse.h代码3.15 列表遍历接口traverse()template &lt;typename T&gt; void List&lt;T&gt;::traverse(void (*visit)(T &amp;)) &#123; // 借助函数指针机制遍历 for (ListNodePosi(T) p = header -&gt; succ; p != trailer; p = p-&gt; succ) visit(p -&gt; data);&#125;template &lt;typename T&gt; template &lt;typename VST&gt; // 元素类型、操作器void List&lt;T&gt;::traverse(VST&amp; visit) &#123; // 借助函数对象机制遍历 for (ListNodePosi(T) p = header -&gt; succ; p != trailer; p = p -&gt; succ) visit(p -&gt; data);&#125; 该接口的设计思路与实现方式，与向量的对应接口如出一辙，复杂度也相同。 3.4 有序列表 若列表中所有节点的逻辑次序与其大小次序完全一致，则称作有序列表(sorted list)。 3.4.1 唯一化 与有序向量同理，有序列表中的雷同节点也必然(在逻辑上)彼此紧邻。123456789101112list_uniquify.h代码3.16 有序列表剔除重复节点接口uniquify()template &lt;typename T&gt; int List&lt;T&gt;::uniquify() &#123; // 成批剔除重复元素，效率更高 if (_size &lt; 2) return 0; // 平凡列表自然无重复 int oldSize = _size; // 记录原规模 ListNodePosi(T) p = first(); ListNodePosi(T) q; // p为各区段起点，q为其后继 while (trailer != (q = p -&gt; succ)) // 反复考察紧邻的节点对(p, q) if (p -&gt; data != q -&gt; data) p = q; // 若互异，则转向下一区段 else remove(q); // 否则(雷同)，则删除后者 return oldSize - _size; // 列表规模变化量，即被删除元素总数&#125; 算法概括：位置指针p和q分别指向每一对相邻的节点，若二者雷同则删除q，否则转向下一对相邻节点。如此反复迭代，直至检查过所有节点。 时间复杂度：整个过程的运行时间为$O(_size) = O(n)$，线性正比于列表原先的规模。 3.4.2 查找实现1234567891011list_search.h代码3.17 有序列表查找接口search()template &lt;typename T&gt; // 在有序列表内节点p(可能是trailer)的n个(真)前驱中，找到不大于e的最后者ListNodePosi(T) List&lt;T&gt;::search(T const&amp; e, int n, ListNodePosi(T) p) const &#123; // assert: 0 &lt;= n &lt;= rank(p) &lt; _size while (0 &lt;= n--) // 对于p的最近n个前驱，从右向左逐个比较 if (((p = p -&gt; pred) -&gt; data) &lt;= e) break; // 直至命中、数值越界或范围越界 // assert: 至此位置p必符合输出语义约定——尽管此前最后一次关键码比较可能没有意义(等效于与-inf比较) return p; // 返回查找终止的位置&#125; // 失败时，返回区间左边界的前驱(可能是header)——调用者可通过valid()判断成功与否 顺序查找 与有序向量的各种查找算法相比，该算法完全不同；反过来，除了循环终止条件的细微差异，多数部分反倒与无序列表的顺序查找算法几乎一样。 原因在于，尽管有序列表中的节点已在逻辑上按次序单调排列，但在动态存储策略中，节点的物理地址与逻辑次序毫无关系，故无法像有序向量那样自如地采用减治策略，从而不得不继续沿用无序列表的顺序查找策略。 复杂度 与无序向量的查找算法同理:最好情况下的运行时间为$O(1)$，最坏情况下为$O(n)$。在等概率的前提下，平均运行时间也是$O(n)$，线性正比于查找区间的宽度。 3.5 排序器3.5.1 统一入口12345678910111213list_sort.h代码3.18 有序列表基于排序的构造算法template &lt;typename T&gt; void List&lt;T&gt;::sort(ListNodePosi(T) p, int n)&#123; // 列表区间排序 switch (rand() % 3)&#123; // 随机选取排序算法。可根据具体问题的特点灵活选取或扩充 case 1: insertionSort(p, n); break; // 插入排序 case 2: selectionSort(p, n); break; // 选择排序 case 3: mergeSort(p, n); break; // 归并排序 &#125;&#125; 3.5.2 插入排序构思 插入排序(insertionsort)算法适用于包括向量与列表在内的任何序列结构。 算法的思路可简要描述为：始终将整个序列视作并切分为两部分：有序的前缀，无序的后缀；通过迭代，反复地将后缀的首元素转移至前缀中。由此亦可看出插入排序算法的不变性： 在任何时刻，相对于当前节点$e = S[r]$，前缀$S[0, r)$总是业已有序 算法开始时该前缀为空，不变性自然满足。 实现 有序列表的节点查找算法。12345678910list_insertionsort.h代码3.19 列表的插入排序 template &lt;typename T&gt; // 列表的插入排序算法：对起始于位置p的n个元素排序void List&lt;T&gt;::insertionSort(ListNodePosi(T) p, int n)&#123; // valid(p) &amp;&amp; rank(p) + n &lt;= size for (int r = 0; r &lt; n; r++)&#123; // 逐一为各节点 insertA(search(p-&gt;data, r, p), p-&gt;data); // 查找适当的位置并插入 &#125; p = p -&gt; succ; remove(p -&gt; pred); // 转向下一节点&#125; 有多个元素命中时search()接口将返回其中最靠后者，排序之后重复元素将保持其原有次序，故以上插入排序算法属于稳定算法。 复杂度 插入排序算法共由n步迭代组成，故其运行时间应取决于，各步迭代中所执行的查找、删除及插入操作的效率。插入操作insertA()和删除操作remove()均只需$O(1)$时间；查找操作search()所需时间可在$O(1)$至$O(n)$之间浮动。 当输入序列已经有序时，该算法中的每次search()操作均仅需$O(1)$时间，总体运行时间为$O(n)$。但反过来，若输出序列完全逆序，则各次search()操作所需时间将现行递增，累计共需$O(n^2)$时间。在等概率条件下，平均仍需要$O(n^2)$时间。 3.5.3 选择排序 选择排序(selectionsort)也适用于向量与列表之类的序列结构。 构思 与插入排序类似，该算法也将序列划分为无序前缀和有序后缀两部分；此外，还要求前缀不大于后缀。如此，每次只需从前缀中选出最大者，并作为最小元素转移至后缀中，即可使有序部分的范围不断扩张。 同样地，上述描述也给出了选择排序算法过程所具有的不变性： 在任何时刻，后缀$S(r, n)$已经有序，且不小于前缀$S[0, r]$ 在算法的初始时刻，后缀为空，不变性自然满足。假设不变性已满足，调用无序序列的查找算法，从前缀中找出最大者M。然后将M从前缀中取出并作首元素插入后缀，即可使得后缀的范围扩大，并继续保持有序。 如此，该后缀的范围可不断扩展。当其最终覆盖整个序列时，亦即整体有序。 实现12345678910111213list_selectionsort代码3.20 列表的选择排序template &lt;typename T&gt; // 列表的选择排序算法:对起始于位置p的n个元素排序void List&lt;T&gt;::selectionSort(ListNodePosi(T) p, int n)&#123; // valid(p) &amp;&amp; rank(p) + n &lt;= size ListNodePosi(T) head = p -&gt; pred; ListNodePosi(T) tail = p; for (int i = 0; i &lt; n; i++) tail = tail -&gt; succ; // 待排序区间为(head, tail) while (1 &lt; n)&#123; // 在至少还剩两个节点之前，在待排序区间内 ListNodePosi(T) max = selectMax(head-&gt;succ, n); // 找出最大者(歧义时后者优先) insertB(tail, remove(max)); // 将其移至无序区间末尾(作为有序区间新的首元素) tail = tail -&gt; pred; n--; &#125;&#125; 其中的selectMax()接口用于在无序列表中定位最大的节点。selectMax()算法也称作画家算法。1234567891011list_selectmax.h代码3.21 列表最大节点的定位template &lt;typename T&gt; // 从起始于位置p的n个元素中选出最大者ListNodePosi(T) List&lt;T&gt;::selectMax(ListNodePosi(T) p, int n)&#123; ListNodePosi(T) max = p; // 最大者暂定为首节点p for(ListNodePosi(T) cur = p; 1 &lt; n; n--) // 从首节点p出发，将后续节点逐一与max比较 if (!lt((cur = cur -&gt; succ) -&gt; data, max -&gt; data)) // 若当前元素不小于max，则 max = cur; // 更新最大元素位置记录 return max; // 返回最大节点位置&#125; 复杂度 与插入排序类似地，选择排序亦由n步迭代组成，故其运行时间取决于各步迭代中查找及插入操作的效率。根据之前的结论，insertB()和remove()均只需$O(1)$时间。selectMax()每次必须遍历整个无序前缀，耗时应线性正比于前缀长度；全程累计耗时$O(n^2)$。 无论输入序列中各元素的大小次序如何，以上n次selectMax()调用的累计耗时总是$\Theta (n^2)$。也就是说，其最好和最坏情况下的渐进效率相同。 选择排序属于CBA式算法，故相对之前给出的$\Omega(nlogn)$下界，$\Theta(n^2)$的效率应有很大的改进空间。借助更为高级的数据结构，可以令单次selectMax()操作的复杂度降至$O(logn)$，从而使选择排序的整体效率提高至$O(nlogn)$（insert()和remove()操作需要动态空间分配，虽然可以认为是依然是常数的时间复杂度，但从实际的时间消耗而言，它大致是通常基本操作的100倍，因为这对操作应该尽可能少的使用）。 3.5.4 归并排序 基于二路归并的向量排序算法，其构思也同样适用于列表结构。有序列表的二路归并不仅可以实现，而且能够达到与有序向量二路归并同样高的效率。 二路归并算法的实现12345678910111213141516list_merge.h代码3.22 有序列表的二路归并template &lt;typename T&gt; // 有序列表的归并：当前列表中自p起的n个元素，与列表L中自q起的m个元素归并void List&lt;T&gt;::merge(ListNodePosi(T) &amp; p, int n, List&lt;T&gt;&amp; L, ListNodePosi(T) q, int m) &#123; // assert: this.valid(p) &amp;&amp; rank(p) + n &lt;= size &amp;&amp; this.sorted(p, n) // L.valid(q) &amp;&amp; rank(q) + m &lt;= L._size &amp;&amp; L.sorted(q, m) // 注意：在归并排序之类的场合，有可能this == L &amp;&amp; rank(p) + n = rank(q) ListNodePosi(T)pp = p-&gt;pred; // 借助前驱(可能是header)，以便返回前... while (0 &lt; m) // 在q尚未移出区间之前 if ((0 &lt; n) &amp;&amp; (p-&gt;data &lt;= q-&gt;data)) // 若p仍在区间内且v(p) &lt;= v(q)，则 &#123; if (q == (p = p -&gt; succ)) break; n--; &#125; // p归入合并的列表，并替换为其直接后继 else // 若p已超出右界或v(q) &lt; v(p)，则 &#123; insertB(p, L.remove((q = q-&gt;succ) -&gt; pred)); m--; &#125; // 将q转移至p之前 p = pp -&gt; succ; // 确定归并后区间的(新)起点&#125; List::merge()可以将另一有序列表L中起始于节点q、长度为m的子列表，与当前有序列表中起始于节点p、长度为n的子列表做二路归并。 归并时间 二路归并算法merge()的时间成本主要消耗于其中的迭代。该迭代反复地比较两个子列表的首节点p和q，并视其大小相应地令p指向其后继，或将节点q取出并作为p的前驱插入前一子列表。当且仅当后一子列表中所有节点均处理完毕时，迭代才会终止。因此，在最好情况下，共需迭代m次；而在最坏情况下，则共需迭代n次。 总体而言，共需$O(m+n)$时间，线性正比于两个子列表的长度之和。 分治策略 采用分治策略并基于以上有序列表的二路归并算法，递归地描述和实现列表的归并排序算法。1234567891011121314list_mergesort.h代码3.23 列表的归并排序template &lt;typename T&gt; // 列表的归并排序算法：对起始于位置p的n个元素排序void List&lt;T&gt;::mergeSort(ListNodePosi(T) &amp; p, int n)&#123; // valid(p) &amp;&amp; rank(p) + n &lt;= size if (n &lt; 2) return; // 若待排序范围已足够小，则直接返回；否则... int m = n &gt;&gt; 1; // 以重点为界 ListNodePosi(T) q = p; for (int i = 0; i &lt; m; i++) &#123; q = q -&gt; succ; // 均分列表 &#125; mergeSort(p, m); mergeSort(q, n - m); // 对前、后子列表分别排序 merge(p, m, *this, q, n - m); // 归并&#125; // 注意：排序后，p依然指向归并后区间的(新)起点 排序时间 根据该算法的流程，为对长度为n的列表做归并排序，首先需要花费线性时间确定居中的切分节点，然后递归地对长度均为n/2的两个子列表做归并排序，最后还需花费线性的时间做二路归并。因此，仿照对向量归并排序算法的分析方法，同样可知其复杂度应为$O(nlogn)$。 注意，在子序列的划分阶段，向量与列表归并排序算法之间存在细微但本质的区别。前者支持循秩访问的方式，故可在$O(1)$时间内确定切分中点；后者仅支持循位置访问的方式，故需花费$O(n)$时间。但在有序子序列的合并阶段二者均需$O(n)$时间，故二者的渐进时间复杂度依然相等。 最后，尽管二路归并算法并未对子列表的长度做出任何限制，但这里出于整体效率的考虑，在划分子列表时宁可花费$O(n)$时间使得二者尽可能接近等长。反之，若为省略这部分时间而不保证划分的均衡性，则反而可能导致整体效率的下降。(习题[3-16])]]></content>
      <categories>
        <category>计算机科学与技术</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二章 向量]]></title>
    <url>%2F2019%2F03%2F24%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AC%AC%E4%BA%8C%E7%AB%A0%20%E5%90%91%E9%87%8F%2F</url>
    <content type="text"><![CDATA[本章的讲解围绕向量结构的高效实现而逐步展开，包括其作为抽象数据类型的接口规范以及对应的算法，尤其是高效维护动态向量的技巧。此外，还针对有序向量，系统介绍经典的查找与排序算法，并就其性能做一分析对比，这也是本章的难点与重点所在。最后，还引入复杂度下界的概念，并通过建立比较树模型，针对基于比较式算法给出复杂度下界的统一界定方法。 数据结构是数据项的结构化集合。数据结构划分为线性结构、半线性结构和非线性结构三大类。 最为基本的线性结构统称为序列(sequence)，根据其中数据项的逻辑次序与其物理存储地址的对应关系不同，又可进一步地将序列分为向量(Vector)和列表(List)。 在向量中，所有数据项的物理存放位置与其逻辑次序完全吻合，此时的逻辑次序也称作秩(Rank)。而在列表中，逻辑上相邻的数据项在物理上未必相邻，而是采用间接定址的方式通过封装后的位置(position)相互引用。 从数组到向量数组 具体地，数组A[]中的每一个元素都唯一对应于某一下标编号，记作A[0,n) = {A[0], A[1], .., A[n-1]}。其中，对于任何 0 ≤ i &lt; j &lt; n，A[i]都是A[j]的前驱(predecessor)，A[j]都是A[i]的后继(successor)。特别地，对于任何i ≥ 1，A[i-1]称作A[i]的直接前驱(immediate predecessor)；对于任何i ≤ n - 2，A[i+1]称作A[i]的直接后继(immediate successor)。任一元素的所有前驱构成其前缀(prefix)，所有后继构成其后缀(suffix)。 具体地，若数组A[]存放空间的起始位置为A，且每个元素占用s个单位的空间，则元素A[i]对应的物理地址为：A + i * s，因其中元素的物理地址与其下标之间满足这种线性关系，故亦称作线性数组(linear array)。 向量 以此前介绍的线性递归为例，运行过程中所出现过的所有递归实例，按照相互调用的关系可构成一个线性序列。在此序列中，各递归实例的秩反映了它们各自被创建的时间先后，每一递归实例的秩等于早于它出现的实例总数。反过来，通过r亦可唯一确定$e = v_r$。这是向量特有的元素访问方式，称作循秩访问(call-by-rank)。 向量的特点：不限定同一向量中的各元素都属于同一基本类型，它们本身可以是来自于更具一般性的某一类的对象。另外，各元素也不见得同时具有某一数值属性，故而并不保证它们之间能够相互比较大小。 构造与析构 向量结构在内部维护一个元素类型为T的私有数组_elem[]：其容量由私有变量_capacity指示；有效元素的数量(即向量当前的实际规模)，则有_size指示。此外还进一步地约定，在向量元素的秩、数组单元的逻辑编号以及物理地址之间，具有如下对应关系：向量中秩为r的元素，对应于内部数组中的_elem[r]，其物理地址为_elem+r 默认构造方法 默认的构造方法是，首先根据创建者指定的初始容量，向系统申请空间，以创建内部私有数组_elem[]；若容量未明确指定，则使用默认值DEFAULT_CAPACITY。接下来，鉴于初生的向量尚不包含任何元素，故将指示规模的变量_size初始化为0。整个过程顺序进行，没有任何迭代，故若忽略用于分配数组空间的时间，共需常数时间。 基于复制的构造方法 向量的另一典型创建方式，是以某个已有的向量或数组为蓝本，进行(局部或整体的)克隆。12345678vector_constructor_by_copying.htemplate &lt;typename T&gt; // 元素类型void Vector&lt;T&gt;::copyFrom(T const *A, Rank lo, Rank hi) &#123; // 以数组区间A[lo,hi)为蓝本复制向量 _elem = new T[_capacity = 2 * (hi - lo) ]; _size = 0; // 分配空间，规模清零 while(lo &lt; hi) // A[lo, hi)内的元素逐一 _elem[_size++] = A[lo++]; // 复制至_elem[0, hi-lo)&#125; copyFrom()首先根据待复制区间的边界，换算出新向量的初始规模；再以双倍的容量，为内部数组_elem[]申请空间。最后通过一趟迭代，完成区间A[lo, hi) (注意这里是左闭右开) 内各元素的顺次复制。若忽略开辟新空间所需的时间，运行时间应正比于区间宽度，即$O(hi - lo) = O(size)$。 需强调的是，由于向量内部含有动态分配的空间，默认的运算符”=”不足以支持向量之间的直接赋值(因为向量内存储数据的数据类型并非全是基本数据类型)。为适应此类赋值操作的需求，重载向量的赋值运算符。1234567vector_assignment.htemplate &lt;typename T&gt; Vector&lt;T&gt;&amp; Vector&lt;T&gt;::operator=(Vector&lt;T&gt; const&amp; V) &#123; // 重载 if (_elem) delete [] _elem; // 释放原有内容 copyFrom(V.elem, 0, V.size()); // 整体复制 return *this; // 返回当前对象的引用，以便链式赋值&#125; 析构方法与析构函数不同，同一对象只能有一个析构函数，不得重载。向量对象的析构过程，只需释放用于存放元素的内部数组_elem[]，将其占用的空间交还操作系统。_capacity和_size之类的内部变量无需做任何处理，它们将作为向量对象自身的一部分被系统回收，此后既无需也无法被引用。若不计系统用于空间回收的时间，整个析构过程只需O(1)时间。 动态空间管理静态空间管理 内部数组所占物理空间的容量，若在向量的生命期内不允许调整，则称作静态空间管理策略。 向量实际规模与其内部数组容量的比值(即_size/_capacity)，亦称作装填因子(load factor)。 如何才能保证向量的装填因子既不致于超过1，也不致于太接近于0？为此，需要改用动态空间管理策略。其中一种有效的方法，即使用所谓的可扩充向量。 可扩充向量 可扩充向量(extendable vector) 的原理：若内部数组仍有空余，则操作可照常执行。每经一次插入(删除)，可用空间都会减少(增加)一个单元。一旦空间耗尽，就动态地扩大内部数组的容量。这里的难点及关键在于：如何实现扩容？新的容量取作多少才算适宜？ 一种可行的方法，我们需要另行申请一个容量更大的数组B[]，并将原数组中的成员集体搬迁至新的空间，此后访客顺利地插入新元素e而不致溢出。当然，原数组所占的空间，需要及时释放并归还操作系统。 扩容基于以上策略的扩容算法expand()。12345678910vector_expand.htemplate &lt;typename T&gt; void Vector&lt;T&gt;::expand() &#123; // 向量空间不足时扩容 if(_size &lt; _capacity) return; // 尚未满员时，不必扩容 if(_capacity &lt; DEFAULT_CAPACITY) _capacity = DEFAULT_CAPACITY; // 不低于最小容量 T* oldElem = _elem; _elem = new T[_capacity &lt;&lt;= 1]; // 容量加倍 for(int i = 0; i &lt; _size; i++) _elem[i] = oldElem[i]; // 复制原向量内容(T为基本类型，或已重载赋值操作符'='） delete [] oldElem; // 释放原空间&#125; 请注意，新数组的地址由操作系统分配，与原数据区没有直接的关系。这种情况下，若直接饮用数组，往往会导致共同指向原数组的其他指针失效，称为野指针 (wild pointer)；而封装为向量后，即可继续准确地引用各元素，从而有效地避免野指针的风险。 这里的关键在于，新数组的容量总是取作原数组的两倍————这正是上述后一问题的答案。取作二倍的目的是预留一些空间后，使得将来足够长的时间内，不会因为有必要扩容而打断我们的计算过程。下面介绍通过分摊分析对用于扩容的时间成本进行分析。 分摊分析(amortized analysis)分摊复杂度 对可扩充向量的足够多次连续操作，并将其间所消耗的时间，分摊至所有的操作。如此分摊平均至单词操作的时间成本，称作分摊运行时间(amortized running time)。 注意这一指标与平均运行时间(average running time) 有着本质的区别。后者是按照某种假定的概率分布，对各种情况下所需执行时间的加权平均，故亦称作期望运行时间(expected running time)。而前者则要求，参与分摊的操作必须构成和来自一个真实可行的操作序列，而且该序列还必须足够地长。 相对而言，分摊复杂度可以针对计算成本和效率，做出更为客观而准确的设计(优点)。比如在这里，在任何一个可扩充向量的生命期内，在任何足够长的连续操作序列中，以任何固定间隔连续出现上述最坏情况的概率均为0，故常规的平均复杂度根本不具任何参考意义。 O(1)分摊时间 假定数组的初始容量为某一常数N。既然是估计复杂度的上界，故不妨设向量的初始规模也为N——即将溢出。另外不难看出，除插入操作外，向量其余的接口操作既不会直接导致溢出，也不会增加伺候溢出的可能性，因此不妨考察最坏的情况，假设在伺候需要连续地进行n次insert()操作，n &gt;&gt; N。首先定义如下函数：size(n) = 连续插入n个元素后向量的规模capacity(n) = 连续插入n个元素后数组的容量T(n) = 为连续插入n个元素而花费于扩容的时间 其中，向量规模从N开始随着操作的进程逐步递增，故有：$size(n) = N + n$ 既然不致溢出，故装填因子绝不会超出100%。同时，这里的扩容采用了“懒惰”策略——只有在的确即将发生溢出时，才不得不将容量加倍——因此装填因子也始终不低于50%。概括起来，始终应有：$size(n) ≤ capacity(n) ≤ 2 * size(n)$考虑到N为常数，故有：$capacity(n) = Θ(size(n)) = Θ(n)$ 容量以2为比例按指数速度增长，在容量达到capacity(n)之前，共做过$Θ(log_2n)$次扩容，每次扩容所需时间线性正比于当时的容量(或规模)，且同样以2为比例按指数速度增长。因此，消耗于扩容的时间累计不过：$T(n) = 2N + 4N + 8N + … + capacity(n) &lt; 2 * capacity(n) = Θ(n)$ 将其分摊到其间的连续n次操作，单次操作所需的分摊运行时间应为$O(1)$。 其它扩容策略 早期可扩充向量多采用另一策略：一旦有必要，则追加固定数目的单元。实际上，无论采用的固定常数多大，在最坏情况下，此类数组单次操作的分摊时间复杂度都高达$Ω(n)$。 缩容1234567891011vector_shrink.htemplate &lt;typename T&gt; void Vector&lt;T&gt;::shrink() &#123; // 装填因子过小时压缩向量所占空间 if(_capacity &lt; DEFAULT_CAPACITY &lt;&lt; 1) return; // 不致收缩到DEFAULT_CAPACITY以下 if(_size &lt;&lt; 2 &gt; _capacity) return; // 以25%为界 T* oldElem = _elem; _elem = new T[_capacity &gt;&gt;= 1]; // 容量减半 for (int i = 0; i &lt; _size; i++) &#123; _elem[i] = oldElem[i]; // 复制原向量内容 &#125; delete [] oldElem; // 释放原空间&#125; 与expand()操作类似，尽管单次shrink()操作需要线性量级$Ω(n)$的时间，但其分摊复杂度亦为$O(1)$。 常规向量直接引用元素 重载操作符”[]”，使向量ADT访问元素的方式与数组直接通过下标访问元素的方式(形如”A[i]”)相同。12345vector_bracket.h 代码2.6 重载向量操作符[]template &lt;typename T&gt; T&amp; Vector&lt;T&gt;::operator[](Rank r) const // 重载下标操作符&#123; return _elem[r];&#125; // assert: 0 &lt;= r &lt; _size 置乱器置乱算法1234567permute.h代码2.7 向量整体置乱算法permute()template &lt;typename T&gt;void permute(Vector&lt;T&gt;&amp; V)&#123; //随机置乱向量，使各元素等概率出现在各位置 for(int i = V.size(); i &gt; 0; i--) // 自后向前 swap(V[i-1], V[rand() % i]); // V[i-1]与V[0,i)中某一随机元素交换&#125; 该算法从置乱区间的末元素开始，逆序地向前逐一处理各元素。对每一个当前元素V[i - 1]，先通过调用rand()函数在[0, i)之间等概率地随机选取一个元素，再令二者互换位置。注意，这里的交换操作swap()，隐含了三次基于重载操作符”[]”的赋值。每经过一步这样的迭代，置乱区间都会向前拓展一个单元。因此经过O(n)步迭代后，即实现了整个向量的置乱。 从理论上讲，使用这里的permute()算法，不仅可以枚举出同一向量所有可能的排列，而且能够保证生成各种排列的概率相等。 区间置乱接口123456789vector_unsort.h代码2.8 向量区间置乱接口unsort()template &lt;typename T&gt; void Vector&lt;T&gt;::unsort(Rank lo, Rank hi) &#123; // 等概率随机置乱区间[lo,hi) T* V = _elem + lo; // 将子向量_elem[lo,hi)视作另一向量V[0,hi-lo) for (Rank i = hi - lo; i &gt; 0 ; i--) &#123; // 自后向前 swap(V[i-1], V[rand() % i]); // 将V[i-1]与V[0, i)中某一元素随机交换 &#125;&#125; 通过该接口，可以均匀地置乱任一向量区间[lo, hi)内的元素，故通用性有所提高。可见，只要将该区间等效地视作另一向量V，即可从形式上完整地套用以上permute()算法的流程。尽管如此，还要特别留意代码2.7和代码2.8之间的细微差异：后者是通过下标，直接访问内部数组的元素；而前者则是借助重载的操作符”[]”，通过秩间接地访问向量的元素。 判等器与比较器 从算法的角度来看，”判断两个对象是否相等”与”判断两个对象的相对大小”都是至关重要的操作，它们直接控制者算法执行的分支方向。这两种操作之间既有联系也有区别，不能相互替代。比如，有些对象只能比对但不能比较；反之，支持比较的对象未必支持比对。不过，出于简化的考虑，在很多场合并不需要严格地将二者区分开来。 算法实现的简洁性和通用性，在很大程度上体现于：针对整数等特定数据类型的某种实现，可否推广至可比较或可比对的任何数据类型，而不必关心如何定义以及判定其大小或相等关系。若能如此，就可以将比对和比较操作的具体实现剥离出来，直接讨论算法流程本身。 为此，通常可以采用两种方法。其一，将比对操作和比较操作分别分装成通用的判等器和比较器。其二，在定义对应的数据类型时，通过重载”&lt;”和”==”之类的操作符，给出大小和相等关系的具体定义及其判别方法。 在一些复杂的数据结构中，内部元素本身的类型可能就是指向其它对象的指针；而从外部更多关注的，则往往是其所指对象的大小。若不加处理而直接根据指针的数值(即被指对象的物理地址)进行比较，则所得结果将毫无意义。 无序查找判等器仅支持比对，但未必支持比较的向量，称作无序向量(unsorted vector)。 顺序查找逐个比对的查找方式，称作顺序查找(sequential search)。 实现12345678vector_find.h代码2.10 无序向量元素查找接口find()template &lt;typename T&gt; // 无序向量的顺序查找：返回最后一个元素e的位置；失败时，返回lo - 1Rank Vector&lt;T&gt;::find(T const &amp;e, Rank lo, Rank hi) const &#123; // assert: 0 &lt;= lo &lt; hi &lt;= _size while ((lo &lt; hi--) &amp;&amp; (e != _elem[hi])); // 从后向前，顺序查找 return hi; // 若hi &lt; lo, 则意味着失败；否则hi即命中元素的秩&#125; 其中若干细微之处，需要体会。比如，当同时多个命中元素时，本书统一约定返回其中秩最大者——故这里采用了自后向前的查找次序。如此，一旦命中即可立即返回，从而省略掉不必要的比对。另外，查找失败时约定统一返回-1。这不仅简化了对查找失败情况的判别，同时也使此时的返回结果更加易于理解——只要假想者在秩为-1处植入一个与任何对象对相等的哨兵元素，则返回该元素的秩当且仅当查找失败。 最后一处需要留意。while循环的控制逻辑由两部分组成，首先判断是否已抵达通配符，再判断当前元素与目标元素是否相等。利用了C/C++语言中逻辑表达式的短路求值特性，在前一判断非真厚循环会立即终止，而不致因试图引用已越界的秩(-1)而出错。 复杂度 最坏情况，查找终止于首元素_elem[lo]，运行时间为O(hi - lo) = O(n)。最好情况下，查找命中于末元素_elem[hi - 1]，仅需O(1)时间。对于规模相同、内部组成不同的输入，渐进运行时间却有本质区别，故此类算法也称作输入敏感的(input sensitive) 算法。 插入实现123456789101112vector_insert.h代码2.11 向量元素插入接口insert()template &lt;typename T&gt; // 将e作为秩为r元素插入Rank Vector&lt;T&gt;::insert(Rank r, const T &amp;e) &#123; // assert: 0 &lt;= r &lt;= size expand(); // 若有必要，扩容 for (int i = _size; i &gt; r; i--) &#123; _elem[i] = _elem[i-1]; // 自后向前，后继元素顺次后移一个单元 &#125; _elem[r] = e; _size++; // 置入新元素并更新容量 return r; // 返回秩&#125; 插入前首先调用expand()算法核对是否即将溢出，若有必要，则加倍扩容。为保证数组元素的物理地址连续，随后需要将后缀_elem[r, _size)（若非空)整体后移一个单元。这些后继元素自后向前的搬迁次序不能颠倒，否则会因元素被覆盖而造成数据丢失(自后向前的原因)。在单元_elem[r]腾出之后，方可将待插入对象e置入其中。 复杂度 时间主要消耗于后继元素的后移，线性正比于后缀的长度，故总体为$O( size - r + 1)$。 新插入元素越靠后(前)所需时间越短(长)。特别地，r取最大值_size时为最好情况，只需$O(1)$时间；r取最小值0时，需要$O(size)$时间。一般地，若插入位置等概率分布，则平均运行时间为$O(size) = O(n)$，线性正比于向量的实际规模。 删除 删除操作重载有两个接口，remove(lo, hi)用以删除区间[lo, hi)内的元素，而remove(r)用以删除秩为r的单个元素。乍看起来，利用后者即可实现前者：令r从hi - 1到lo递减，反复调用remove(r)。实际可行的思路恰好相反，应将单元素删除视作区间删除的特例，并基于后者实现前者(单元素删除与区间删除的关系)。如此可将移动操作的总次数控制在$O(m)$以内，而与待删除区间的宽度无关。 区间删除：remove(lo, hi)12345678910vector_removeInterval.h代码2.12 向量区间删除接口remove(lo, hi)template &lt;typename T&gt; int Vector&lt;T&gt;::remove(Rank lo, Rank hi) &#123; // if (lo == hi) return 0; // 出于效率考虑，单独处理退化情况，比如remove(0, 0) while (hi &lt; _size) _elem[lo++] = _elem[hi++] ; // [hi, _size)顺次前移hi - lo个单元 _size = lo; // 更新规模，直接丢弃尾部[lo, _size = hi)区间 shrink(); // 若有必要，则缩容 return hi - lo; // 返回被删除元素的数目&#125; 设[lo, hi)为向量的合法区间，则其后缀[hi, n)需整体前移hi - lo个单元。与插入算法同理，这里后继元素自前往后的移动次序也不能颠倒。 单元素删除：remove(r)12345678vector_remove.h代码2.13 向量单元素删除接口remove()template &lt;typename T&gt; T Vector&lt;T&gt;::remove(Rank r) &#123; // 删除向量中秩为r的元素, 0 &lt;= r &lt;= size T e = _elem[r]; // 备份被删除元素 remove(r, r + 1); // 调用区间删除算法，等效于对区间[r, r+1)的删除 return e; // 返回被删除元素&#125; 复杂度remove(lo, hi)的计算成本，主要消耗于后续元素的前移，线性正比于后缀的长度，总体不过$O(m+1) = O(size - hi + 1)$。区间删除操作所需的时间，应该仅取决于后继元素的数目，而与被删除区间本社你的宽度无关。特别地，基于该接口实现的单元素删除接口remove(r)需耗时$O(size - r)$。也就是说，被删除元素在向量中的位置越靠后(前)所需时间越短(长)，最好为$O(1)$，最坏为$O(n) = O(size)$。 唯一化实现1234567891011vector_deduplicate.h代码2.14 无序向量清除重复元素接口depulicate()template &lt;typename T&gt; int Vector&lt;T&gt;::deduplicate() &#123; // 删除无序向量中重复元素(高效版) int oldSize = _size; // 记录原规模 Rank i = 1; // 从_elem[1]开始 while (i &lt; _size) // 自前向后逐一考察各元素_elem[i] ( find( _elem[i], 0, i) &lt; 0) ? // 在其前缀中寻找与之雷同者(至多一个) i++ : remove(i); // 若无雷同则继续考察其后继，否则删除雷同者 return oldSize - _size; // 向量规模变化量，即被删除元素总数&#125; 该算法自前往后逐一考察各元素_elem[i]，并通过调用find()接口，在其前缀中寻找与之雷同者。若找到，则随即删除；否则，转而考察当前元素的后继。 正确性 算法的正确性由以下不变性保证: 在while循环中，在当前元素的前缀_elem[0, i)内，所有元素彼此互异。 初次进入循环时i=1，只有唯一的前驱_elem[0]，故不变性自然满足。 假设在转至元素e = _elem[i]之前不变性一直成立。于是，经过针对该元素的一步迭代之后，无非两种结果： 1)若元素e的前缀_elem[0, i)中不含与之雷同的元素，则在做过i++之后，新的前缀_elem[0, i)将继续满足不变性，而且其规模增加一个单位。 2)反之，若含存在与e雷同的元素，则由此前一直满足的不变性可知，这样的雷同元素不超过一个。因此在删除e之后，前缀_elem[0, i)依旧保持不变性。 复杂度 这里所需的时间，主要消耗于find()和remove()两个接口，前一部分时间应先行正比于查找区间的宽度，即前驱的总数；后一部分时间应线性正比于后继的总数。因此，每步迭代所需时间为$O(n)$，总体复杂度应为$O(n^2)$。 遍历实现123456789101112131415vector_traverse.h代码2.15 向量遍历接口traverse()template &lt;typename T&gt; void Vector&lt;T&gt;::traverse(void (*visit)(T &amp;)) &#123; // 借助函数指针机制 for (int i = 0; i &lt; _size; i++) &#123; visit(_elem[i]); // 遍历向量 &#125;&#125;template &lt;typename T&gt; template &lt;typename VST&gt; // 元素类型、操作器void Vector&lt;T&gt;::traverse(VST &amp;visit) &#123; // 借助函数对象机制 for (int i = 0; i &lt; _size; i++) &#123; visit(_elem[i]); // 遍历向量 &#125;&#125; traverse()遍历的过程，就是自前向后逐一对各元素实施同一基本操作。而具体采用何种操作，可通过两种方式指定。前一种方式借助函数指针*visit()指定某一函数，该函数只有一个参数，其类型为对向量元素的引用，故通过该函数即可直接访问或修改向量元素。另外，也可以函数对象的形式，指定具体的遍历操作。这类对象的操作符”()”经重载之后，在形式上等效于一个函数接口，故此得名。 相比较而言，后一形式的功能更强，适用范围更广。比如，函数对象的形式支持对向量元素的关联修改。也就是说，对各元素的修改不仅可以相互独立地进行，也可以根据某个(些)元素的数值相应地修改另一元素。前一形式也可实现这类功能，但要繁琐很多。 复杂度 遍历操作本身只包含一层线性的循环迭代，故除了向量规模的因素外，遍历所需时间应线性正比于所统一指定的基本操作所需的时间。 有序向量 若向量S[0, n)中的所有元素不仅按线性次序存放，而且其数值大小也按此次序单调分布，则称作有序向量(sorted vector)。有序向量不要求元素互异，故通常约定其中的元素自前(左)向后(右)构成一个非降序列，即对任意$0 ≤ i &lt; j &lt; n$都有$S[i] ≤ S[j]$。 有序性甄别12345678910vector_disordered.h代码2.17 有序向量甄别算法disordered()template &lt;typename T&gt; int Vector&lt;T&gt;::disordered() const &#123; // 返回向量中逆序相邻元素对的总数 int n = 0; // 计数器 for (int i = 1; i &lt; _size; i++) &#123; // 逐一检查_size - 1对相邻元素 if (_elem[i - 1] &gt; _elem[i]) n++; // 逆序则计数 &#125; return n; // 向量有序当且仅当n = 0&#125; 顺序扫描整个向量，逐一比较每一对相邻元素——向量已经有序，当且仅当它们都是顺序的。 唯一化低效版实现123456789vector_uniquify_slow.h代码2.18 有序向量uniquify()接口的平凡实现template &lt;typename T&gt; int Vector&lt;T&gt;::uniquify() &#123; // 有序向量重复元素剔除算法(低效版) int oldSize = _size; int i = 1; // 当前比对元素的秩，起始于首元素 while (i &lt; _size) // 从前向后，逐一比对各对相邻元素 _elem[i-1] == _elem[i] ? remove(i) : i++; // 若雷同，则删除后者；否则，转至后一元素 return oldSize - _size; // 向量规模变化量，即被删除元素总数&#125; 正确性 其正确性基于如下事实：有序向量中的重复元素必然前后紧邻。于是，可以自前向后地逐一检查各对相邻元素:若二者雷同则调用remove()接口删除靠后者，否则转向下一对相邻元素。如此，扫描结束后向量中将不再含有重复元素。 复杂度 运行时间主要消耗于while循环，共需迭代_size - 1 = n - 1步。此外，在最坏情况下，每次循环都需要执行一次remove()操作，由前面可知remove()操作的复杂度线性正比于被删除元素的后继元素总数。因此，当大量甚至所有元素均雷同时，用于所有这些remove()操作的时间总量将高达： $(n - 2) + (n - 3) + … + 2 + 1 = O(n^2)$ 与向量未排序时相同，说明该方法未能充分利用此时向量的有序性。 改进思路 低效版唯一化过程复杂度过高的根源是，在对remove()接口的各次调用中，同一元素可能作为后继元素向前移动多次，且每次仅移动一个单元。 因为此时的每组重复元素都必然前后紧邻地集中分布，所以可以区间为单位成批地删除前后紧邻的各组重复元素，并将其后继元素(若存在)统一地大跨度前移。具体地，若V[lo, hi)为一组相邻的重复元素，则所有的后继元素V[hi, _size)可统一地整体前移hi - lo - 1个单元。 高效版1234567891011vector_uniquify.h代码2.19 有序向量uniquify()接口的高效实现template &lt;typename T&gt; int Vector&lt;T&gt;::uniquify() &#123; // 有序向量重复元素剔除算法(高效版) Rank i = 0, j = 0; // 各对互异"相邻"元素的秩 while (++j &lt; _size) // 逐一扫描，直至末元素 if (_elem[i] != _elem[j]) // 跳过雷同者 _elem[++i] = _elem[j]; // 发现不同元素时，向前移至紧邻于前者后侧 _size = ++i; shrink(); // 直接截除尾部多余元素 return j - i; // 向量规模变化量，即被删除元素总数&#125; 既然各组重复元素必然彼此相邻地构成一个子区间，故只需依次保留各区间的起始元素。于是，这里引入了变量i和j。每经过若干次移动，i和j都将分别指向下一对相邻子区间的首元素；在将后者转移至前者的后继位置之后(相比低效版这里是元素的复制而不是前移，因此不需要remove()操作)，即可重复上述过程。 复杂度 while循环的每一次迭代，仅需对元素数值做一次比较，向后移动一到两个位置指针，并至多向前复制一个元素，故只需常数时间。而在整个算法过程中，每经过一次迭代秩j都必须加1，鉴于j不能超过向量的规模n，故共需迭代n次。由此可知，uniquify()算法的时间复杂度应为$O(n)$，较之uniquify_slow()的$O(n^2)$,整整提高了一个线性因子。 反过来，在遍历所有元素之前不可能确定是否有重复元素，故就渐进复杂度而言，能在$O(n)$时间内完成向量的唯一化已属最优。能做到这一点的关键在于向量已经排序。 查找二分查找(版本A)实现12345678910111213vector_search_binary_a.h代码 2.21 二分查找算法(版本A)// 二分查找算法(版本A):在有序向量的区间[lo,hi)内查找元素e, 0 &lt;= lo &lt;= hi &lt;= _sizetemplate &lt;typename T&gt; static Rank binSearch(T* A, T const&amp; e, Rank lo, Rank hi)&#123; while (lo &lt; hi)&#123; // 每步迭代可能要做两次比较判断，有三个分支 Rank mi = (lo + hi) &gt;&gt; 1; // 以中点为轴点 if (e &lt; A[mi]) hi = mi; // 深入前半段[lo, mi)继续查找 else if (A[mi] &lt; e) lo = mi + 1; // 深入后半段(mi, hi)继续查找 else return mi; // 在mi处命中 &#125; // 成功查找可以提前终止 return -1; // 查找失败&#125; // 有多个命中元素时，不能保证返回秩最大者；查找失败时，简单返回-1，而不能指示失败的位置 为在有序向量区间[lo, hi)内查找元素e，该算法以中点$mi = (lo + hi)/2$为界，将其大致平均地分为前、后两个子向量。随后通过一至两次比较操作，确定问题转化的方向。通过快捷的整数移位操作回避了相对更加耗时的除法运算。另外，通过引入lo、hi和mi等变量，将减治算法通常的递归模式改成了迭代模式。 复杂度 以上算法采取的策略可概括为，以”当前区间内居中的元素”作为目标元素的试探对象。从应对最坏情况的保守角度来看，这一策略是最优的——每一步迭代之后无论沿着哪个方向深入，新问题的规模都将缩小一半。因此，这一策略也称作二分查找(binary search)。 随着迭代的不断深入，有效的查找区间宽度将按1/2的比例以几何级数的速度递减。于是，经过至多$log_2(hi -lo)$步迭代后，算法必然终止。鉴于每步迭代仅需常数时间，故总体时间复杂度不超过:$O(log_2(hi - lo)) = O(logn)$。 与之前的顺序查找算法$O(n)$复杂度相比，$O(logn)$几乎改进了一个线性因子。 查找长度 以上迭代过程所涉及的计算，主要分为两类：元素的大小比较、秩的算术运算及其赋值。虽然二者均属于$O(1)$复杂度的基本操作，但元素的秩无非是(无符号)的整数，而向量元素的类型则通常更为复杂，甚至复杂到未必能够保证在常数时间内完成(习题【2-17】)。因此就时间复杂度的常系数而言，前一类计算的权重远远高于后者，而查找算法的整体效率也更主要地取决于所执行的元素大小比较操作的次数，即所谓查找长度(search length)。 成功查找长度 对于长度为n的有序向量，共有n种可能的成功查找，分别对应于某一元素。实际上，每一种成功查找所对应的查找长度，仅取决于n以及目标元素所对应的秩，而与元素的具体数值无关。 为了估计出一半情况下的成功查找长度，不失一般性地，仍在等概率条件下考察长度为$n = 2^k - 1$的有序向量，并将其对应的平均成功查找长度记作$C_{average}(k)$，将所有元素对应的查找长度总和记作$C(k) = C_{average}(k) \cdot (2^k - 1)$。 特别地，当k = 1时向量长度n = 1，成功查找仅有一种情况，故有边界条件: $C_{average}(1) = C(1) = 2​$ 以下采用递推分析法。对于长度为$n = 2^k - 1$的有序向量，每步迭代都有三种可能的分支:经过1次成功的比较后，转化为一个规模为$2^{k-1}-1$的新问题；经2次失败的比较后，终止于向量中的某一元素，并确认在此处成功命中；经1次失败的比较另加1次成功的比较后，转化为另一个规模为$2^{k-1} -1​$的新问题。 根据以上递推分析的结论，可得递推式如下:$$\begin{aligned}C(k)&amp; = [C(k-1) + (2^{k-1} -1 )] + 2 + [C(k-1) + 2 \times (2^{k-1} -1 )] \\&amp; = 2 \cdot C(k-1) + 3 \cdot 2^{k-1} - 1\end{aligned}$$ 若令： $F(k) = C(k) - 3k \cdot 2^{k-1} - 1$ 则有: $F(1) = -2​$$$\begin{aligned} F(k) &amp; = 2 \cdot F(k - 1) = 2^2 \cdot F(k - 2) = 2^3 \cdot F(k - 3) = … \\ &amp; = 2^{k-1} \cdot F(1) = -2^k \end{aligned}$$ 于是：$$\begin{aligned} C(k) &amp; = F(k) + 3k \times 2^{k-1} + 1 \\ &amp; = -2^k + 3k \times 2^{k-1} + 1 \\ &amp; = (3k/2 -1) \cdot (2^k - 1) + 3k/2 \end{aligned}$$ 进而：$$ \begin{aligned} C_{average}(k) &amp; = C(k) / (2^k - 1) \\ &amp; = 3k/2 - 1 + 3k/2/(2^k - 1) \\ &amp; = 3k/2 - 1 + O(\varepsilon) \\ \end{aligned}$$ 也就是说，若忽略末尾趋于收敛的波动项，平均查找长度应为： $O(1.5k) = O(1.5 \cdot log_2n)​$ 失败查找长度 按照上述代码，失败查找的终止条件必然是”lo ≥ hi”，也就是说，只有在有效区间宽度缩减至0时，查找方以失败告终。因此，失败查找的时间复杂度应为确定的$Θ(logn)$。 仿照以上对平均成功查找长度的递推分析方法，不难证明(习题【2-20】)，一般情况下的平均失败查找长度亦为$O(1.5 \cdot log_2n)$。 不足 尽管二分查找算法(版本A)即便在最坏情况下也可保证$O(logn)$的渐进时间复杂度，但就其常系数1.5而言仍有改进余地。下面介绍Fibonacci查找将完成这改进。 Fibonacci查找递推方程 递推方程法既是复杂度分析的重要方法，也是优化算法时确定突破口的有力武器。 最终求解所得到的平均复杂度，主要取决于$(2_{k-1} - 1)$和$2 \times (2_{k-1} - 1)$两项，其中的$(2_{k-1} - 1)$为子向量的宽度，而系数1和2则是算法为深入前、后子向量，所需做的比较操作次数。以此前的二分查找算法版本A为例，之所以存在均衡性方面的缺陷，根源来自于这两项的大小不相匹配。 基于这一理解，发现解决问题的思路不外乎两种： 其一，调整前、后区域的宽度，适当地加长(缩短)前(后)子向量； 其二，统一沿两个方向深入所需要执行的比较次数，比如都统一为一次； 黄金分割 简化起见，设向量长度n = fib(k) - 1 fibsearch(e, 0, n)查找可以mi = fib(k - 1) - 1作为前、后子向量的切分点。如此，前、后子向量的长度将分别是： $fib(k-1) - 1$ $fib(k-2) - 1 = (fib(k) - 1) - (fib(k - 1) - 1) - 1$ 于是，无论朝哪个方向深入，新向量的长度从形式上都依然是某个Fibonacci数减一，故这一处理手法可以反复套用，直至因在S[mi]处命中或向量长度收缩至零而终止。这种查找算法，亦称作Fibonacci查找(Fibonaccian search)。 实现123456789101112131415vector_search_fibonaccin.h代码 2.22 Fibonacci查找算法// Fibonacci查找算法(版本A):在有序向量的区间[lo, hi)内查找元素e, 0 &lt;= lo &lt;= hi &lt;= _sizetemplate &lt;typename T&gt; static Rank fibSearch(T* A, T const&amp; e, Rank lo, Rank hi)&#123; Fib fib(hi - lo); // 用O(log_phi(n = hi - lo)时间创建Fib数列 while (lo &lt; hi)&#123; // 每步迭代可能要做两次比较判断，有三个分支 while (hi - lo &lt; fib.get()) fib.prev(); // 通过向前顺序查找(分摊O(1))——至多迭代几次 Rank mi = lo + fib.get() - 1; // 确定形如Fib(k) - 1 的轴点 if (e &lt; A[mi]) hi = mi; // 深入前半段[lo, mi)继续查找 else if (A[mi] &lt; e) lo = mi + 1; // 深入后半段(mi, hi)继续查找 else return mi; // 在mi处命中 &#125;// 成功查找可以提前终止 return -1; // 查找失败&#125; // 有多个命中元素时，不能保证返回秩最大者；失败时，简单地返回-1，而不能指示失败的位置 算法主体框架与二分查找大致相同，主要区别在于以黄金分割点取代中点作为切分点。为此，需要借助Fib对象(习题【1-22】)，实现对Fibonacci数的高效设置与获取。 尽管以下的分析多以长度为fib(k) - 1的向量为例，但这一实现完全可适用于长度任意的向量中的任意子向量。为此，只需在进入循环之前调用构造器Fib(n = hi - lo)，将初始长度设置为”不小于n的最小Fibonacci项”。这一步所需花费的$O(log_{\phi}n)$时间，分摊到后续的$O(log_{\phi}n)$步迭代中，并不影响算法整体的渐进复杂度。 定量分析 Fibonacci查找算法最好、最坏情况的成功查找长度与二分算法的结论完全一致。 依然将长度为n = fib(k) - 1的有序向量的平均成功查找长度记作$C_{average}(k)$，将所有元素对应的查找长度总和记作$C(k) = C_{average}(k) \cdot (fib(k) - 1)$。 同理，可得边界条件及递推式如下: $C_{average}(2) = C(2) = 0$ $C_{average}(3) = C(3) = 2$$$\begin{aligned} C(k) &amp; = [C(k-1) + (fib(k-1) - 1)] + 2 + [C(k-2) + 2 \times (fib(k-2) - 1)] \\ &amp; = C(k - 2) + C(k - 1) + fib(k - 2) + fib(k) - 1 \end{aligned}$$ 结合以上边界条件，可以解得: (令$F(k) = -C(k) + k \cdot fib(k) + 1$，则有$F(0) = 1$，$F(1) = 2$，$F(k) = F(k-1) + F(k-2)$)$$\begin{aligned} C(k) &amp; = k \cdot fib(k) - fib(k + 2) + 1 \\ &amp; = (k - \phi^2) \cdot fib(k) + 1 + O(\mathcal{E}) \end{aligned}$$其中，$\phi = (\sqrt{5} + 1) / 2 = 1.618$ 于是$$\begin{aligned} C(k) &amp; = C(k) / (fib(k) - 1)\\ &amp; = k - \phi^2 + 1 + (k - \phi^2) / (fib(k) - 1) + O(\mathcal{E}) \\ &amp; = k - \phi^2 + 1 + O(\mathcal{E}) \\ \end{aligned}$$ 忽略末尾趋于收敛的波动项，平均查找长度的增长趋势为: $O(k) = O(log_{\phi}n) = O(log_{\phi}2 \cdot log_2n) = O(1.44 \cdot log_2n)$ 较之之前二分查找算法(版本A)的$O(1.5 \cdot log2n)$，效率略有提高。 二分查找(版本B)从三分支对应两分支 为了解决二分查找算法版本A的不均衡性，Fibonacci查找算法已通过采用黄金分割点，在一定程度上降低了时间复杂度的常系数。 还有另一更为直接的方法，即令以上两项的常系数同时等于1。也就是说，无论朝哪个方向深入，都只需做1次元素的大小比较。相应地，算法在每步迭代中(或递归层次上)都只有两个分支方向，而不再是三个。 具体过程与二分查找算法的版本A基本类似。不同之处是，在每个切分点A[mi]处，仅做一次元素比较。具体地，若目标元素小于A[mi]，则深入前端子向量A[lo, mi]继续查找；否则，深入后端子向量A[mi, hi)继续查找。 实现1234567891011vector_search_binary_b.h代码 2.23 二分查找算法(版本B)// 二分查找算法(版本B)：在有序向量的区间[lo, hi)内查找元素e, 0 &lt;= lo &lt;= hi &lt;= _sizetemplate &lt;typename T&gt; static Rank binSearch(T* A, T const&amp; e, Rank lo, Rank hi)&#123; while ( 1 &lt; hi - lo)&#123; // 每步迭代仅需做一次比较，有两个分支；成功查找不能提前终止 Rank mi = (lo + hi) &gt;&gt; 1; // 以中点为轴点 (e &lt; A[mi]) ? hi = mi : lo = mi; // 经比较后确定深入[lo, mi)或[mi, hi) &#125; // 出口时hi = lo + 1, 查找区间仅含一个元素A[lo] return (e == A[lo]) ? lo : -1; // 查找成功时返回对应的秩；否则统一返回-1&#125;// 有多个命中元素时，不能保证返回秩最大者；查找失败时，简单地返回-1，而不能指示失败的位置 注意与二分查找版本A的差异。首先，每一步迭代只需判断是否e &lt; A[mi]，即可相应地更新有效查找区间的右边界(hi = mi)或左边界(lo = mi)。另外，只有等到区间的宽度已不足2个单元时迭代才会终止，最后再通过一次比对判断查找是否成功。 性能 尽管版本B中的后端子向量需要加入A[mi]，但得益于mi总是位于中央位置，整个算法$O(logn)$的渐进复杂度不受任何影响。 版本B中只有在向量有效区间宽度缩短至1个单元时算法才会终止，而不能像版本A一旦命中就能及时返回。因此，最好情况下的效率有所倒退。作为补偿，最坏情况下的效率相应地有所提高。实际上无论是成功查找或失败查找，版本B各分支的查找长度更加接近，故整体性能更趋稳定。 二分查找(版本C)实现1234567891011vector_search_binary_c.h代码 2.24 二分查找算法(版本C)// 二分查找算法(版本C)：在有序向量的区间[lo, hi)内查找元素e, 0 &lt;= lo &lt;= hi &lt;= _sizetemplate &lt;typename T&gt; static Rank binSearch(T* A, T const&amp; e, Rank lo, Rank hi)&#123; while (lo &lt; hi)&#123; // 每步迭代仅需做一次比较判断，有两个分支 Rank mi = ( lo + hi ) &gt;&gt; 1; // 以中点为轴点 ( e &lt; A[mi] ) ? hi = mi : lo = mi + 1; // 经比较后确定深入[lo, mi)或(mi, hi) &#125;// 成功查找不能提前终止 return --lo; // 循环结束时，lo为大于e的元素的最小秩，故lo - 1即不大于e的元素的最大秩&#125; // 有多个命中元素时，总能保证返回秩最大者；查找失败时，能够返回失败位置 该版本的主体结构与版本B一致，故不难理解，二者的时间复杂度相同。 正确性 版本C与版本B的差异，主要有三点。首先，只有当有效区间的宽度缩短至0(而不是1)时，查找方告终止。另外，在每次转入后端分支时，子向量的左边界取作mi + 1而不是mi。 通过数学归纳可以证明，版本C中的循环体，具有如下不变性: A[0, lo)中的元素皆不大于e；A[hi, n)中的元素皆大于e 首先迭代时，lo = 0且hi = n，A[hi, n)均空，不变性自然成立。 设在某次进入循环时以上不变性成立，以下无非两种情况。若e &lt; A[mi]，在令hi = mi并使A[hi, n)向左扩展之后，该区间内的元素皆不小于A[mi]，也仍然大于e。反之，若A[mi] ≤ e，在令lo = mi + 1并使A[0, lo)向右拓展之后，该区间内的元素皆不大于A[mi]，也仍然不大于e。上述不变性得以延续。 循环终止时，lo = hi。考察此时的元素A[lo - 1]和A[lo]:作为A[lo, n) = A[hi, n)内的第一个元素，A[lo]必大于e。也就是说A[lo - 1]即是原向量中不大于e的最后一个元素。因此在循环结束后，无论成功与否，只需返回lo - 1即可——这也是版本C与版本B的第三点差异。 排序与下界有序性有序性在很多场合都能极大地提高计算的效率。 排序及其分类在解决许多应用问题时一种普遍采用的策略是，首先将向量转换为有序向量，再调用有序向量支持的各种高效算法。 排序算法分类排序算法有多种，可从多个角度对其进行分类。 根据其处理数据的规模与存储的特点不同，可分为： 内部排序算法 外部排序算法前者处理的数据规模相对不大，内存足以容纳；后者处理的数据规模很大，必须借助外部甚至分布式存储器，在排序计算过程的任一时刻，内存中只能容纳其中一小部分数据。 根据输入形式的不同，可分为： 离线算法(offline algorithm) 在线算法(online algorithm)前一情况下，待排序的数据以批处理的形式整体给出；而在网络计算之类的环境中，待排序的数据通常需要实时生成，在排序算法启动后数据才陆续到达。 针对所依赖的体系结构不同，又可分为： 串行排序算法 并行排序算法 根据排序算法是否采用随机策略，可分为： 确定式 随机式 本书讨论的范围，主要集中于确定式串行脱机的内部排序算法。 下界 一般地，任一问题在最坏情况下的最低计算成本，即为该问题的复杂度下界(lower bound)。一旦某一算法的性能达到这一下界，即意味着它已是最坏情况下最优的(worst-case optimal)。 以下结合比较树模型，介绍界定问题复杂度下界的一种重要方法。 比较树基于比较的分支 用节点(圆圈)表示算法过程中的不同状态，用有向边表示不同状态之间的相互转换，就可以将算法转化为树形结构。 这一转化方法也可以推广并应用于其他算法。一般地树根结点对应算法入口处的起始状态；内部节点对应过程中的某步计算，通常属于基本操作；叶节点则对应经一系列计算后某次运行的终止状态。如此借助这一树形结构，可以涵盖对应算法所有可能的执行流程。 比较树 算法所有可能的执行过程，都可涵盖于这一树形结构中。具体地，该树具有以下性质： 每一内部节点各对应于一次比对(称量)操作； 内部节点的左、右分支，分别对应于在两种比对结果(是否等重)下的执行方向； 叶节点(或等效地，根到叶节点的路径)对应于算法某次执行的完整过程及输出； 反过来，算法的每一运行过程都对应于从根到某一叶节点的路径。 按上述规则与算法相对应的树，称作比较树(comparison tree)。无论什么算法，只要其中的分支完全取决于不同变量或常量的比对或比较结果，则该算法所有可能的执行过程都可表示和概括为一棵比较树。反之，凡可如此描述的算法，都可称作基于比较式算法(comparison-based algorithm)，简称CBA式算法。 CBA式算法在最坏情况下的最低执行成本，可由对应的比较树界定。 估计下界最小树高 考察任一CBA式算法，设CT(A)为与之对应的一棵比较树。 根据比较树的性质，算法A每一次运行所需的时间，将取决于对应叶节点到根节点的距离(称作叶节点的深度)；而算法A在最坏情况下的运行时间，将取决于比较树中所有叶节点的最大深度(称作该树的高度，记作$h(CT(A))$)。因此就渐进的意义而言，算法A的时间复杂度应不低于$\Omega(h(CT(A)))$。 如何估计这些比较树的最小高度？ 为此，只需考察书中所含叶节点(可能的输出结果)的数目。具体地，在一棵高度为h的二叉树中，叶节点的数目不可能多余$2^h$。因此反过来，若某一问题的输出结果不少于N种，则比较树中叶节点也不可能少于N个，树高h不可能低于$log_2N$(习题【7-3】) 排序 任一CBA式排序算法所对应比较树的高度应为: $h ≥ \lceil log_3(n!) \rceil = \lceil log_3e \cdot ln(n!) \rceil = \Omega(nlogn)$ 因此最坏情况下CBA排序算法至少需要$\Omega(nlogn)$时间，其中n为待排序元素数目。 需要强调的是，这一$\Omega(nlogn)$下界是针对比较树模型而言的。事实上还有很多不属此类的排序算法，并且其中一些算法在最坏情况下的运行时间，有可能低于这一下界，但与上述结论并不矛盾。 排序器起泡排序起泡排序1234567vector_bubblesort.h代码 2.26 向量的起泡排序template &lt;typename T&gt; // 向量的起泡排序void Vector&lt;T&gt;::bubbleSort(Rank lo, Rank hi) &#123; // assert: 0 &lt;= lo &lt; hi &lt;= _size while (!bubble(lo, hi--)); // 逐趟做扫描交换，直至全序&#125; 反复调用单趟扫描交换算法，直至逆序现象完全消除。 扫描交换123456789101112vector_bubble.h代码 2.27 单趟扫描交换template &lt;typename T&gt; bool Vector&lt;T&gt;::bubble(Rank lo, Rank hi) &#123; // 一趟扫描交换 bool sorted = true; // 整体有序标志 while (++lo &lt; hi) // 自左向右，逐一检查各对相邻元素 if (_elem[lo - 1] &gt; _elem[lo])&#123; // 若逆序，则 sorted = false; // 意味着尚未整体有序，并需要 swap (_elem[lo - 1], _elem[lo]); // 通过交换使局部有序 &#125; return sorted; // 返回有序标志&#125; 依次比对各对相邻元素，每当发现逆序即令二者彼此交换；一旦经过某趟扫描后未发现任何逆序的相邻元素，即意味着排序任务已经完成，则通过返回标志”sorted”，以便主算法及时终止。 重复元素与稳定性 稳定性(stability)是对排序算法更为细致的要求，重在考察算法对重复元素的处理效果。具体地，在将向量A转换为有序向量S之后，设$A[i]$对应于$S[k_i]$。若对于A中每一对重复元素$A[i] = A[j]$(相应地$S[k_i] = S[k_j]$)，都有i &lt; j当且仅当$k_i &lt; k_j$，则称该排序算法是稳定算法(stable algorithm)。简而言之，稳定算法的特征是，重复元素之间的相对次序在排序前后保持一致。反之，不具有这一特征的排序算法都是不稳定算法(unstable algorithm)。 归并排序有序向量的两路归并 二路归并，就是将两个有序序列合并成一个有序序列。归并排序所需的时间，也主要决定于各趟二路归并所需时间的总和。 二路归并属于迭代式算法。每步迭代中，只需比较两个待归并向量的首元素，将小者取出并追加到输出向量的末尾，该元素在原向量中的后继则成为新的首元素。如此往复，直到，某一向量为空。最后，将另一非空的向量整体接至输出向量的末尾。 分治策略12345678910vector_mergesort.h代码 2.28 向量的归并排序template &lt;typename T&gt; // 向量归并排序void Vector&lt;T&gt;::mergeSort(Rank lo, Rank hi) &#123; // 0 &lt;= lo &lt; hi &lt;= _size if (hi - lo &lt; 2) return; // 单元素区间自然有序，否则... int mi = ( lo + hi ) / 2; // 以中点为界 mergeSort(lo, mi); mergeSort(mi, hi); // 分别排序 merge(lo, mi, hi); // 归并排序&#125; 均匀地将向量S[lo, hi)划分成两个子向量。借助以上的二路归并算法，通过递归调用将二者分别转换为有序向量，得到与原向量S对应的整个有序向量。 这里递归终止条件是当前向量长度：$n = hi -lo = 1$ 仅含单个元素的向量必然有序，这一处理分支自然也就可以作为递归基。 二路归并接口的实现123456789101112131415vector_merge.h代码 2.29 有序向量的二路归并template &lt;typename T&gt; // 有序向量的归并void Vector&lt;T&gt;::merge(Rank lo, Rank mi, Rank hi) &#123; // 各自有序的子向量[lo, mi)和[mi, hi) T* A = _elem + lo; // 合并后的向量A[0, hi - lo) = _elem[lo, hi) int lb = mi - lo; T* B = new T[lb]; // 前子向量B[0, lb) = _elem[lo, mi) for ( Rank i = 0; i &lt; lb; B[i] = A[i++]); // 复制前子向量 int lc = hi - mi; T* C = _elem + mi; // 后子向量C[0, lc) = _elem[mi, hi) for (Rank i = 0, j = 0, k = 0; (j &lt; lb) || (k &lt; lc);)&#123; // B[j]和C[k]中的小者续至A末尾 if ((j &lt; lb) &amp;&amp; (!(k &lt; lc) || (B[j] &lt;= C[k]))) A[i++] = B[j++]; if ((k &lt; lc) &amp;&amp; (!(j &lt; lb) || (C[k] &lt; B[j]))) A[i++] = C[k++]; &#125; delete [] B; //释放临时空间B&#125; // 归并后得到完整的有序向量 约定参与归并的子向量在原向量中总是前、后相邻的，故借助三个入口参数即可界定其范围[lo, mi)和[mi, hi)。另外，为保证归并向量所得的子向量能够原地保存以便继续参与更高层的归并，这里使用了临时数组B[]存放前一向量[lo, mi)的副本(习题【2-28】)。 归并时间 二路归并算法merge()的渐进时间成本，取决于其中循环迭代的总次数。 每经过一次迭代，B[i]和C[k]之间的小者都会被移出并接至A的末尾(习题【2-29】和习题【2-30】)。这意味，每经过一次迭代，总和s = j + k都会加一。 考察这一总和s在迭代过程中的变化。初始时，有s = 0 + 0 = 0;而在迭代期间，始终有: $s &lt; lb + lc = (mi - lo) + (hi - mi) = hi - lo$因此，迭代次数及所需时间均不超过$O(hi - mi) = O(n)$。 反之，按照算法的流程控制逻辑，无论子向量的内部元素组成及其相对大小如何，只有待到s = hi - lo时迭代方能终止。因此，该算法在最好情况下仍需$\Omega(n)$时间，概括而言应为$\Theta(n)$。 推广 二路归并只需线性时间的结论，并不限于相邻且等长的子向量。实际上，即便子向量在物理地址空间上并非前后衔接，且长度相差悬殊，该算法也依然可行且仅需线性时间。 更重要地，这一算法框架也可应用于列表——而且同样可以达到线性的时间效率。 排序时间 归并排序算法的时间复杂度采用递推方程分析法，为此首先将归并排序算法处理长度为n的向量所需时间记作$T(n)$。根据算法构思与流程，为对长度为n的向量归并排序，需递归地对长度各为n/2的两个子向量做归并排序，再花费线性时间做一次二路归并。如此，可得到如下递推关系： $T(n) = 2 \times T(n/2) + O(n)$ 另外，当子向量长度缩短到1时，递归即可终止并直接返回该向量。故有边界条件 $T(1) = O(1)$ 联立以上递推式，可以解得(习题【2-26】) $T(n) = O(nlogn)$ 也就是说，归并算法可在$O(nlogn)$时间内对长度为n的向量完成排序。因二路归并算法的效率稳定在$\Theta(n)$，故更准确地讲，归并排序算法的时间复杂度应为$\Theta(nlogn)$。]]></content>
      <categories>
        <category>计算机科学与技术</category>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[启动、中断、异常和系统调用]]></title>
    <url>%2F2019%2F03%2F17%2F%E5%90%AF%E5%8A%A8%E3%80%81%E4%B8%AD%E6%96%AD%E3%80%81%E5%BC%82%E5%B8%B8%E5%92%8C%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[内容摘要 启动 计算机结构概述 计算机内存和硬盘布局 系统启动流程 中断、异常和系统调用 背景(3.3) 中断、异常和系统调用相比较(3.3) 中断和异常处理机制(3.3) 系统调用的概念和实现(3.4) 程序调用与系统调用的不同之处(3.4) 开销(3.4) 系统调用示例 3.1 BIOS计算机体系结构概述 启动时计算机内存和磁盘布局CPU加电后会对里面寄存器做一个初始化到一个指定的状态，然后去执行第一条指令，第一条指令存储在内存中。内存会分为RAM随机访问存储和ROM只读存储两部分，系统的初始化代码存储在ROM中。系统CPU完成初始化后，它处于实模式下，在实模式下它的地址计算把段寄存器左移4位，然后加上它的当前指令指针，这两个加在一起作为当前访问第一条指令的位置，还有一条限制是说在加电的时候，它处于实模式，这个时候地址总线并不是像我们现在用到的通常系统是32位，它只有20位的地址可用即用的区域是2的20次方就是1M，所以放的区域就只能放在最底下1M里头的一小块。这块代码为了从硬盘上读数据，它必须提供相应的服务，如果没有这些服务，是没有办法访问到磁盘设备的，为了做到这件事情，在BIOS里头它需要提供这样的一些功能：(1)基本的输入输出：完成能够从磁盘上读数据，从键盘上读用户的输入并且可以在显示器上显示相应的输出。(2)系统的配置信息：由BIOS的设置来决定加电时是从硬盘启动、从网络启动还是说从光盘启动。依据这些设置执行它的启动程序，并且能从硬盘把加载程序和操作系统内容加载到系统当中来。具体过程： BIOS 初始化完成后，将加载程序从磁盘的引导扇区(这个引导扇区长度只有512字节，更长的它没有这个能力在BIOS程序，它不允许能读更多内容)加载到指定的位置(Ox7c00)； 跳转到其中的固定位置(CS:IP=0000:7c00)； 把控制权转到从磁盘上读进来的程序，这里是加载程序； 加载程序 将操作系统的代码和数据从硬盘加载到内存中； 跳转到操作系统的起始位置，把控制权交给操作系统，来继续执行操作系统功能； BIOS可以从磁盘读取加载程序，那么为什么不直接从BIOS里将操作系统的内核映像读取进来而通过加载程序再去读取呢？说明：由于磁盘是由文件系统的并且文件系统多种多样，不能限制磁盘只使用一种文件系统，而且又不能在BIOS上加上认识所有文件系统的代码。为了增加这种灵活性，在这里就有一个基本约定就是我不需要认识格式也能从里头读到读到第一块，读到这块后会用这块里的加载程序来识别磁盘上的文件系统，认识磁盘上的文件系统后就可以读到操作系统内核的镜像并把它加载到内存当中来。这整个过程就是用加载程序读到操作系统来，这个过程后再把相应的控制权转到读进来的操作系统内核上，之后操作系统就可以运行了。 总结一下BIOS最初存放在内存中的ROM部分，加载程序和操作系统则存放在磁盘中，BIOS首先从磁盘中读取加载程序放入内存中，然后通过内存中的加载程序将磁盘中存储的操作系统也读取到内存中，最终跳转到操作系统在内存中的起始地址，把控制权交给操作系统。 (3)开机自检和系统启动程序 BIOS系统调用 BIOS以中断调用的方式提供了基本的I/O功能 INT 10h:字符显示 INT 13h:磁盘扇区读写 INT 15h:检测内存大小 INT 16h:键盘输入 只能在x86实模式下访问，如果是在保护模式下上述功能无法使用 3.2 系统启动流程计算机启动流程之前所说的加电后去读BIOS，BIOS再去读你的加载程序，加载程序去读内核映像，这个实际上又可以细化下去，因为我们在加载程序的时候，在BIOS里头并不能直接去读加载程序(bootloader)。 最早系统里只有一个分区的时候可以直接在分区里找文件系统，然而现在大多数的计算机里头并非只有一个分区，可能会有几个分区，并且每个分区可能会装不同的系统，这时就需要在前边加上一个主引导记录，这个主引导记录的目的就是说明要从哪个文件系统内去读加载程序。有了主引导记录后就进到当前某个分区里面，分区里面又有一个分区的引导扇区，这个活动分区的引导扇区再来加载文件系统的加载程序。这个过程当中实际上我们就需要知道中间这几个部分的格式是什么样子的，如果不知道，那么写出来的程序最终存到磁盘上机器是不能够从里头认识的。 总结一下首先系统加电，BIOS初始化硬件，之后BIOS读取磁盘上最前边的主引导扇区代码(主引导记录)，由主引导记录得知我们知道接下来要进入哪个分区，进入分区后主引导记录读取活动分区的引导扇区代码，引导扇区再来读取文件系统内的加载程序，层层递进，类似栈的结构。 CPU初始化具体说来有这样的几个过程，首先CPU加电完成它的初始化到一个确定的状态去读第一条指令，我们需要知道CPU初始化之后它的代码段段寄存器和当前指令指针寄存器这两个寄存器的内容，算出它的第一条指令在内存当中的什么地方，这是它计算的依据。因为它是实模式，所以CS和IP都是16位的，CS左移4位后与IP相加算出当前访问的第一条指令的位置。并且BIOS存放在内存中最底下的1M位置，原因是实模式下地址总线是只有20位。CPU加电稳定后从0XFFFF0(CS:IP=0xf000:fff0)读第一条指令，第一条指令是跳转指令。 BIOS初始化过程BIOS除了从磁盘上读取加载程序，实际上还有很多事情要做。(1) 硬件自检POST：顾名思义硬件自检是为了检测出硬件的好坏。(2) 检查系统中内存和显卡等关键部件的是否存在和工作状态。(3) 查找并执行显卡等接口卡BIOS，进行设备初始化。因为这些关键性的接口卡里也有它自己的初始化程序。(4) 执行系统BIOS，进行系统检测，检测和配置系统中安装的即插即用设备(系统初始化)。比如我想从一个USB接口的光驱里启动系统，如何启动？在这个BIOS里的自检是能够做到系统的自检，检测并配置这些即插即用的设备。(5) 更新CMOS中的扩展系统配置数据ESCD。上述都做完了后就已经知道系统里连接了哪些硬件，在BIOS里有一个系统配置表(ESCD)，就是扩展系统配置数据。通过这个数据就可以知道当前系统里有些什么设备，并且这个数据会随着设备的改变而改变。(6) 按指定启动顺序从软盘、硬盘或光驱启动。第5步也做完后就将控制权转移到从外部读进来的数据里或读进来的代码里，而这就是按照我们在BIOS里指定的顺序，从软盘、硬盘或者光盘或者指定的其他设备上读进第一块扇区。 主引导记录MBR格式读进扇区后面临多个分区，这时候就需要主引导记录。主引导记录总共512字节，分为三部分：启动代码、硬盘分区表和结束标志字。 启动代码启动代码占主引导记录中的446字节，它的主要作用有两点： 检查分区表正确性。如果分区表是错误的，那么程序时无法正常加载的； 加载并跳转到磁盘上的引导程序； 硬盘分区表硬盘分区表则占64字节，硬盘分区表负责描述分区状态和位置，每个分区描述信息占16字节。 结束标志字结束标志字占剩余的2字节。所有的引导扇区都有一个结束标志，这个结束标是55AA。有了结束标后，它才认为这是一个合法的主引导记录。 分区引导扇区格式由主引导记录进入分区后同样需要面对分区引导扇区，分区引导扇区由4个部分组成： 跳转指令：跳转到启动代码。这条跳转指令与平台相关，CPU不同跳转指令不同(我猜是因为汇编语言分为Intel格式和AT&amp;T格式两种) 文件卷头：文件系统描述信息。 启动代码：跳转到加载程序。启动代码说明加载程序的位置，加载程序可以放在任意的地方只需启动代码标识出来即可。 结束标志：55AA，和主引导记录的结束标志字相同。 加载程序(bootloader)加载程序同样可以细化，主要分成三步： 从文件系统中读取启动配置信息。加载程序并非直接去加载内核，而是从文件系统中读一个启动配置文件(这时候加载程序是能够认识文件系统的格式的)，这个启动配置文件在不同的操作系统里是不一样的，比如Windows和Linux都有自己的格式，这样Windows和Linux都有自己的加载程序的格式。 可选的操作系统内核列表和加载参数。依据配置信息选择启动的参数，比如是正常启动，还是在安全模式下启动，更或者是在调试状态下启动系统，这些区别都可以读出来。 依据配置加载指定内核并跳转到内核执行。参数已经选择好后，配置信息导致加载程序在加载内核的时候内核会不一样，依据配置加载内核。 虽然整个过程的描述已经细化，但是介绍的仍然是很粗的。如果要想写出实际的程序，那么还需要知道CPU的手册、CPU加电时的状态，BIOS里的规范，第一条指令在磁盘中的位置和它的格式，内核编译时的一些相应信息。有很多需要考虑的因素，这种考虑的因素又有很多细节和实际的硬件环境或者说周围的情况密切相关，这时就需要制定一组相应的标准作为系统启动的规范。 系统启动规范系统启动规范主要分为BIOS和UEFI两种。 BIOSBIOS是现在广泛使用的在PC机上的启动流程标准。BIOS是主板上的一段程序，包括系统设置，自检程序和系统自启动程序，它可以完成系统的启动。BIOS从70年代后期最早出现，至今已有几十年的发展并发生很多变化，主要有BIOS-MBR、BIOS-GPT和PXE三种。之前提到的主引导记录BIOS-MBR实际上相当于最早的BIOS，它是从主板加电自检后进到磁盘上的唯一的一个分区上去加载它的引导记录，然而有了多分区磁盘后就需要选择从哪个分区启动，这时就在前面加上一个主引导记录来说明是选择了哪个分区进行启动。由前文介绍主引导扇区的格式可知，主引导记录里只能描述最多4个分区，每个占16个字节，因为启动代码和结束标志字已经将剩余的448字节全部占满，然而现在的计算机很多都会超过4个分区。为了解决这一问题出现了GPT(全局唯一标识分区表)，GPT可以在分区表里描述更多的分区结构，这样就不会有4个分区的限制了。BIOS-MBR和BIOS-GPT是BIOS的两个发展，PXE实际上是网络启动的一个标准，举个例子就是机器启动后想听过局域网或者其他的网络连接服务器，从服务器上下载内核镜像来执行，PXE就是这种启动的标准。总的来说BIOS可以有一些局部的修改来完善对后续的支持，但这种支持总是会受到前边的制约，比如说在主引导记录里为了支持多分区就在中间加成了磁盘的主引导巨鹿，然后再加上活动分区里的引导记录，多了两层但实际多的这两层意义并不是特别的必要。所以可以设计一种全新的规范来解决这一问题，这就是UEFI。 UEFIUEFI(统一可扩展固件接口)想达到的目的是在所有平台上提供一致的操作系统启动服务，为了做到这一点它从90年代开始推出它的第一个版本，直到现在都在不断的演变的过程中。 3.3 中断、异常和系统调用比较这节介绍了中断、异常和系统调用的作用，是为了解决什么问题，主要的应用场景。以及他们之间的区别和共同点，还介绍了中断、异常和系统调用的实现机制。 背景之前介绍过计算机启动后会加载操作系统的内核，然后将控制权交给操作系统内核，这一阶段是可以信任的。但在操作系统内核之上，实际还有很多的应用程序，没有办法做到对这些应用程序的完全的信任，然而这些应用程序要使用操作系统内核提供的服务，并且只有操作系统执行特短指令(具有特殊权限的指令，这类指令只用于操作系统或其他系统软件，一般不直接提供给用户使用)，这时就需要解决一个操作系统内核与外界打交道的问题，也就是说可以信任的内核必须对外界提供某种访问的接口。 同样在使用计算机的过程中我们除了跟应用程序打交道外，程序或计算机系统在运行过程中会有各种各样的问题，为了能够让计算机系统对外界作出适当的反映比如及时反映键盘的输入，需要提出中断机制，也就是当外设与系统有交互的时候需要如何处理。还有一种情况是使用应用程序的过程中出现了一些问题，这些问题是程序编写者事先没有预料到的，对于这种异常情况把它的控制权转交给操作系统，由操作系统来处理它，这就是应用程序执行中遇到意外交由异常来做处理。 系统调用则是为了解决用户程序如何来使用系统服务的问题。操作系统需要通过系统调用来提供一个接口，让应用程序既方便的使用内核提供的服务，又不至于用户的行为对内核的安全产生影响。提供服务的方式有多种可以通过内核提供服务，还可以使用函数库，这里需要作出判断。 为什么需要中断、异常和系统调用 在计算机运行中，内核是被信任的第三方 只有内核可以执行特权指令 方便应用程序 中断和异常希望解决的问题 当外设连接计算机时，会出现什么现象？ 当应用程序处理意想不到的行为时，会出现什么现象？ 系统调用希望解决的问题 用户应用程序时如何得到系统服务？ 系统调用和功能调用的不同之处是什么？ 内核的进入与退出从这个图中可以看到操作系统内核和外界打交道基本上就是中断、异常和系统调用这三个接口。 中断、异常和系统调用系统调用(System call)是应用程序主动向操作系统发出的服务请求。异常(Exception)则是非法指令或者其他原因导致的指令执行失败(如：内存出错)之后的处理请求。中断(hardware interrupt)是硬件设备对操作系统提出的处理请求。 中断、异常和系统调用的比较 源头 中断：外设 异常：应用程序意想不到的行为 系统调用：应用程序请求操作提供服务 响应方式 中断：异步 异常：同步。因为异常是与当前指令有关的，必须处理完当前纸条异常所产生指令所导致的问题才可以继续下去。 系统调用：异步或同步 处理机制 中断：持续，对用户应用程序是透明的 异常：杀死或者重新执行意想不到的应用程序指令。异常会处理当前所出现的问题。 系统调用：等待和持续。等待用户提出之后处理，等待然后再继续。 中断处理机制这节标题中的中断实际上可以理解为系统调用、中断和异常这三种情况的总称。 硬件处理 在CPU初始化时设置中断使能标志。也就是说在许可外界打扰CPU的执行之前CPU是不会对外界的任何中断请求发出响应 依据内部或外部事件设置中断标志 依据中断向量调用相应中断服务例程。 中断产生了后通常是一个电平的上升沿或者说是一个高电平，那CPU会记录下这间事情，也就是说会有一个中断标志表示出现了一个中断，然后这时候需要知道中断是由什么设备产生的，需要知道中断源的编号，这一部分是由硬件来做的。 软件 现场保护(编译器) 中断服务程序(服务例程) 清除中断标记(服务例程) 现场恢复(编译器) 中断嵌套 硬件中断服务例程可被打断 不同硬件中断源可能硬件中断处理时出现 硬件中断服务例程中需要临时禁止中断请求 中断请求会保持到CPU做出响应 异常服务例程可能被打断 异常服务例程执行时可能出现硬件中断 异常服务例程可嵌套 异常服务例程可能出现缺页 3.4 系统调用系统调用 操作系统服务的编程接口 通常由高级语言编写(C或者C++) 程序访问通常是通过高层次的API接口而不是直接进行系统调用。写程序的时候通常并不直接去使用系统调用而把系统调用封装到一个库里面，应用程序是访问这些库里的库函数来实现的。 不同的系统里用户使用的接口是不一样的，三种最常用的应用程序编程接口(API) Win32 API 用于 Windows POSIX API 用于POSIX-based systems(包括UNIX,LINUX,MAC OS X的所有版本) Java API用于JAVA虚拟机(JVM) 系统调用的实现 每个系统调用对应一个系统调用号 系统调用接口根据系统调用号来维护表的索引 系统调用接口调用内核态中的系统调用功能实现，并返回系统调用的状态和结果 用户不需要知道系统调用的实现 需要设置调用参数和获取返回结果 操作系统接口的细节大部分都隐藏在应用编程接口后 通过运行程序支持的库来管理 函数调用和系统调用的不同处调用一个函数需要把参数压到堆栈里面去，然后转到相应函数去执行，执行时候从堆栈里获取参数信息执行，返回的结果放在那里再返回回来，这样在上面的函数调用就知道相关的返回结果，然后利用这个结果继续往下执行。而对于系统调用来说，它由于内核是受保护的，而应用程序是它自己的区域，为了保护内核的实现，这里内核和用户态的应用程序之间使用不同的堆栈，所以在这里会有一个堆栈的切换，切换之后由于处于内核态，就可以使用特权指令，这些特权指令所导致的结果就是这时可以直接对设备进行控制，而这种操作在用户态是不可能进行的。 系统调用使用的是INT和IRET指令用于系统调用，函数调用使用的是CALL和RET指令，这四条指令在指令集是完全不同的。 系统调用 INT和IRET指令用于系统调用 系统调用时，堆栈切换和特权级的转换 函数调用 CALL和RET用于常规调用 常规调用时没有堆栈切换 中断、异常和系统调用的开销 超过函数调用。原因是有一个用户态到内核态的切换 开销： 引导机制 建立内核堆栈 验证参数 内核态映射到用户态的地址空间 更新页面映射权限 内核态独立地址空间 TLB]]></content>
      <categories>
        <category>计算机科学与技术</category>
        <category>操作系统</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中将字符串所表示的值进行int或float转换]]></title>
    <url>%2F2018%2F12%2F24%2FPython%E4%B8%AD%E5%B0%86%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%89%80%E8%A1%A8%E7%A4%BA%E7%9A%84%E5%80%BC%E8%BF%9B%E8%A1%8Cint%E6%88%96float%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[这是一个小技巧，在做编译原理课设的过程中需要我将通过单词扫描器得到的单词进行类型判断是int类型还是float类型并调用对应的类型转换函数int()和float()，然而我并有找到单独一个函数去做这个事情，于是通过使用几个函数组合解决了这个问题。 解决这个问题的思路是通过使用replace(&#39;.&#39;, &#39;&#39;)函数将字符串中的’.’替换为空，然后调用isdigit()判断替换后的字符串是否全由数字组成，如果是则排除是字符串的组合。然后再次调用isdigit()函数辨别字符串中是否存在&#39;.&#39;，如果有则说明是浮点数，否则为整数。 示例： 1234567891011121314var0 = '1234'var1 = '123.4'def convert(var): if var.replace('.', '').isdigit(): if var.isdigit(): return int(var) else: return float(var) else: return var print('var0:', convert(var0))print('var1:', convert(var1)) 输出结果为： 12('var0:', 1234)('var1:', 123.4)]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python动态生成变量名和exec函数及eval函数的用法]]></title>
    <url>%2F2018%2F12%2F21%2FPython%E5%8A%A8%E6%80%81%E7%94%9F%E6%88%90%E5%8F%98%E9%87%8F%E5%90%8D%E5%92%8Cexec%E5%87%BD%E6%95%B0%E5%8F%8Aeval%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[最近在做编译原理课程设计，在实现基于DAG的局部优化算法时需要生成很多变量且变量需要以n1、n2、n3····n100这种形式命名作为DAG结点的编码，使用其他静态编译语言据我了解只能在代码中手动写出这100个变量名，但是查阅资料发现Python能够实现动态生成变量名而不像静态语言一样笨拙。 解决动态生成变量名的问题有几种方法，类似locals函数、exec函数。其中我选择的是exec函数，选择的原因是这两个函数起先我都不了解，于是尝试写一些demo学习使用它们，然而locals函数好像在我的应用场景中并不适用又或者是由于我的使用方法不对导致的无法得到想要的结果，诸多原因使得我最终选择了exec函数来动态生成变量名。 单独使用exec函数其实并不能动态生成变量名，与format函数加以配合才能达到该目的。 exec函数这里首先介绍一下exec函数。exec函数是Python的built-in函数(内置函数)。exec函数的实际作用是动态执行Python代码。也就是说exec函数可以执行复杂的Python代码。 1exec(source, globals=None, locals=None, /) 参数说明： source：必选参数，表示需要被指定的Python代码。它必须是字符串或者code对象。如果source是一个字符串，该字符串会先被解析为一组Python语句，然后执行。如果source是code对象，那么它只是被简单的执行。 globals：可选参数，表示全局命名空间(存放全局变量)，如果被提供，则必须是一个字典对象。 locals：可选参数，表示局部命名空间(存放局部变量)，如果被提供，可以是任何映射对象。如果参数被忽略，那么它将会取与globals相同的值。 如果globals和locals都被忽略，那么它们将取exec函数被调用环境下的全局命名空间和局部命名空间。 返回值：exec函数的返回值永远为None。 示例：12345&gt;&gt;&gt; i = 2&gt;&gt;&gt; j = 3&gt;&gt;&gt; exec("ans = i + j")&gt;&gt;&gt; print("Answer is: ", ans)Answer is: 5 解释一下在上个例子中，ans变量并没有显式的定义，但仍然可以在print函数中调用。这是由于exec()语句执行了&quot;ans = i + j&quot;中的代码，定义了ans变量。 format函数str.format函数是一种格式化字符串的函数，它增强了字符串格式化的功能。 基本语法是通过{}和:来代替之前的%。format函数可以接受不限个参数，位置可以不按顺序。 示例：1234&gt;&gt;&gt;"&#123;&#125; &#123;&#125;".format("hello", "world") # 不设置指定位置，按默认顺序'hello world'&gt;&gt;&gt;"&#123;1&#125; &#123;0&#125; &#123;1&#125;".format("hello", "world") # 设置指定位置'world hello world' 同样可以设置参数：123456789101112131415#!/usr/bin/python# -*- coding: UTF-8 -*- &gt;&gt;&gt; print("网站名：&#123;name&#125;, 地址 &#123;url&#125;".format(name="菜鸟教程", url="www.runoob.com"))&gt;&gt;&gt; 网站名：菜鸟教程, 地址 www.runoob.com# 通过字典设置参数&gt;&gt;&gt; site = &#123;"name": "菜鸟教程", "url": "www.runoob.com"&#125;&gt;&gt;&gt; print("网站名：&#123;name&#125;, 地址 &#123;url&#125;".format(**site))&gt;&gt;&gt; 网站名：菜鸟教程, 地址 www.runoob.com # 通过列表索引设置参数&gt;&gt;&gt; my_list = ['菜鸟教程', 'www.runoob.com']&gt;&gt;&gt; print("网站名：&#123;0[0]&#125;, 地址 &#123;0[1]&#125;".format(my_list)) # "0" 是必须的&gt;&gt;&gt; 网站名：菜鸟教程, 地址 www.runoob.com 也可以向str.format()传入对象：12345678#!/usr/bin/python# -*- coding: UTF-8 -*- class AssignValue(object): def __init__(self, value): self.value = valuemy_value = AssignValue(6)print('value 为: &#123;0.value&#125;'.format(my_value)) # "0" 是可选的 输出结果为：1value 为: 6 菜鸟教程中还有一些数字格式化的具体教程，感兴趣的可以看一下。 动态生成变量名将上述介绍的exec函数和format函数结合起来就能够做到动态生成变量名。 示例：123456In [1]: for i in range(5): ...: exec('var&#123;&#125; = &#123;&#125;'.format(i, i)) ...:In [2]: print(var0, var1, var2, var3 ,var4)0 1 2 3 4 eval函数eval函数与exec函数有些相似但又有些不同exec，所以这里同时介绍eval函数，与exec函数对比记忆加深理解。eval函数同样能够做到动态执行代码，但是它所能够执行的代码相比exec函数有特殊的限定。 eval函数的实际作用是计算指定表达式的值。也就是说它要执行的Python代码只能是单个表达式(注意eval不支持任何形式的赋值操作)，而不能是复杂的代码逻辑。 1eval(source, globals=None, locals=None, /) 参数说明与exec函数的一样。 返回值：如果source是一个code对象，且创建该code对象时，complie函数的mode参数是exec，那么eval函数的返回值是None；否则，如果source是一个输出语句，如print()，则eval()的返回结果为None；否则，source表达式的结果就是eval()的返回值。 示例：123456789101112x = 10def func(): y = 20 #局部变量y a = eval("x+y") print("a:",a) #x没有就调用全局变量 b = eval("x+y",&#123;"x":1,"y":2&#125;) #定义局部变量，优先调用 print("b:",b) c = eval("x+y",&#123;"x":1,"y":2&#125;,&#123;"y":3,"z":4&#125;) print("c:",c) d = eval("print(x,y)") print("d:",d) #对于变量d，因为print()函数不是一个计算表达式，因此没有返回值func() 输出结果：12345a: 30b: 3c: 410 20d: None eval函数和exec函数的区别 eval函数只能计算单个表达式的值，而exec函数可以动态运行代码段； eval函数可以有返回值，而exec函数返回值永远为None； 参考资料 Python动态变量名定义与调用 - Pyerlife - 博客园 python中的exec()、eval()以及complie() - 明王不动心 - 博客园 Python format 格式化函数 | 菜鸟教程]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[《推荐系统实践》读书笔记总结]]></title>
    <url>%2F2018%2F12%2F04%2F%E3%80%8A%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[后记本书着重介绍了推荐系统的各种算法设计和系统设计的方法，并且利用一些公开的数据集离线评测了各种算法。对于无法通过离线评测知道算法性能的情况，本书引用了很多著名的用户调查实验来比较不同的算法。 但需要申明的一点是，本书的很多离线实验都是在一两个数据集上完成的，所以本书得到的所有结论都不是定论，可能换一个数据集就会得到完全相反的结论。这主要是因为不同网站中的用户行为有很大的差异，所以推荐系统很难有放之四海而皆准的结论。因此，需要在自己的数据集上重复本书介绍的实验和算法，再得到审核自己具体情况的结论。 2009年ACM推荐系统大会上Strand研究人员做的一个报告“推荐系统十堂课”，在这个报告中Strand的研究人员总结了他们设计推荐系统的经验，提出了10条在设计推荐系统中学习到的经验和教训。 确定你真的需要推荐系统。推荐系统只有在用户遇到信息过载时才必要。如果你的网站物品不太多，或者用户兴趣都比较单一，那么也许并不需要推荐系统。所以不要纠结于推荐系统这个词，不要为了做推荐系统而做推荐系统，而是应该从用户的角度出发，设计出能够真正帮助用户发现内容的系统，无论这个系统算法是否复杂，只要能够真正帮助用户，就是一个好的系统。 确定商业目标和用户满意度之间的关系。对用户好的推荐系统不代表商业上有用的推荐系统，因此要首先确定用户满意的推荐系统和商业上需求的差距。一般来说，有些时候用户满意和商业需求并不吻合。但是一般情况下，用户满意度总是符合企业的长期利益，因此这一条的主要观点是要平衡企业的长期利益和短期利益之间的关系。 选择合适的开发人员。一般来说，如果是一家大公司，应该雇用自己的开发人员来专门进行推荐系统的开发。 忘记冷启动的问题。不断地创新，互联网上有任何你想要的数据。只要用户喜欢你的产品，他们就会不断贡献新的数据。 平衡数据和算法之间的关系。使用正确的用户数据对推荐系统至关重要。对用户行为数据的深刻理解是设计好推荐系统的必要条件，因此分析数据是设计系统中最重要的部分。数据分析决定了如何设计模型，而算法只是决定了最终如何优化模型。 找到相关的物品很容易，但是何时以何种方式将它们展现给用户是很困难的。不要为了推荐而推荐。 不要浪费时间计算相似兴趣的用户，可以直接利用社会网络数据。 需要不断地提升算法的扩展性。 选择合适的用户反馈方式。 设计合理的评测系统，时刻关注推荐系统各方面的性能。 总结这本书很早之前就想看了而且很早之前就买了，然后可能由于当时看到这里面复杂的数学公式和算法望而生畏就没有读下去，只读了一点。最近不是很忙，加上心血来潮花了一周时间粗略地看了一遍并且整理了读书笔记。同时，这也是我第一次写读书笔记，笔记的很大部分都是摘抄书上内容，而另一部分则是将书上内容用我自己的语言加以概括。这么做的原因有两点：(1)第一次整理读书笔记不清楚该如何整理；(2)关于推荐系统方面的内容是我第一次了解，所以很多知识都是第一次听说，因此觉得书上的所有内容我都需要学习、整理。尽管这次我整理了书中几乎所有的公式，但是没有一个公式是我真正推导验证过的，只知皮毛。当然这么做也是有我的理由的，我觉得即使我这次推导了一遍公式，记忆很牢固但是如果长期不去使用、复习，那么忘记是迟早的事。 为了让自己心里不那么惭愧，我总结了通过这次整理读书笔记学到的阅读整理技巧，聊以自慰： 读技术性书籍不要奢求读一次便要全部掌握记牢，欲速则不达。读技术性书籍有好几种阅读方法，你可以尝试带有目的性的去读，当前你需要去了解哪部分知识便去读那部分知识，这样可以做当通过实际生活中的应用加深你对相应知识的理解，两全其美。当然，你也可以去读两三遍，第一遍读的时候知识粗略了解，能够做到如果遇到问题知道在书中哪部分寻找解答方法即可，这就可以算作第二遍去阅读。第三遍阅读则是你遇到的问题多得已经几乎让你将书中提到的算法全部实现过了，这时候你再去阅读一遍目的是将整个知识体系梳理一遍，因为这时候估计你已经能够做到遇到1马上知道1后面跟的是2了。这两种阅读方法无法比较好坏，只能说面对的情况不同，选择的阅读方法就不同。 读书笔记的整理也很相似，当你第一遍阅读的时候可以只在书上画出你觉得重要的部分。不要急于去整理，原因是当你第一次阅读某一领域的书籍时会遇见很多你不了解的知识，如果直接去整理摘抄的话，不说你会收获多少，时间成本就很大（我在整理这本书的读书笔记的时候就深刻意识到了这点，因为我可能只花一两个小时去阅读一章，但是会花掉我四五个小时去整理摘抄并且这个过程是十分枯燥无趣的，令人很难坚持完成），而且长时间不复习很容易会忘记，更令人难过的是你会认为自己将阅读这本书的时间算作是浪费掉的，这种挫败感至少对我来说是难以化解的，从而丧失了积极反馈，成就感荡然无存。真正该去整理的时间是在第二次复习的时候，因为当你结合你实际问题去阅读的时候，实际问题会给你提供一个角度，你会从这个角度看待这部分知识。同样你也会从这个角度去理解这部分知识，进而解决实际问题，这可能就是大佬说的每次阅读会学到不同的东西。 最后评价一下这本书。看到扉页上写到2012年6月第一版，距离现在已经六年多了。不难想象这本书所涉及到的机器学习的知识在当时可以算作是十分前沿的技术，因为当时还没有深度学习的提出，AI领域的爆发式发展，梯度下降等机器学习算法还没像现在这般耳熟能详。如果我能在那个年代读到这样一本书，那么我一定是最”前卫”的程序员。因此，我觉得这本书可以算作是推荐系统领域的经典入门必读书籍，这个称号当之无愧，国人能写出这种水平的书籍我感到无比自豪。书中引用很多论文并且介绍了这些论文中的算法，严谨细致，为对推荐领域更为感兴趣的读者提供了丰富的扩展阅读材料，并且介绍的众多算法无一不是当时最为流行的推荐系统算法，这一点从作者所引用论文的发表时间就可以看出。由浅入深，先介绍简单算法再一步步加以改进，使读者更加容易消化理解。同时书中也加入了作者自己的观点以及经验，干货十足。然而令人可惜地是本书没有第二版，书中介绍的Amazon和Twitter的一些例子在如今看来早已过时，国内也出现了以推荐系统为核心技术的独角兽公司例如今日头条等。 但瑕不掩瑜，我仍然以读到此书为我的一大幸事。]]></content>
      <categories>
        <category>计算机科学与技术</category>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（八）]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AB%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第8章 评分预测问题之前讨论的都是TopN推荐，但同样评分预测问题也是推荐系统研究的核心。评分预测问题就是如何通过已知的用户历史评分记录预测未知的用户评分记录。 本章主要讨论评分预测这一推荐领域的经典问题。因为这一问题的研究集中在学术界，所以本章的介绍也比较偏学术，相对前面各章会增加一些公式和理论的讨论。 8.1 离线实验方法评分预测问题基本都通过离线实验进行研究。在给定用户评分数据集后，研究人员会将数据集按照一定的方式分成训练集和测试集，然后根据测试集建立用户兴趣模型来预测测试集中的用户评分。对于测试集中的一对用户和物品$(u, i)$，用户$u$对物品$i$的真实评分$r_{ui}$，而推荐算法预测的用户$u$对物品$i$的评分为$\hat r_{ui}$，那么一般可以用均方根误差RMSE度量预测的精度：$$RMSE = \frac{\sqrt{\sum_{(u,i)\in T}(r_{ui} - \hat r_{ui})^2}}{\vert Test \vert}$$评分预测的目的就是找到最好的模型最小化测试集的RMSE。 关于如何划分训练集和测试集，如果是和时间无关的预测任务，可以以均匀分布随机划分数据集，即对每个用户，随机选择一些评分记录作为测试集，剩下的记录作为测试集。如果是和时间相关的任务，那么需要将用户的旧行为作为训练集，将用户的新行为作为测试集。Netflix通过如下方式划分数据集，首先将每个用户的评分记录按照从早到晚进行排序，然后将用户最后10%的评分记录作为测试集，前90%的评分记录作为训练集。 8.2 评分预测算法本节从简单到复杂地介绍具有代表性的算法，并给出它们在Netflix数据集上的效果。 8.2.1 平均值最简单的评分预测算法是利用平均值预测用户对物品的评分的。下面各节分别介绍各种不同的平均值。 1.全局平均值在平均值里最简单的是全局平均值。它的定义为训练集中所有评分记录的评分平均值：$$\mu = \frac{\sum_{(u,i) \in Train}r_{ui}}{\sum_{(u,i) \in Train }1}$$而最终的预测函数可以直接定义为：$$\hat r_{ui} = \mu$$ 2.用户评分平均值用户$u$的评分平均值$\bar r_u$定义为用户$u$在训练集中所有评分的平均值：$$\bar r_u = \frac{\sum_{i \in N(u)}r_{ui}}{\sum_{i \in N(u)}1}$$ 而最终的预测函数可以定义为：$$\hat r_{ui} = \bar r_{u}$$ 3.物品评分平均值物品$i$的评分平均值$\bar r_i$定义为物品$i$在训练集中接收的所有评分的平均值：$$\bar r_i = \frac{\sum_{u \in N(i)}r_{ui}}{\sum_{u \in N(i)}1}$$而最终的预测函数可以定义为：$$\hat r_{ui} = \bar r_i$$ 4.用户分类对物品分类的平均值(类类平均值)假设有两个分类函数，一个是用户分类函数$\phi$，一个是物品分类函数$\varphi$。$\phi(u)$定义了用户$u$所属的类，$\varphi(u)$定义了物品$i$所属的类。那么，我们可以利用训练集中同类用户对同类物品评分的平均值预测用户对物品的评分，即：$$\hat r_{ui} = \frac{\sum_{(v,j)\in Train, \phi(u)=\phi(v),\varphi(i)=\varphi(j)} r_{vj}}{\sum_{(v,j)\in Train, \phi(u)=\phi(v),\varphi(i)=\varphi(j)}1}$$前面提出的全局平均值，用户评分平均值和物品评分平均值都是类类平均值的一种特例。 如果定义$\phi(u)=0,\varphi(i)=0$，那么$\hat r_{ui}$就是全局平均值。 如果定义$\phi(u) = u,\varphi(i) = 0$，那么$\hat r_{ui}$就是用户评分平均值。 如果定义$\phi(u) = 0,\varphi(i) = i$，那么$\hat r_{ui}$就是物品评分平均值。 除了这3种特殊的平均值，在用户评分数据上还可以定义很多不同的分类函数。 用户和物品的平均分 对于一个用户，可以计算他的评分平均分。然后将所有用户按照评分平均分从小到大排序，并将用户按照平均分平均分成N类。物品也可以用同样的方式分类。 用户活跃度和物品流行度 对于一个用户，将他评分的物品数量定义为他的活跃度。得到用户活跃度之后，可以将用户通过活跃度从小到大排序，然后平均分为N类。物品的流行度定义为给物品评分的用户数目，物品也可以按照流行度均匀分成N类。 下面的Python代码给出了类类平均值的计算方法。 123456789101112131415def PredictAll(records, user_cluster, item_cluster): total = dict() count = dict() for r in records: if r.test != 0: continue gu = user_cluster.GetGroup(r.user) gi = item_cluster.GetGroup(r.item) basic.AddToMat(total, gu, gi, r.vote) basic.AddToMat(count, gu, gi, 1) for r in records: gu = user_cluster.GetGroup(r.user) gi = item_cluster.GetGroup(r.item) average = total[gu][gi] / (1.0 * count[gu][gi] + 1.0) r.predict = average 在这段代码中，user_cluster.GetGroup函数接收一个用户ID，然后根据一定的算法返回用户的类别。item_cluster.GetGroup函数接收一个物品的ID，然后根据一定的算法返回物品的类别。total[gu][gi]/count[gu][gi]记录了第gu类用户给第gi类物品评分的平均分。 上文提到，user_cluster和item_cluster有很多不同的定义方式，下面的Python代码给出了不同的user_cluster和item_cluster定义方式。其中，Cluster是基类，对于任何用户和物品，它的GetGroup函数都返回0，因此如果user_cluster和item_cluter都是Cluster类型，那么最终的预测函数就是全局平均值。IdCluster的GetGroup函数接收一个ID，会返回这个ID，那么如果user_cluster是Cluster类型，而item_cluster是IdCluster类型，那么最终的预测函数给出的就是物品平均值。在MovieLens数据集上利用不同平均值方法计算RMSE，实验结果表明对用户使用UserVoteCluster，对物品采用ItemVoteCluster，可以获得最小的RMSE。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697class Cluster: def __init__(self,records): self.group = dict() def GetGroup(self, i): return 0class IdCluster(Cluster): def __init__(self, records): Cluster.__init__(self, records) def GetGroup(self, i): return iclass UserActivityCluster(Cluster): def __init__(self, records): Cluster.__init__(self, records) activity = dict() for r in records: if r.test != 0: continue basic.AddToDict(activity, r.user, 1) k = 0 for user, n in sorted(activity.items(), \ key=itemgetter(1), reverse=False): c = int((k * 5) / (1.0 * len(activity))) self.group[user] = c k += 1 def GetGroup(self, uid): if uid not in self.group: return -1 else: return self.group[uid] class ItemPopularityCluster(Cluster): def __init__(self, records): Cluster.__init__(self, records) popularity = dict() for r in records: if r.test != 0: continue basic.AddToDict(popularity, r.item, 1) k = 0 for item, n in sorted(popularity.items(), \ key=itemgetter(1), reverse=False): c = int((k * 5) / (1.0 * len(popularity))) self.group[item] = c k += 1def GetGroup(self, item): if item not in self.group: return -1 else: return self.group[item]class UserVoteCluster(Cluster): def __init__(self, records): Cluster.__init__(self, records) vote = dict() count = dict() for r in records: if r.test != 0: continue basic.AddToDict(vote, r.user, r.vote) basic.AddToDict(count, r.user, 1) k = 0 for user, v in vote.items(): ave = v / (count[user] * 1.0) c = int(ave * 2) self.group[user] = c def GetGroup(self, uid): if uid not in self.group: return -1 else: return self.group[uid]class ItemVoteCluster(Cluster): def __init__(self, records): Cluster.__init__(self, records) vote = dict() count = dict() for r in records: if r.test != 0: continue basic.AddToDict(vote, r.item, r.vote) basic.AddToDict(count, r.item, 1) k = 0 for item, v in vote.items(): ave = v / (count[item] * 1.0) c = int(ave * 2) self.group[item] = c def GetGroup(self, item): if item not in self.group: return -1 else: return self.group[item] 8.2.2 基于邻域的方法 基于用户的邻域算法和基于物品的邻域算法都可以应用到评分预测中。基于用户的邻域算法认为预测一个用户对一个物品的评分，需要参考和这个用户兴趣相似的用户对该物品的评分，即：$$\hat r_{ui} = \bar r_{u} + \frac{\sum_{v \in S(u,K) \cap N(i)}w_{uv}(r_{vi} - \bar r_v)}{\sum_{v \in S(u,K) \cap N(i)}\vert w_{uv} \vert}$$$S(u,K)$是和用户$u$兴趣最相似的$K$个用户的集合，$N(i)$是对物品$i$评过分的用户集合，$r_{vi}$是用户$v$对物品$i$的评分，$\bar r_v$是用户$v$对他评过分的所有物品评分的平均值。用户之间的相似度$w_{uv}$可以通过皮尔逊系数计算：$$w_{uv} = \frac{\sum_{i \in I}(r_{ui}-\bar r_u)\cdot (r_{vi} - \bar r_v)}{\sqrt{\sum_{i \in I} (r_{ui} - \bar r_u)^2 \sum_{i \in I} (r_{vi} - \bar r_v)^2}}$$下面的Python代码实现了用户相似度的计算和最终的预测函数： 12345678910111213141516171819202122232425262728293031323334353637def UserSimilarity(records): item_users = dict() ave_vote = dict() activity = dict() for r in records: addToMat(item_users, r.item, r.user, r.value) addToVec(ave_vote, r.user, r.value) addToVec(activity, r.user, 1) ave_vote = &#123;x:y/activity[x] for x,y in ave_vote.items()&#125; nu = dict() W = dict() for i,ri in item_users.items(): for u,rui in ri.items(): addToVec(nu, u, (rui - ave_vote[u])*(rui - ave_vote[u])) for v,rvi in ri.items(): if u == v: continue addToMat(W, u, v, \ (rui - ave_vote[u])*(rvi - ave_vote[v])) for u in W: W[u] = &#123;x:y/math.sqrt(nu[x]*nu[u]) for x,y in W[u].items() return W def PredictAll(records, test, ave_vote, W, K): user_items = dict() for r in records: addToMat(user_items, r.user, r.item, r.value) for r in test: r.predict = 0 norm = 0 for v,wuv in sorted(W[r.user].items(), \ key=itemgetter(1), reverse=True)[0:K]: if r.item in user_items[v]: rvi = user_items[v][r.item] r.predict += wuv * (rvi - ave_vote[v]) norm += abs(wuv) if norm &gt; 0: r.predict /= norm r.predict += ave_vote[r.user] 基于物品的邻域算法在预测用户$u$对物品$i$的评分时，会参考用户u对和物品i相似的其他物品的评分，即：$$\hat r_{ui} = \bar r_i + \frac{\sum_{j \in S(u,K) \cap N(u)}w_{ij} (r_{uj} - \bar r_i)}{\sum_{j \in S(u,K) \cap N(u)} \vert w_{ij} \vert}$$$S(i,K)$是和$i$最相似的物品集合，$N(u)$是用户$u$评过分的物品集合，$w_{ij}$是物品之间的相似度，$\bar r_i$是物品$i$的平均分。对于如何计算物品的相似度，Badrul Sarwar等在论文(参见Badrul Sarwar、George Karypis、Joseph Konstan和John Riedl的“Item-based Collaborative Filtering Recommendation Algorithms”（ACM 2001 Article，2001）)里做了详细的研究，文章比较了3种主要的相似度。 第一种是普通的余弦相似度(cosine similarity):$$w_{ij} = \frac{\sum_{u \in U} r_{ui} \cdot r_{uj}}{\sqrt{\sum_{u \in U} r_{ui}^2 \sum_{u \in U} r_{uj}^2}}$$第二种是皮尔逊系数(pearson correlation):$$w_{ij} = \frac{\sum_{u \in U}(r_{ui}-\bar r_i)\cdot (r_{uj} - \bar r_j)}{\sqrt{\sum_{u \in U} (r_{ui} - \bar r_i)^2 \sum_{u \in U} (r_{uj} - \bar r_j)^2}}$$第三种是被Sarwar称为修正的余弦相似度(adjust cosine similarity):$$w_{ij} = \frac{\sum_{u \in U}(r_{ui}-\bar r_u)\cdot (r_{uj} - \bar r_u)}{\sqrt{\sum_{u \in U} (r_{ui} - \bar r_u)^2 \sum_{u \in U} (r_{uj} - \bar r_u)^2}}$$Sarwar利用MovieLens最小的数据集对3种相似度进行了对比 ，并将MAE作为评测指标。实验结果表明利用修正后的余弦相似度进行评分预测可以获得最优的MAE。不过需要说明的是，在一个数据集上的实验并不意味着在其他数据集上也能获得相同的结果。 8.2.3 隐语义模型与矩阵分解模型做机器学习和数据挖掘研究的人经常会看到下面的各种名词，即隐含类别模型(Latent Class Model)、隐语义模型(Latent Factor Model)、pLSA、LDA、Topic Model、Matrix Factorization、Factorized Model。 这些名词在本质上应该是同一种思想体系的不同扩展。在推荐系统领域，提的最多的就是潜语义模型和矩阵分解模型。这两个名词说的是一回事，就是如何通过降维的方法将评分矩阵补全。 用户的评分行为可以表示成一个评分矩阵$R$，其中$R[u][i]$就是用户$u$对物品$i$的评分。但是，用户不会对所有的物品评分， 所以这个矩阵里有很多元素都是空的， 这些空的元素称为缺失值(missing value)。因此，评分预测从某种意义上说就是填空，如果一个用户对一个物品没有评过分，那么推荐系统就要预测这个用户是否是否会对这个物品评分以及会评几分。 1.传统的SVD分解一个空的矩阵有很多种补全方法，选择其中一种对矩阵扰动最小的补全方法。什么是对矩阵扰动最小？就是补全后矩阵的特征值和补全之前矩阵的特征值相差不大，就算是扰动比较小。所以，最早的矩阵分解模型就是从数学上的SVD(奇异值分解)开始的(参见Daniel Billsus和Michael J. Pazzani的“Learning Collaborative Information Filters”（1998）)。给定$m$个用户和$n$个物品，和用户对物品的评分矩阵$\mathbb R^{m \times n}$。首先需要对评分矩阵中的缺失值进行简单地补全，比如用全局平均值，或者用户/物品平均值补全，得到补全后的矩阵$R’$。接着，可以用SVD分解将$R’$分解成如下形式：$$R’ = U^TSV$$其中$U \in \mathbb R^{k \times m}$，$V \in \mathbb R^{k \times m}$是两个正交矩阵，$S \in \mathbb R^{k \times k}$是对角阵，对角线上的每一个元素都是矩阵的奇异值。为了对$R’$进行降维，可以取最大的$f$个奇异值组成对角矩阵$S_f$，并且找到这$f$个奇异值中每个值在$U$、$V$矩阵中对应的行和列，得到$U_f$、$V_f$，从而可以得到一个降维后的评分矩阵：$$R_f’ = U^T_f S_f V_f$$其中，$R_(u, i )$就是用户$u$对物品$i$评分的预测值。 SVD分解是早期推荐系统研究常用的矩阵分解方法，不过该方法具有以下缺点，因此很难在实际系统中应用。 该方法首先需要用一个简单的方法补全稀疏评分矩阵。一般来说，推荐系统中的评分矩阵是非常稀疏的，一般都有95%以上的元素是缺失的。而一旦补全，评分矩阵就会变成一个稠密矩阵，从而使评分矩阵的存储需要非常大的空间，这种空间的需求在实际系统中是不可能接受的。 该方法依赖的SVD分解方法的计算复杂度很高，特别是在稠密的大规模矩阵上更是非常慢。 2.Simon Funk的SVD分解正是由于上面的两个缺点，SVD分解算法提出几年后在推荐系统领域都没有得到广泛的关注。直到2006年Netflix Prize开始后，Simon Funk在博客上公布了一个算法(称为Funk-SVD)(参见Simon Funk的博客，文章地址为http://sifter.org/~simon/journal/20061211.html )，一下子引爆了学术界对矩阵分解类方法的关注。而且，Simon Funk的博客也成为了很多学术论文经常引用的对象。 Simon Funk 提出的矩阵分解方法后来被 Netflix Prize 的冠军Koren称为Latent Factor Model(简称为LFM)。 第3章曾经简单介绍过LFM在TopN推荐中的应用，因此这里不再详细介绍这一方面背后的思想。从矩阵分解的角度说，如果将评分矩阵$R$分解为两个低维矩阵相乘：$$\hat R = P^TQ$$其中$P \in \mathbb R^{f \times m}$和$Q \in \mathbb R^{f \times n}$是两个降维后的矩阵。 那么，对于用户$u$对物品$i$的评分的预测值$\hat R(u,i) = \hat r_{ui}$，可以通过如下公式计算：$$\hat r_{ui} = \sum_f{p_{uf} q_{if}}$$其中$p_{uf} = P(u,f)$，$q_{if} = Q(i,f) $。那么，Simon Funk的思想很简单：可以直接通过训练集中的观察值利用最小化RMSE学习$P$、$Q$矩阵。 Simon Funk认为，既然用RMSE作为评测指标，那么如果能找到合适的$P$、$Q$来最小化训练集的预测误差，那么应该也能最小化测试集的预测误差。因此，Simon Funk定义损失函数为：$$C(p,q) = \sum_{(u,i) \in Train}(r_{ui} - \hat r_{ui})^2 = \sum_{(u,i) \in Train}(r_{ui} - \sum_{f = 1}^F p_{uf}q_{if})^2$$直接优化上面的损失函数可能会导致学习的过拟合， 因此还需要加入防止过拟合项$\lambda(\Vert p_u \Vert^2 + \Vert q_i \Vert^2)$，其中$\lambda$是正则化参数，从而得到：$$C(p,q) = \sum_{(u,i) \in Train}(r_{ui} - \sum_{f = 1}^F p_{uf}q_{if})^2 + \lambda(\Vert p_u \Vert^2 + \Vert q_i \Vert^2)$$要最小化上面的损失函数，可以利用随机梯度下降法(参见http://en.wikipedia.org/wiki/Stochastic_gradient_descent )。该算法是最优化理论里最基础的优化算法，它首先通过求参数的偏导数找到最速下降方向，然后通过迭代法不断地优化参数。下面介绍优化方法的数学推导。 上面定义的损失函数里有两组参数$p_{uf}$和$q_{if}$，最速下降法需要首先对它们分别求偏导数，可以得到：$$\frac{\partial C}{\partial p_{uf}} = -2q_{ik} + 2\lambda p_{uk}$$ $$\frac{\partial C}{\partial p_{if}} = -2p_{uk} + 2\lambda q_{ik}$$ 然后，根据随机梯度下降法，需要将参数沿着最速下降方向向前推进，因此可以得到如下递推公式：$$p_{uf} = p_{uf} + \alpha(q_{ik} - \lambda p_{uk}) \\q_{if} = q_{if} + \alpha(p_{uk} - \lambda q_{ik})$$其中，$\alpha$是学习速率(learning rate)，它的取值需要通过反复实验获得。 下面的代码实现了学习LFM模型时的迭代过程。在LearningLFM函数中，输入train是训练集中的用户评分记录，F是隐类的格式，n是迭代次数。 1234567891011def LearningLFM(train, F, n, alpha, lambda): [p,q] = InitLFM(train, F) for step in range(0, n): for u,i,rui in train.items(): pui = Predict(u, i, p, q) eui = rui - pui for f in range(0,F): p[u][k] += alpha * (q[i][k] * eui - lambda * p[u][k]) q[i][k] += alpha * (p[u][k] * eui - lambda * q[i][k]) alpha *= 0.9 return list(p, q) 如上面的代码所示，LearningLFM主要包括两步。(1)需要对P、Q矩阵进行初始化，(2)需要通过随机梯度下降法的迭代得到最终的$P$、$Q$矩阵。在迭代时，需要在每一步对学习参数$\alpha$进行衰减(alpha *= 0.9)，这是随机梯度下降法算法要求的，其目的是使算法尽快收敛。如果形象一点说就是，如果需要在一个区域找到极值，一开始可能需要大范围搜索，但随着搜索的进行，搜索范围会逐渐缩小。 初始化$P、Q$矩阵的方法很多，一般都是将这两个矩阵用随机数填充，但随机数的大小还是有讲究的，根据经验，随机数需要和$1/sqrt(F)$成正比。下面的代码实现了初始化功能。 123456789def InitLFM(train, F): p = dict() q = dict() for u, i, rui in train.items(): if u not in p: p[u] = [random.random()/math.sqrt(F) \ for x in range(0,F)] if i not in q: q[i] = [random.random()/math.sqrt(F) \ for x in range(0,F)] return list(p, q) 而预测用户$u$对物品$i$的评分可以通过如下代码实现： 12def Predict(u, i, p, q): return sum(p[u][f] * q[i][f] for f in range(0,len(p[u])) LFM提出之后获得了很大的成功，后来很多著名的模型都是通过对LFM修修补补获得的，下面的各节分别介绍一下改进LFM的各种方法。这些改进有些是对模型的改进，有些是将新的数据引入到模型当中。 3.加入偏置项后的LFM上节提出的LFM预测公式通过隐类将用户和物品联系在一起。但是，实际情况下，一个评分系统有些固有属性和用户物品无关，而用户也有些属性和物品无关，物品也有些属性和用户无关。因此， Netflix Prize中提出了另一种LFM，其预测公式如下：$$\hat r_{ui} = \mu + b_u + b_i + p_u^T \cdot q_i$$相比上节的LFM预测公式增加了3项$\mu$、$b_u$、$b_i$。本章将这个模型称为BiasSVD。新增三项的作用如下： $\mu$ 训练集中所有记录的评分的全局平均数。在不同网站中，因为网站定位和销售的物品不同，网站的整体评分分布也会显示出一些差异。比如有些网站中的用户就是喜欢打高分，而另一些网站的用户就是喜欢打低分。而全局平均数可以表示网站本身对用户评分的影响。 $b_u$ 用户偏置(user bias)项。这一项表示了用户的评分习惯中和物品没有关系的那种因素。有的用户对什么都喜欢打高分或者低分。 $b_i$ 物品偏置(item bias)项。这一项表示了物品接受的评分中和用户没有什么关系的因素。与用户偏置项同理。 增加的3个参数中，只有$b_u$、$b_i$是要通过机器学习训练出来的。同样可以求导，然后用梯度下降法求解这两个参数，只需对LearningLFM稍做修改，就可以支持BiasLFM模型： 12345678910111213def LearningBiasLFM(train, F, n, alpha, lambda, mu): [bu, bi, p,q] = InitLFM(train, F) for step in range(0, n): for u,i,rui in train.items(): pui = Predict(u, i, p, q, bu, bi, mu) eui = rui - pui bu[u] += alpha * (eui - lambda * bu[u]) bi[i] += alpha * (eui - lambda * bi[i]) for f in range(0,F): p[u][k] += alpha * (q[i][k] * eui - lambda * p[u][k]) q[i][k] += alpha * (p[u][k] * eui - lambda * q[i][k]) alpha *= 0.9 return list(bu, bi, p, q) 而$b_u$、$b_i$在一开始只要初始化成全0的向量。 123456789101112131415161718def InitBiasLFM(train, F): p = dict() q = dict() bu = dict() bi = dict() for u, i, rui in train.items(): bu[u] = 0 bi[i] = 0 if u not in p: p[u] = [random.random()/math.sqrt(F) for x in range(0,F)] if i not in q: q[i] = [random.random()/math.sqrt(F) for x in range(0,F)] return list(p, q)def Predict(u, i, p, q, bu, bi, mu): ret = mu + bu[u] + bi[i] ret += sum(p[u][f] * q[i][f] for f in range(0,len(p[u])) return ret 4.考虑邻域影响的LFM前面的LFM模型中并没有显式地考虑用户的历史行为对用户评分预测的影响。为此，Koren在Netflix Prize比赛中提出了一个模型(参见Yehuda Koren的“Factor in the Neighbors: Scalable and Accurate Collaborative Filtering”（ACM 2010 Article，2010）)，将用户历史评分的物品加入到了LFM模型中，Koren将该模型称为SVD++。 为了将基于邻域的方法设计成一个像LFM那样可以学习的模型，可以将ItemCF的预测算法改成如下形式：$$\hat r_{ui} = \frac{1}{\sqrt{\vert N(u) \vert}} \sum_{j \in N(u)}w_{ij}$$公式中的$w_{ij}$不再是根据ItemCF算法计算出的物品相似度矩阵，而是一个和P、Q一样的参数，它通过优化如下的损失函数进行优化：$$C(w) = \sum_{(u,i) \in Train}(r_{ui} - \sum_{j \in N(u)} w_{ij}r_{uj})^2 + \lambda w_{ij}^2$$这个模型有一个缺点，就是$w$将是一个比较稠密的矩阵，存储它需要比较大的空间。此外，如果有$n$个物品，那么该模型的参数个数就是$n^2$个，这个参数个数比较大容易造成结果的过拟合。因此，Koren提出用该对$w$矩阵也进行分解，将参数个数降低到$2 \times n \times F$个，模型如下：$$\hat r_{ui} = \frac{1}{\sqrt{\vert N(u) \vert}} \sum_{j \in N(u)}x_i^Ty_j = \frac{1}{\sqrt{\vert N(u) \vert}}x_i^T \sum_{j \in N(u)}y_j$$$x_i$、$y_j$是两个$F$维的向量。由此可见，该模型用$x_i^Ty_j$代替了$w_{ij}$，从而大大降低了参数的数量和存储空间。 再进一步，可以将前面的LFM和上面的模型相加，从而得到如下模型：$$\hat r_{ui} = \mu + b_u + b_i + p_u^T \cdot q_i + \frac{1}{\sqrt{\vert N(u) \vert}}x_i^T \sum_{j \in N(u)}y_j$$Koren又提出为了不增加太多参数造成过拟合，可以令$x=q$，从而得到最终的SVD++模型：$$\hat r_{ui} = \mu + b_u + b_i + q_i^T \cdot (p_u + \frac{1}{\sqrt{\vert N(u) \vert}} \sum_{j \in N(u)}y_j)$$通过将损失函数对各个参数求偏导数，也可以轻松推导出迭代公式。下面给出SVD++模型训练的实现代码，如下所示： 12345678910111213141516171819202122232425def LearningBiasLFM(train_ui, F, n, alpha, lambda, mu): [bu, bi, p, q, y] = InitLFM(train, F) z = dict() for step in range(0, n): for u,items in train_ui.items(): z[u] = p[u] ru = 1 / math.sqrt(1.0 * len(items)) for i,rui in items items(): for f in range(0,F): z[u][f] += y[i][f] * ru sum = [0 for i in range(0,F)] for i,rui in items items(): pui = Predict() eui = rui - pui bu[u] += alpha * (eui - lambda * bu[u]) bi[i] += alpha * (eui - lambda * bi[i]) for f in range(0,F): sum[k] += q[i][k] * eui * ru p[u][k] += alpha * (q[i][k] * eui - lambda * p[u][k]) q[i][k] += alpha * ((z[u][k] + p[u][k]) * eui - lambda * q[i][k]) for i,rui in items items(): for f in range(0,F): y[i][f] += alpha * (sum[f] - lambda * y[i][f]) alpha *= 0.9 return list(bu, bi, p, q) 8.2.4 加入时间信息利用时间信息的方法也主要分为两种，一种是将时间信息应用到基于邻域的模型中，另一种是将时间信息应用到矩阵分解模型中。 1.基于邻域的模型融合时间信息由于实际生活中用户数目太大，所以基于用户的邻域模型很少被使用，主要是因为存储用户相似度矩阵非常困难。因此，本节主要讨论如何将时间信息融合到基于物品的邻域模型中。 Netflix Prize 的参赛队伍 BigChaos在技术报告中提到了一种融入时间信息的基于邻域的模型，本节将这个模型称为TItemCF。该算法通过如下公式预测用户在某一个时刻会给物品什么评分：$$\hat r_{uit} = \frac{\sum_{j \in N(u) \cap S(i,K)}f(w_{ij}, \Delta t)r_{uj}}{\sum_{j \in N(u) \cap S(i,K)}f(w_{ij},\Delta t)}$$$\Delta t = t_{ui} - t_{uj}$是用户$u$对物品$i$和物品$j$评分的时间差，$w_{ij}$是物品$i$和$j$的相似度，$f(w_{ij}, \Delta t)$是一个考虑了时间衰减后的相似度函数，它的主要目的是提高用户最近的评分行为对推荐结果的影响，BigChaos在模型中采用了如下的$f$：$$f(w_{ij},\Delta t) = \sigma(\delta \cdot w_{ij} \cdot \text{exp}(\frac{-|\Delta t|}{\beta}) + \gamma) \\\sigma(x) = \frac{1}{1+ \text{exp}(-x)}$$$\sigma(x)$是sigmoid函数，它的目的是将相似度压缩到(0，1)区间中。从上面的定义可以发现，随着$\Delta t$增加，$f(w_{ij}, \Delta t)$会越来越小，也就是说用户很久之前的行为对预测用户当前评分的影响越来越小。 2.基于矩阵分解的模型融合时间信息在引入时间信息后，用户评分矩阵不再是一个二维矩阵，而是变成了一个三维矩阵。不过可以仿照二维矩阵的方式对三维矩阵进行分解(参见Liang Xiang和Qing Yang的“Time-Dependent Models in Collaborative Filtering Based Recommender S WI-IAT 09)。回顾之前的BiasSVD模型：$$\hat r_{ui} = \mu + b_u + b_i + p^T_u \cdot q_i$$$\mu$可以看做对二维矩阵的零维分解，$b_u$、$b_i$可以看做对二维矩阵的一维分解，而$p^T_u \cdot q_i$则看做对二维矩阵的二维分解。仿照这种分解，将用户-物品-时间三维矩阵如下分解：$$\hat r_{uit} = \mu + b_u +b_i + b_t+ p^T_u \cdot q_i + x^T_u \cdot y_t + s^T_i z_t + \sum_f g_{u,f} h_{i,f}l_{t,f}$$这里$b_t$建模了系统整体平均分随时间变化的效应，$x^T_u \cdot y_t$建模了用户平均分随时间变化的效应，$s^T_i z_t$建模了物品平均分随时间变化的效应，而$\sum_f g_{u,f} h_{i,f}l_{t,f}$建模了用户兴趣随时间影响的效应。这个模型也可以很容易地利用前面提出的随机梯度下降法进行训练。本章将这个模型记为TSVD。 Koren在SVD++模型的基础上也引入了时间效应(参见Yehuda Koren的“Collaborative Filtering with temporal dynamics”（ACM 2009 Article，2009）)，回顾一下SVD++模型：$$\hat r_{ui} = \mu + b_u + b_i + q_i^T \cdot (p_u + \frac{1}{\sqrt{\vert N(u) \vert}} \sum_{j \in N(u)}y_j)$$对这个模型做如下改进以融合时间信息：$$\hat r_{ui} = \mu + b_u(t) + b_i(t) + q_i^T \cdot (p_u(t) + \frac{1}{\sqrt{\vert N(u) \vert}} \sum_{j \in N(u)}y_j) \\b_u(t) = b_u + \alpha_u \cdot dev_u(t) + b_{ut} + b_{u,period(t)} \\dev_u(t) = sign(t - t_u) \cdot \vert t - t_u \vert^\beta \\b_i(t) = b_i + b_{it} + b_{i, period(t)}\\p_{uf}(t) = p_{uf} + p_{utf}$$这里$t_u$是用户所有评分的平均时间。$period(t)$考虑了季节效应，可以定义为时刻$t$所在的月份。该模型同样可以通过随机梯度下降法进行优化。 8.2.5 模型融合Netflix Prize的最终获胜队伍通过融合上百个模型的结果才取得了最终的成功。由此可见模型融合对提高评分预测的精度至关重要。本节讨论模型融合的两种不同技术。 1.模型级联融合假设已经有一个预测器$\hat r^{(k)}$，对于每个用户-物品对$(u,i)$都给出预测值，那么可以在这个预测器的基础上设计骗一个预测期$\hat r^{(k + 1)}$来最小化损失函数： $$C = \sum_{(u,i) \in Train}(r_{ui} - \hat r_{ui}^{(k)} - \hat r_{ui}^{(k+1)})$$由上面的描述可以发现，级联融合很像Adaboost算法。和Adaboost算法类似，该方法每次产生一个新模型，按照一定的参数加到旧模型上去，从而使训练集误差最小化。不同的是，这里每次生成新模型时并不对样本集采样，针对那些预测错的样本，而是每次都还是利用全样本集进行预测，但每次使用的模型都有区别。 一般来说，级联融合的方法都用于简单的预测器，比如前面提到的平均值预测器。下面的Python代码实现了利用平均值预测器进行级联融合的方法。 12345678910111213def Predict(train, test, alpha): total = dict() count = dict() for record in train: gu = GetUserGroup(record.user) gi = GetItemGroup(record.item) AddToMat(total, gu, gi, record.vote - record.predict) AddToMat(count, gu, gi, 1) for record in test: gu = GetUserGroup(record.user) gi = GetUserGroup(record.item) average = total[gu][gi] / (1.0 * count[gu][gi] + alpha) record.predict += average 通过在MovieLens数据集计算对平均值方法采用级联融合后的RMSE，可见即使是利用简单的算法进行级联融合，也能得到比较低的评分预测误差。 2.模型加权融合假设有$K$个不同的预测器${\hat r^{(1)}，\hat r^{(2)}，···，\hat r^{(K)}}，本节主要讨论如何将它们融合起来获得最低的预测误差。 最简单的融合算法就是线性融合，即最终的预测器$\hat r$是这$K$个预测器的线性加权：$$\hat r = \sum_{k = 1}^K \alpha_k \hat r^{(k)}$$一般来说，评分预测问题的解决需要在训练集上训练$K$个不同的预测器，然后在测试集上作出预测。但是，如果我们继续在训练集上融合$K$个预测器，得到线性加权系数，就会造成过拟合的问题。因此，在模型融合时一般采用如下方法。 假设数据集已经被分为了训练集A和测试集B，那么首先需要将训练集A按照相同的分割方法分为A1和A2，其中A2的生成方法和B的生成方法一致，且大小相似。 在A1上训练$K$个不同的预测器，在A2上作出预测。因为我们知道A2上的真实评分值，所以可以在A2上利用最小二乘法计算出线性融合系数$\alpha_k$。 在A上训练$K$个不同的预测器，在B上作出预测，并且将这$K$个预测器在B上的预测结果按照已经得到的线性融合系数加权融合，以得到最终的预测结果。 除了线性融合，还有很多复杂的融合方法，比如利用人工神经网络的融合算法。其实，模型融合问题就是一个典型的回归问题，因此所有的回归算法都可以用于模型融合。 8.2.6 Netflix Prize的相关实验结果Netflix Prize比赛的３年时间里，很多研究人员在同一个数据集上重复实验了前面几节提到的各种算法。本节引用他们的实验结果对比各个算法的性能。Netflix Prize采用RMSE评测预测准确度，因此本节的评测指标也是RMSE，具体见表8-4。]]></content>
      <categories>
        <category>计算机科学与技术</category>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（七）]]></title>
    <url>%2F2018%2F11%2F30%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第7章 推荐系统实例前面几章介绍了各种各样的数据和基于这些数据的推荐算法。在实际系统中，前面几章提到的数据大都存在，因此如何设计一个真实的推荐系统处理不同的数据，根据不同的数据设计算法，并将这些算法融合到一个系统当中是本章讨论的主要问题。 本章首先介绍推荐系统的外围架构，然后介绍推荐系统的架构，并对架构中每个模块的设计进行深入讨论。 7.1 外围架构这一节主要讨论推荐系统是如何和网站的其他系统接口的。 UI系统负责给用户展示网页并和用户交互。网站会通过日志系统将用户在UI上的各种各样的行为记录到用户行为日志中。日志可能存储在内存缓存里，也可能存储在数据库中，也可能存储在文件系统中。而推荐系统通过分析用户的行为日志，给用户生成推荐列表，最终展示到网站的界面上。因此可以发现，推荐系统要发挥强大的作用，除了推荐系统本身，主要还依赖于两个条件——界面展示和用户行为数据。 目前流行的推荐系统界面存在一些共性： 通过一定方式展示物品，主要包括物品的标题、缩略图和介绍等。 很多推荐界面都提供了推荐理由，理由可以增加用户对推荐结果的信任度。 推荐界面还需要提供一些按钮让用户对推荐结果进行反馈，这样才能让推荐算法不断改 善用户的个性化推荐体验。 在设计推荐界面时，可以综合考虑其他网站的设计并结合自己网站的特点。 数据收集和存储从产生行为的用户角度看，有些行为是只有注册用户才能产生的，而有些行为是所有用户都可以产生的。从规模上看，浏览网页、搜索记录的规模都很大，因为这种行为所有用户都能产生，而且平均每个用户都会产生很多这些行为。购买、收藏行为规模中等，因为只有注册用户才能产生这种行为，但购买行为又是电商网站的主要行为，所以它们相对于评论来说规模更大，但相对于网页浏览行为来说规模要小得多，最后剩下的行为是注册用户里的一小部分人才有的，所以规模不会很大。同样有些行为需要实时存取，而有些并不需要。 按照前面数据的规模和是否需要实时存取，不同的行为数据将被存储在不同的媒介中。一般来说，需要实时存取的数据存储在数据库和缓存中，而大规模的非实时地存取数据存储在分布式文件系统（如HDFS）中。 数据能否实时存取在推荐系统中非常重要，因为推荐系统的实时性主要依赖于能否实时拿到用户的新行为。只有快速拿到大量用户的新行为，推荐系统才能够实时地适应用户当前的需求，给用户进行实时推荐。 7.2 推荐系统架构推荐系统联系用户和物品的方式主要有3种，在第4章开头部分介绍过，分别是： 基于用户的推荐算法 基于物品的推荐算法 基于特征的推荐算法 其中上述三种都可以将其抽象为基于特征的推荐算法，因为用户喜欢的物品可以算是用户特征，同样与用户兴趣相似的其他用户也是一种用户特征。然后根据抽象设计一种基于特征的推荐系统架构。当用户到来之后，推荐系统需要为用户生成特征，然后对每个特征找到和特征相关的物品，从而最终生成用户的推荐列表。因而，推荐系统的核心任务就被拆解成两部分，一个是如何为给定用户生成特征，另一个是如何根据特征找到物品。 用户特征种类很多，主要包括如下几类： 人口统计学特征 用户行为特征 用户的话题特征 可以根据用户的历史行为利用话题模型(topic model)将电视剧和电影聚合成不同的话题，并且计算出每个用户对什么话题感兴趣。 同时推荐系统的推荐任务也有很多种，如果要在一个系统中把上面提到的各种特征和任务都统筹考虑，那么系统将会非常复杂，而且很难通过配置文件方便地配置不同特征和任务的权重。因此，推荐系统需要由多个推荐引擎组成，每个推荐引擎负责一类特征和一种任务，而推荐系统的任务只是将推荐引擎的结果按照一定权重或者优先级合并、排序然后返回。 这样做有两个好处： 可以方便地增加/删除引擎，控制不同引擎对推荐结果的影响。对于绝大多数需求，只需要通过不同的引擎组合实现。 可以实现推荐引擎级别的用户反馈。每一个推荐引擎其实代表了一种推荐策略，而不同的用户可能喜欢不同的推荐策略。可以将每一种策略都设计成一个推荐引擎，然后通过分析用户对推荐结果的反馈了解用户比较喜欢哪些引擎推荐出来的结果，从而对不同的用户给出不同的引擎组合权重。 将推荐系统拆分成不同推荐引擎后，如何设计一个推荐引擎变成了推荐系统设计的核心部分。下一节讨论推荐引擎的设计方法。 7.3 推荐引擎的架构推荐系统架构主要包括3部分： 该部分负责(1)从数据库或者缓存中拿到用户行为数据，通过(2)分析不同行为，(3)生成当前用户的特征向量。不过如果是使用非行为特征，就不需要使用行为提取和分析模块了。该模块的输出是用户特征向量。 该部分负责将用户的特征向量通过特征-物品相关矩阵转化为初始推荐物品列表。 该部分负责对初始的推荐列表进行过滤、排名等处理，从而生成最终的推荐结果。 下节对各个不同的部分分别详细解释。 7.3.1 生成用户特征向量一般来说，用户的特征包括两种，一种是用户的注册信息中可以提取出来的，另一种特征主要是从用户的行为中计算出来的，本节着重讨论如何生成特征。 一个特征向量由特征以及特征的权重组成，在利用用户行为计算特征向量时需要考虑以下因素。 用户行为的种类 不同行为的影响不同，大多时候很难确定什么行为更加重要，一般的标准就是用户付出代价越大的行为权重越高。 用户行为产生的时间 距离现在越近的行为权重越高。 用户行为的次数 用户对同一个物品的同一种行为发生的次数也反映了用户对物品的兴趣，行为次数多的物品对应的特征权重越高。 物品的热门程度 用户对热门物品的行为不能够反映用户的兴趣，而冷门物品则可以能够反映。推荐引擎在生成用户特征时会加重不热门物品对应的特征的权重。 7.3.2 特征—物品相关推荐在得到用户的特征向量后，可以根据离线相关表得到初始的物品推荐列表。离线相关表可以存储在MySQL中。对于每个特征，我们可以在相关表中存储和它最相关的N个物品的ID。 在线使用的特征—物品相关表一般都不止一张。因为可能使用了不同的推荐算法。总之，对于一个推荐引擎可以在配置文件中配置很多相关表以及它们的权重，而在线服务在启动时会将这些相关表按照配置的权重相加，然后将最终的相关表保存在内存中，而在给用户进行推荐时，用的已经是加权后的相关表了。 特征—物品相关推荐模块还可以接受一个候选物品集合。候选物品集合的目的是保证推荐结果只包含候选物品集合中的物品。对推荐物品的范围进行限定。 书中对为什么不在过滤模块中将候选集合外的电视剧过滤掉，而要在相关推荐模块中处理候选物品列表作出了解释，不过我没有看明白，有机会再看一次这部分。 特征—物品相关推荐模块除了给用户返回物品推荐列表，还需要给推荐列表中的每个推荐结果产生一个解释列表，表明这个物品是因为哪些特征推荐出来的。下面的代码给出了相关推荐模块的大体工作流程。 1234567def RecommendationCore(features, related_table): ret = dict() for fid, fweight in features.items() for item, sim in related_table[fid].items(): ret[item].weight += sim * fweight ret[item].reason[fid] = sim * fweight return ret 7.3.3 过滤模块在得到初步的推荐列表后，需要先按照产品需求对结果进行过滤，过滤掉不符合要求的物品，然后再把推荐列表展现给用户。 一般来说，过滤模块会过滤掉以下物品： 用户已经产生过行为物品 为了保证结果的新颖性 候选物品以外的物品 候选物品集合一般有两个来源，一个是产品需求。另一个来源是用户自己的选择，过滤掉不满足用户所选条件的物品。 7.3.4 排名模块对推荐列表进行排名可以更好地提升用户满意度，一般排名模块需要包括很多不同的子模块，下面对不同的模块分别加以介绍。 1.新颖性排名新颖性排名模块的目的是给用户尽量推荐他们不知道的、长尾中的物品。虽然前面的过滤模块已经过滤掉了用户曾经有过行为的物品，保证了一定程度的新颖性，但是用户在当前网站对某个物品没有行为并不代表用户不知道这个物品。 要准确了解用户是否已经知道某个物品是非常困难的，因此只能通过某种近似的方式知道，比如使用如下公式对推荐结果中热门的物品进行降权。$$p_{ui} = \frac{p_{ui}}{\log{(1 + \alpha \cdot popularity(i))}}$$不过，要实现推荐结果的新颖性，仅仅在最后对热门物品进行降权是不够的，而应在推荐引擎的各个部分考虑新颖性问题。 本章提到推荐系统架构主要是基于物品的推荐算法的，因此回顾一下基于物品的推荐算法的基本公式：$$p_{ui} = \sum_{j \in N(u) \cap S(i,K)} w_{ji} r_{uj}$$在上述公式中$j$是联系用户和推荐物品的特征。最终$p_{ui}$的大小主要取决于两个参数——$w_{ji}$和$r_{uj}$。其中，$r_{uj}$在通过用户行为生成用户特征向量时计算，而$w_{ji}$是离线计算的物品相似度。如果要提高推荐结果的新颖性，在计算这两个数时都要考虑新颖性。与上面同理对$r_{uj}$和$w_{ji}$进行降权。$$r_{uj} = \frac{r_{uj}}{\log(1+\alpha \cdot popularity(j))}$$ $$w_{ji} = \frac{w_{ji}}{\log(1+\alpha \cdot popularity(i))} (popularity(i) &gt; popularity(j))$$ 此外，也可以引入内容相似度矩阵，因为内容相似度矩阵中和每个物品相似的物品都不是很热门，所以引入内容相似度矩阵也能够提高最终推荐结果的新颖度。 2.多样性增加多样性可以让推荐结果覆盖尽可能多的用户兴趣。这里需要指出的是提高多样性并不是时时刻刻都很好。 第一种提高多样性的方法是将推荐结果按照某种物品的内容属性分成几类，然后在每个类中都选择该类中排名最高的物品组合成最终的推荐列表。这种方法的好处是比较简单直观，但这种方法也有严重的缺点。首先，选择什么样的内容属性进行分类对结果的影响很大。其次，就算选择了某种类别，但物品是否属于某个类别是编辑确定的，并不一定能够得到用户的公认。 第二种提高推荐结果多样性的方法是控制不同推荐结果的推荐理由出现的次数。本章提出的推荐系统对于每个推荐出来的物品都有一个推荐理由，这个推荐理由一般是产生推荐结果的重要特征。那么，要提高推荐结果的多样性，就需要让推荐结果尽量来自不同的特征，具有不同的推荐理由，而不是所有的推荐结果都对应一个理由。 下面的代码根据推荐理由增加推荐结果的多样性，这里输入的recommendations是按照权重从大到小排序的，程序中每次拿出一个推荐结果，如果这个结果已经被用过了，就会对推荐结果的权重除以2降权（这里具体除以几可以在实际应用中自己调整），最终将推荐结果重新按照权重从大到小排序。 1234567def ReasonDiversity(recommendations): reasons = set() for i in recommendations: if i.reason in reasons: i.weight /= 2 reasons.add(i.reason) recommendations = sortByWeight(recommendations) 3.时间多样性时间多样性主要是为了保证用户不要每天来推荐系统都看到同样的推荐结果。在第5章已经提到，提高推荐系统的时间多样性要从两个地方着手。首先要保证推荐系统的实时性，在用户有新行为时实时调整推荐结果以满足用户最近的需求。这一点，在本章的推荐系统设计中已经考虑到了。如果用户有实时行为发生，那么行为提取和分析模块就能实时拿到行为数据并转化为新的特征，然后经过特征-物品相关模块转换成和新特征最相关的物品，因而推荐列表中就立即反应了用户最新行为的影响。提高推荐结果多样性的第二个方面是要在用户没有新的行为时，也要保证推荐结果每天都有变化。要实现这一点，只能通过如下方式。 记录用户每次登陆推荐系统看到的推荐结果。 将这些结果发回日志系统。这种数据不需要实时存储，只要能保证小于一天的延时就足够了。 在用户登录时拿到用户昨天及之前看过的推荐结果列表，从当前推荐结果中将用户已经看到的推荐结果降权。 4.用户反馈排名模块最重要的部分就是用户反馈模块。用户反馈模块主要通过分析用户之前和推荐结果的交互日志，预测用户会对什么样的推荐结果比较感兴趣。 如果推荐系统的目标是提高用户对推荐结果的点击率，那么可以利用点击模型(click model)预测用户是否会点击推荐结果。点击模型在很多领域得到了广泛应用，比如搜索结果的点击预测(参见论文“A dynamic bayesian network click model for web search ranking”，作者为Olivier Chapelle和Ya Zhang)、 搜索广告的点击预测(参见论文“Online learning from click data for sponsored search”，作者为Massimiliano Ciaramita、Vanessa Murdock和Vassilis Plachouras )、上下文广告的点击预测(参见论文“Contextual advertising by combining relevance with click feedback”，作者为Deepayan chakrabarti、Deepak Agarwal和Vanja Josifovski。)。点击预测的主要问题是预测用户看到某个推荐结果时是否会点击。那么要进行点击率预测，首先需要提取特征。在推荐系统的点击率预测中可以用如下特征预测用户$u$会不会点击物品$i$： 用户$u$相关的特征，比如年龄、性别、活跃程度、之前有没有点击行为； 物品$i$相关的特征，比如流行度，平均分，内容属性； 物品$i$在推荐列表中的位置。用户的点击和用户界面的设计有很高的相关性，因此物品$i$在推荐列表中的位置对预测用户是否点击很重要； 用户之前是否点击过和推荐物品$i$具有同样推荐解释的其他推荐结果； 用户之前是否点击过和推荐物品$i$来自同样推荐引擎的其他推荐结果。 点击模型需要离线计算好，在线将模型加载到内存中。为了提高在线预测的效率，一般只可以使用线性模型。 7.4 扩展阅读关于推荐系统架构方面的文章很多，不过详细介绍架构的技术报告不多。知名公司亚马逊和Netflix等都只给出了一些简单的线索。本章提到的推荐系统架构主要是基于本书作者在Hulu工作时使用的架构抽象发挥出来的，对于Hulu架构感兴趣的读者可以参考Hulu的技术博客(参见http://tech.hulu.com/blog/2011/09/19/recommendation-system/ )。MyMedia(参见http://mymediaproject.codeplex.com/ )是一个比较著名的开源推荐系统架构。它是由欧洲研究人员开发的一个推荐系统开源框架。该框架同时支持评分预测和TopN推荐，全面支持各种数据和各种算法，对该项目感兴趣的用户可以访问该项目的网站http://www.mymediaproject.org/default.aspx 。本章提出的推荐系统架构基本上是从基于物品的推荐算法衍生出来的，因此本章的架构并不适合用来解决社会化推荐问题。如果要了解社会化推荐方面的架构，可以参考Twitter公开的一些文档。]]></content>
      <categories>
        <category>计算机科学与技术</category>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（六）]]></title>
    <url>%2F2018%2F11%2F29%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第6章 利用社交网络数据美国著名的第三方调查机构尼尔森调查了影响用户相信某个推荐的因素(参见“Global Advertising Consumers Trust Real Friends and Virtual Strangers the Most”，http://blog.nielsen.com/nielsen-wire/consumer/global-advertising-consumers-trust-real-friends-and-virtual-strangers-the-most/ )。书中这部分有关于这次调查的简略介绍。实验证明了好友的推荐对于增加用户对推荐结果的信任度非常重要，并且该实验也从侧面说明了社交网络在推荐系统中可能具有重要的作用。 本章详细讨论了如何利用社交网络数据给用户进行个性化推荐。本章不仅讨论如何利用社交网络给用户推荐物品，而且将讨论如何利用社交网络给用户推荐好友。 6.1 获取社交网络数据的途径6.1.1 电子邮件谷歌在2010年的KDD会议上发表了一篇文章(参见Maayan Roth、Assaf Ben-David、David Deutscher、Guy Flysher、Ilan Horn、Ari Leichtberg、Naty Leiser、Yossi Matias、Ron Merom的“Suggesting Friends Using the Implicit Social Graph”（ACM 2010 Article，2010）)，其中就研究了如何通过Gmail系统中、一些不违反隐私协议的数据预测用户之间的社交关系，以便给用户推荐好友的问题。 其次，如果能够获得用户的邮箱，也可以通过邮箱后缀得到一定的社交关系信息。 6.1.2 用户注册信息用户注册时输入的信息也是一种隐性社交网络数据，可以用来分析。 6.1.3 用户的位置数据可以通过得到的IP地址，GPS数据作为用户位置信息，进而分析出用户的同事、邻居等关系。 6.1.4 讨论和讨论组类似于豆瓣上的小组。兴趣相近的人可能会加入一些相同的小组。 6.1.5 即时聊天工具通过即时聊天工具上的联系人列表和分组信息，知道用户的社交网络关系，并且能够通过统计用户之间聊天的频繁程度，度量出用户之间的熟悉程度。但与电子邮件一样，存在隐私问题。 6.1.6 社交网络上述各种获取用户社交关系的途径，要么就是因为隐私问题很难获取，要么就是虽然容易获取，但却都是隐性社交关系数据，很难推断出用户之间的显性社交关系。但以Facebook和Twitter为代表的新一代社交网络突破了这个瓶颈。 社交网站的另一个好处是自然地减轻了信息过载问题。在社交网站中，我们可以通过好友给自己过滤信息。比如，我们只关注那些和我们兴趣相似的好友，只阅读他们分享的信息，因此可以避免阅读很多和自己无关的信息。个性化推荐系统可以利用社交网站公开的用户社交网络和行为数据，辅助用户更好地完成信息过滤的任务，更好地找到和自己兴趣相似的好友，更快地找到自己感兴趣的内容。 1.社会图谱和兴趣图谱Facebook和Twitter作为社交网站中的两个代表，它们其实代表了不同的社交网络结构。在Facebook里，人们的好友一般都是自己在现实社会中认识的人(参见“Friends &amp; Frenemies: Why We Add and Remove Facebook Friends”，地址为http://blog.nielsen.com/nielsenwire/online_mobile/friends-frenemies-why-we-add-and-remove-facebook-friends/ ，尼尔森的这个报告表明82%的用户会因为在现实社会中认识而在Facebook中加好友。)，并且Facebook中的好友关系是需要双方确认的。在Twitter里，人们的好友往往都是现实中自己不认识的， 而只是出于对对方言论的兴趣而建立好友关系， 好友关系也是单向的关注关系。 以Facebook为代表的社交网络称为社交图谱(social graph)，而以Twitter为代表的社交网络称为兴趣图谱(interest graph)。 关于这两种社交网络的分类早在19世纪就被社会学家研究过。19世纪，德国社会学家斐迪南·滕尼斯（Ferdinand Tönnies）认为社会群体分为两种，一种是通过人们之间的共同兴趣和信念形成的，他将这种社会群体称为Gemeinschaft，而Gemeinschaft这个词后来被翻译成英语就是community，即汉语中的社区。另一种社会群体则是由于人们之间的亲属关系，工作关系而形成的，他称之为Gesellschaft，英文翻译为society，即汉语中的“社会”。因此，斐迪南·滕尼斯说的Gemeinschaft就是兴趣图谱，而Gesellschaft就是社会图谱。 但是，每个社会化网站都不是单纯的社交图谱或者兴趣图谱。 6.2 社交网络数据简介可以用图定义社交网络并表示用户之间的关系。用图$G(V,E,w)$定义一个社交网络，其中$V$是顶点集合，每个顶点代表一个用户，$E$是边集合，如果用户$v_a$和$v_b$有社交网络关系，那么就有一条边$e(v_a , v_b)$连接这两个用户，而$w(v_a , v_b)$定义了边的权重。业界有两种著名的社交网络。一种以Facebook为代表，它的朋友关系是需要双向确认的，因此用无向边连接有社交网络关系的用户。另一种以Twitter为代表，它的朋友关系是单向的，因此用有向边代表这种社交网络上的用户关系。 此外，对图$G$中的用户顶点$u$，定义$out(u)$为顶点$u$指向的顶点集合（如果套用微博中的术语，$out(u)$就是用户$u$关注的用户集合），定义$in(u)$为指向顶点$u$的顶点集合（也就是关注用户$u$的用户集合）。那么，在Facebook这种无向社交网络中显然有$out(u)$=$in(u)$。 一般来说，有3种不同的社交网络数据。 双向确认的社交网络数据 以Facebook为代表的社交网络。用户A和B之间形成好友关系需要通过双方的确认。此种社交网络一般可以通过无向图表示。 单向关注的社交网络数据 以Twitter为代表的社交网络。用户A可以关注用户B而不需要得到用户B的允许。此种社交网络一般可以通过有向图表示。 基于社区的社交网络数据 以豆瓣小组为代表的社交网络。用户之间没有明确的关系，但这种社交网络数据办函了用户属于不同社区的数据。 社交网络数据中的长尾分布该节利用了Slashdot的社交网络数据集(数据集来自Stanford Large Network Dataset Collection，参见http://snap.stanford.edu/data/ )统计了用户入度(in degree)和出度(out degree)的分布，得到了两个结论： 用户的入度近似长尾分布，说明在一个社交网络中影响力大的用户总是占少数。 用户的出度同样近似长尾分布，说明在一个社交网络中，关注很多人的用户占少数，而绝大多数用户只关注很少的人。 6.3 基于社交网络的推荐社会化推荐之所以受到很多网站的重视，是缘于如下优点。 好友推荐可以增加推荐的信任度 好友往往是用户最信任的。用户往往不一定信任计算机的智能，但会信任好朋友的推荐。 社交网络可以解决冷启动问题 当新用户使用社交网络账号登录网站时，网站可以从社交网站中获取用户的好友列表，然后给用户推荐好友在网站上喜欢的物品。 社会化推荐同样拥有缺点，其中最主要的就是很多时候并不一定能提高推荐算法的离线精度（准确率和召回率）。特别是在基于社交图谱数据的推荐系统中，因为用户的好友关系不是基于共同兴趣产生的，所以用户好友的兴趣往往和用户的兴趣并不一致。举个例子就是我们和父母在社交网络上虽然是好友，但兴趣差别很大。 2010年，ACM推荐系统大会的一个讨论组CAMRa曾经举办过一个关于社交网络的推荐系统比赛(参见http://www.dai-labor.de/camra2010/ )。该比赛希望参赛者能够利用用户之间的好友关系给用户推荐电影，并且利用准确率相关的指标评测参赛者的推荐算法。对社会化推荐感兴趣的读者可以关注一下该会议的相关论文。 6.3.1 基于邻域的社会化推荐算法如果给定一个社交网络和一份用户行为数据集。其中社交网络定义了用户之间的好友关系，而用户行为数据集定义了不同用户的历史行为和兴趣数据。那么最简单算法是给用户推荐好友喜欢的物品集合。即用户$u$对物品$i$的兴趣$p_{ui}$可以通过如下公式计算。$$p_{ui} = \sum_{v \in \text{out(u)}} r_{vi}$$$\text{out(u)}$是用户$u$的好友集合，如果用户$v$喜欢物品$i$，则$r_{vi} =1$，否则$r_{vi} = 0$。同时由于不同的好友和用户$u$的熟悉程度和兴趣相似度也是不同的。因此，应该在推荐算法中考虑好友和用户的熟悉程度以及兴趣相似度：$$p_{ui} = \sum_{v \in \text{out(u)}} w_{uv}r_{vi}$$$w_{uv}$由两部分相似度构成，一部分是用户$u$和用户$v$的熟悉程度，另一部分是用户$u$和用户$v$的兴趣相似度。用户$u$和用户$v$的熟悉程度(familiarity)描述了用户$u$和用户$v$在现实社会中的熟悉程度。一般来说，用户更加相信自己熟悉的好友的推荐，因此我们需要考虑用户之间的熟悉度。熟悉度可以用用户之间的共同好友比例来度量。也就是说如果用户$u$和用户$v$很熟悉，那么一般来说他们应该有很多共同的好友。$$familiarity(u,v) = \frac{\vert out(u) \cap out(v) \vert}{\vert out(u) \cup out(v) \vert}$$除了熟悉程度，还需要考虑用户之间的兴趣相似度，而兴趣相似度可以通过和UserCF类似的方法度量，即如果两个用户喜欢的物品集合重合度很高，两个用户的兴趣相似度很高。$$similarity(u,v) = \frac{N(u) \cap N(v)}{N(u) \cup N(v)}$$其中$N(u)$是用户$u$喜欢的物品集合。 下面的代码实现社会化推荐的逻辑。在代码中，familiarity存储了每个用户最熟悉的$K$个好友和他们的熟悉程度，similarity存储了和每个用户兴趣最相关的$K$好友和他们的兴趣相似度。train记录了每个用户的行为记录，其中train[u]记录了用户$u$喜欢的物品列表。 12345678910111213141516def Recommend(uid, familiarity, similarity, train): rank = dict() interacted_items = train[uid] for fid,fw in familiarity[uid]: for item,pw in train[fid]: # if user has already know the item # do not recommend it if item in interacted_items: continue addToDict(rank, item, fw * pw) for vid,sw in similarity[uid]: for item,pw in train[vid]: if item in interacted_items: continue addToDict(rank, item, sw * pw) return rank 6.3.2 基于图的社会化推荐算法图模型的优点是可以将各种数据和关系都表示到图上去。在社交网站中存在两种关系，一种是用户对物品的兴趣关系，一种是用户之间的社交网络关系。本节主要讨论如何将这两种关系建立到图模型中，从而实现对用户的个性化推荐。 用户的社交网络可以表示为社交网络图，用户对物品的行为可以表示为用户物品二分图，而这两种图可以结合成一个图。该图上有用户顶点和物品顶点两种顶点。如果用户$u$对物品$i$产生过行为，那么两个节点之间就有边相连。如果用户$u$和用户$v$是好友，那么也会有一条边连接这两个用户。 在定义完图中的顶点和边后，需要定义边的权重。其中用户和用户之间边的权重可以定义为用户之间相似度的$\alpha$倍（包括熟悉程度和兴趣相似度），而用户和物品之间的权重可以定义为用户对物品喜欢程度的$\beta$倍。$\alpha$和$\beta$需要根据应用的需求确定。如果希望用户好友的行为对推荐结果产生比较大的影响，那么就可以选择比较大的$\alpha$。相反，如果希望用户的历史行为对推荐结果产生比较大的影响，就可以选择比较大的。 在定义完图中的顶点、边和边的权重后，就可以利用前面几章提到的PersonalRank图排序算法给每个用户生成推荐结果。 在社交网络中，除了常见的、用户和用户之间直接的社交网络关系，还有一种关系，即两个用户属于同一个社群。Quan Yuan等详细研究了这两种社交网络关系(参见Quan Yuan、Li Chen和Shiwan Zhao的“Factorization vs. regularization: fusing heterogeneous social relationships in top-n recommendation”（ACM 2011 Article，2011）)，他们将第一种社交网络关系称为friendship，而将第二种社交网络关系称为membership。如果要在前面提到的基于邻域的社会化推荐算法中考虑membership的社交关系，可以利用两个用户加入的社区重合度计算用户 相似度，然后给用户推荐和他相似的用户喜欢的物品。但是，如果利用图模型则更为容易，可以加入一种节点表示社群，而如果用户属于某一社群，图中就有一条边联系用户对应的节点和社群对应的节点。建立图模型后，就可以通过前面提到的基于图的推荐算法(例如PersonalRank)给用户推荐物品。 6.3.3 实际系统中的社会化推荐算法6.3.1节提出的基于邻域的社会化推荐算法看似简单，但在实际系统中却是很难操作的，这主要是因为该算法需要拿到用户所有好友的历史行为数据，而这一操作在实际系统中是比较重的操作。因为大型网站中用户数目非常庞大，用户的历史行为记录也非常庞大，所以不太可能将用户的所有行为都缓存在内存中，只能在数据库前做一个热数据的缓存。 由于ItemCF算法只需要当前用户的历史行为数据和物品的相关表就可以生成推荐结果。对于物品数不是很多的网站，可以将物品相关表缓存在内存中，因此ItemCF算法很容易在实际环境下实现。 可以从几个方面改进基于邻域的社会化推荐算法，让它能够具有比较快的响应时间。改进的方向有两种，一种是治标不治本的方法。简单地说，就是可以做两处截断。第一处截断在拿用户好友集合时只拿出用户相似度最高的N个好友而非全部，从而给该用户做推荐时可以只查询N次用户历史行为接口。此外，在查询每个用户的历史行为时，只返回用户最近1个月的行为，这样就可以在用户行为缓存中缓存更多用户的历史行为数据，从而加快查询用户历史行为接口的速度。此外，还可以牺牲一定的实时性，降低缓存中用户行为列表过期的频率。 而第二种解决方案需要重新设计数据库。Twitter的解决方案是给每个用户维护一个消息队列(message queue)，当一个用户发表一条微博时，所有关注他的用户的消息队列中都会加入这条微博。这个实现的优点是用户获取信息墙时可以直接读消息队列，所以终端用户的读操作很快。不过这个实现也有缺点，当一个用户发表了一条微博，就会触发很多写操作，因为要更新所有关注他的用户的消息队列，特别是当一个人被很多人关注时，就会有大量的写操作。Twitter通过大量的缓存解决了这一问题。具体的细节可以参考InfoQ对Twitter架构的介绍(参见“Twitter, an Evolving Architecture”，地址为http://www.infoq.com/news/2009/06/Twitter-Architecture )。 如果将Twitter的架构搬到社会化推荐系统中，就可以按照如下方式设计系统： 首先，为每个用户维护一个消息队列，用于存储他的推荐列表； 当一个用户喜欢一个物品时，就将（物品ID、用户ID和时间）这条记录写入关注该用户的推荐列表消息队列中； 当用户访问推荐系统时，读出他的推荐列表消息队列，对于这个消息队列中的每个物品，重新计算该物品的权重。计算权重时需要考虑物品在队列中出现的次数，物品对应的用户和当前用户的熟悉程度、物品的时间戳。同时，计算出每个物品被哪些好友喜欢过，用这些好友作为物品的推荐解释。 6.3.4 社会化推荐系统和协同过滤推荐系统关于社会化推荐系统的离线评测可以参考Georg Groh和Christian Ehmig的工作成果(参见“Recommendations in Taste Related Domains: Collaborative Filtering vs. Social Filtering”，2007年)。不过社会化推荐系统的效果往往很难通过离线实验评测，因为社会化推荐的优势不在于增加预测准确度，而是在于通过用户的好友增加用户对推荐结果的信任度，从而让用户单击那些很冷门的推荐结果。此外，很多社交网站（特别是基于社交图谱的社交网站）中具有好友关系的用户并不一定有相似的兴趣。因此，利用好友关系有时并不能增加离线评测的准确率和召回率。因此，很多研究人员利用用户调查和在线实验的方式评测社会化推荐系统。 对社会化推荐系统进行用户调查的代表性工作成果是Rashmi Sinha和Kirsten Swearingen对比社会化推荐系统和协同过滤推荐系统的论文(参见“Comparing Recommendations Made by Online Systems and Friends”，2001年 )。这一节简单介绍了他们的工作方法和结果，详细见书。 6.3.5 信息流推荐信息墙已经是个性化的，但里面仍夹杂了很多垃圾信息。因此，信息流的个性化推荐要解决的问题就是如何进一步帮助用户从信息墙上挑选有用的信息。 目前最流行的信息流推荐算法是Facebook的EdgeRank，该算法综合考虑了信息流中每个会话的时间、长度与用户兴趣的相似度。EdgeRank算法比较神秘，没有相关的论文，不过TechCrunch曾经公开过它的主要思想(参见“EdgeRank: The Secret Sauce That Makes Facebook’s News Feed Tick”， 地址为http://techcrunch.com/2010/04/22/facebook-edgerank/ )。Facebook将其他用户对当前用户信息流中的会话产生过行为的行为称为edge，而一条会话的权重定义为： $$\sum_{\text{edge} \ e}u_e w_e d_e$$ $u_e$指产生行为的用户和当前用户的相似度，这里的相似度主要是在社交网络图中的熟悉度； $w_e$指行为的权重，这里的行为包括创建、评论、like(喜欢)、打标签等，不同的行为有不同的权重。 $d_e$指时间衰减参数，越早的行为对权重的影响越低。 从上面的描述中可以得出如下结论：如果一个会话被你熟悉的好友最近产生过重要的行为，它就会有比较高的权重。 不过，EdgeRank算法的个性化因素仅仅是好友的熟悉度，它并没有考虑帖子内容和用户兴趣的相似度。所以EdgeRank仅仅考虑了“我”周围用户的社会化兴趣，而没有重视“我”个人的个性化兴趣。为此，GroupLens的研究人员Jilin Chen深入研究了信息流推荐中社会兴趣和个性化兴趣之间的关系。 (参见Jilin Chen、Rowan Nairn和Ed H. Chi的“Speak Little and Well: Recommending Conversations in Online Social Streams”（ACM 2011 Article, 2011）)他们的排名算法考虑了如下因素。 会话的长度 越长的会话包括越多的信息。 话题相关性 度量了会话中主要话题和用户兴趣之间的相关性。这里Jilin Chen用了简单的TF-IDF建立用户历史兴趣的关键词向量和当前会话的关键词向量，然后用这两个向量的相似度度量话题相关性。 用户熟悉程度 主要度量了会话中涉及的用户（比如会话的创建者、讨论者等）和当前用户的熟悉程度。对于如何度量用户的熟悉程度下一节将详细介绍。计算熟悉度的主要思想是考虑用户之间的共同好友数等。 为了验证算法的性能，Jilin Chen同样也设计了一个用户调查。首先，他通过问卷将用户分成两种类型。第一种类型的用户使用Twitter的目的是寻找信息，也就是说他们将Twitter看做一种信息源和新闻媒体。而第二种用户使用Twitter的目的是了解好友的最新动态以及和好朋友聊天。然后，他让参试者对如下5种算法的推荐结果给出1~5分的评分，其中1分表示不喜欢，5分表示最喜欢。 Random 给用户随机推荐会话 Length 给用户推荐比较长的会话 Topic 给用户推荐和他兴趣相关的会话。 Tie 给用户推荐和他熟悉的好友参与的会话。 Topic+Tie 综合考虑会话和用户的兴趣相关度以及用户好友参与会话的程度。 通过收集用户反馈，Jilin Chen发现对于所有用户不同算法的平均得分是：Topic+Tie &gt; Tie &gt; Topic &gt; Length &gt; Random而对于主要目的是寻找信息的用户，不同算法的得分是：Topic+Tie ≥ Topic &gt; Length &gt; Tie &gt; Random对于主要目的是交友的用户，不同算法的得分是：Topic+Tie &gt; Tie &gt; Topic &gt; Length &gt; Random 实验结果说明，综合考虑用户的社会兴趣和个人兴趣对于提高用户满意度是有帮助的。因此，当我们在一个社交网站中设计推荐系统时，可以综合考虑这两个因素，找到最合适的融合参数来融合用户的社会兴趣和个人兴趣，从而给用户提供最令他们满意的推荐结果。 6.4 给用户推荐好友好友推荐系统的目的是根据用户现有的好友、 用户的行为记录给用户推荐新的好友，从而增加整个社交网络的稠密程度和社交网站用户的活跃度。 好友推荐算法在社交网络上被称为链接预测(link prediction)。关于链接预测算法研究的代表文章是Jon Kleinberg的“Link Prediction in Social Network”。该文对各种用户好友关系的预测方法进行了系统地研究和对比。本节介绍其中一些比较直观和简单的算法。 6.4.1 基于内容的匹配给用户推荐和他们有相似内容属性的用户作为好友。 常用属性如下： 用户人口统计学属性，包括年龄、性别、职业、毕业学校和工作单位等。 用户的兴趣，包括用户喜欢的物品和发布过的言论等。 用户的位置信息，包括用户的住址、IP地址和邮编等。 利用内容信息计算用户的相似度和前面介绍的利用内容信息计算物品的相似度类似。 6.4.2 基于共同兴趣的好友推荐在Twitter和微博为代表的以兴趣图谱为主的社交网络中，用户往往不关心对于一个人是否在现实社会中认识，而只关心是否和他们有共同的兴趣爱好。因此，在这种网站中需要给用户推荐和他有共同兴趣的其他用户作为好友。 在第3章介绍基于用户的协同过滤算法(UserCF)时已经详细介绍了如何计算用户之间的兴趣相似度，其主要思想就是如果用户喜欢相同的物品，则说明他们具有相似的兴趣。 此外，也可以根据用户在社交网络中的发言提取用户的兴趣标签，来计算用户的兴趣相似度。关于如何分析用户发言的内容、提取文本的关键词、计算文本的相似度，可以参考第4章。 6.4.3 基于社交网络图的好友推荐最简单的好友推荐算法是给用户推荐好友的好友。 下面介绍3中基于社交网络的好友推荐算法。对于用户$u$和用户$v$，可以用他们共同好友比例计算他们的相似度：$$w_{out}(u,v) = \frac{\vert out(u) \cap out(v) \vert}{\sqrt {\vert out(u) \vert \vert out(v) \vert}}$$ 下面的代码实现了这种相似度： 1234567891011def FriendSuggestion(user, G, GT): suggestions = dict() friends = G[user] for fid in G[user]: for ffid in GT[fid]: if ffid in friends: continue if ffid not in suggestions: suggestions[ffid] = 0 suggestions[ffid] += 1 suggestions = &#123;x: y / math.sqrt(len(G[user]) * len(G[x]) for x,y in suggestions&#125; $w_{out}(u,v)$公式中$out(u)$是在社交网络图中用户$u$指向的其他好友的集合。同理$in(u)$是在社交网络图中指向用户$u$的用户的集合。在无向社交网络图中，$out(u)$和$in(u)$是相同的集合。但在有向社交网络中，两个集合就不同了，因此可以通过$in(u)$定义另一种相似度：$$w_{in}(u,v) = \frac{\vert in(u) \cap in(v) \vert}{\sqrt{\vert in(u) \vert \vert in(v) \vert}}$$ 12345678910def FriendSuggestion(user, G, GT): suggestions = dict() for fid in GT[user]: for ffid in G[fid]: if ffid in friends: continue if ffid not in suggestions: suggestions[ffid] = 0 suggestions[ffid] += 1 suggestions = &#123;x: y / math.sqrt(len(GT[user]) * len(GT[x]) for x,y in suggestions&#125; 这两种相似度的定义有着不同的含义，用微博中的关注来解释这两种相似度。如果用户$u$关注了用户$v$，那么$v$就属于$out(u)$，而$u$就属于$in(v)$。因此，$w_{out} (u , v )$越大表示用户$u$和$v$关注的用户集合重合度越大，而$w_{in }(u, v) $越大表示关注用户$u$和关注用户$v$的用户的集合重合度越大。 前面两种相似度都是对称的，也就是也就是$w_{in} (u, v) = w_{in} (v, u )$，$w_{out} (u , v ) = w_{out} (v, u ) $。同时，我们还可以定义第三种有向的相似度：$$w_{out,in}(u,v) = \frac{\vert out(u) \cap in(v) \vert}{out(u)}$$这个相似度的含义是用户$u$关注的用户中，有多大比例也关注了用户v。但是，这个相似度有一个缺点，就是在该相似度的定义下所有人都和名人有很大的相似度。这是因为这个相似度在分母的部分没有考虑$|in(v)|$的大小。因此，可以用如下公式改进上面的相似度：$$w_{out,in}’(u,v) = \frac{\vert out(u) \cap in(v) \vert}{\sqrt{\vert out(u) \vert \vert in(v) \vert}}$$ 123456789def FriendSuggestion(user, G, GT): suggestions = dict() for fid in GT[user]: for ffid in G[fid]: if ffid in friends: continue if ffid not in suggestions: suggestions[ffid] = 0 suggestions[ffid] += 1 suggestions = &#123;x: y / math.sqrt(len(GT[user]) * len(GT[x]) for x,y in suggestions&#125; 前面讨论的这些相似度都是基于一些简单计算公式给出的。这些相似度的计算无论时间复杂度还是空间复杂度都不是很高，非常适合在线应用使用。 离线实验本节通过一些离线实验评测本节提出的几种相似度，评测哪种相似度能更好地预测用户之间的好友关系。实验详情见书。最终的结论是在实际系统中没有哪一种相似度公式绝对合适，只有在自己的数据集上对不不同的算法，才能找到最适合自己数据集的好友推荐算法。 6.4.4 基于用户调查的好友推荐算法对比对于前面3节提出的几种不同的好友推荐算法，上一节提到的GroupLen的Jilin Chen也进行了研究。他通过用户调查对比了不同算法的用户满意度(参见Jilin Chen、Werner Geyer、Casey Dugan Michael Muller、Ido Guy的“‘Make New Friends, but Keep the Old’ ——Recommending People on Social Networking Site”（CHI 2009）)。实验介绍和结果见书。 6.5 扩展阅读社交网络分析的研究已经有很悠久的历史了。其中关于社交网络最让人耳熟能详的结论就是六度原理。六度原理讲的是社会中任意两个人都可以通过不超过6个人的路径相互认识，如果转化为图的术语，就是社交网络图的直径为6。不过喜欢刨根问底的读者一定好奇六度原理的正确性。六度原理在均匀随机图上已经得到了完美证明，对此感兴趣的读者可以参考Random Graph一书。很多对社交网络的研究都是基于随机图理论的，因此深入研究社交网络必须掌握随机图理论的相关知识。 社交网络研究中有两个最著名的问题。第一个是如何度量人的重要性，也就是社交网络顶点的中心度(centrality)，第二个问题是如何度量社交网络中人和人之间的关系，也就是链接预测。这两个问题的研究都有着深刻的实际意义，因此得到了业界和学术界的广泛关注。对这两个问题感兴趣的读者可以参考社交网络分析方面的书(比如（Social Network Analysis: Methods and Applications）和（Social Network Analysis: A Handbook）)。 对于基于社交网络的推荐算法，因为数据集的限制，最早的研究都是基于Epinion的用户信任网络的。Ma Hao在Epinion数据集上提出了很多基于矩阵分解的社会化推荐算法用来解决评分预测问题(参见Hao Ma、Haixuan Yang、Michael R. Lyu和Irwin King的“SoRec: Social Recommendation Using Probabilistic Matrix Factorization”（ACM 2008 Article , 2008）)，其主要思想是在矩阵分解模型中加入正则化项，让具有社交关系的用户的隐语义向量具有比较高的相似度。 ACM推荐系统大会在2010年曾经举办过一个社会化推荐比赛(即CAMRa201: Challenge on Context-aware Movie Recommendation )，该比赛将社交网络看做一种上下文，希望参赛者能够利用社交网络信息提高推荐系统的性能。关注社交化推荐的读者可以关注一下该比赛最后发出的论文集。]]></content>
      <categories>
        <category>计算机科学与技术</category>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（五）]]></title>
    <url>%2F2018%2F11%2F28%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第5章 利用上下文信息上下文信息对于提高推荐系统的各项评测指标是十分重要的，因此不能忽略上下文信息。准确了解用户的上下文信息(context)，并将该信息应用于推荐算法是设计好的推荐系统的关键步骤。关于上下文推荐的研究， 可以参考Alexander Tuzhilin(个人主页为http://people.stern.nyu.edu/atuzhili/ )教授的一篇综述“Context Aware Recommender Systems”。 本章主要讨论了时间上下文，并简单介绍一下地点上下文，讨论如何将时间信息和地点信息建模到推荐算法中，从而让推荐系统能够准确预测用户在某个特定时刻及特定地点的兴趣。本章仍然研究TopN推荐，即如何给用户生成一个长度为$N$的推荐列表，而该列表包含了用户在某一时刻或者某个地方最可能喜欢的物品。 5.1 时间上下文信息本节重点讨论了上下文信息中最重要的时间上下文信息。本节首先介绍了各种不同的时间效应，然后研究如何将这些时间效应建模到推荐系统的模型中，最后通过实际数据集对比不同模型的效果。 5.1.1 时间效应简介一般认为，时间信息对用户兴趣的影响表现在以下几个方面。 用户兴趣是变化的 这里提到的用户兴趣变化是因为用户自身原因发生的变化，并且考虑用户最近的兴趣只能针对渐变的用户兴趣，而对突变的用户兴趣很难起作用。 物品也是有生命周期的 不同系统的物品具有不同的生命周期。 季节效应 季节效应主要反映了时间本身对用户兴趣的影响。 5.1.2 时间效应举例这节通过Google Insights工具提供的某个搜索词的搜索频率曲线对时间效应进行一些分析，并且罗列了一些用户兴趣变化及节日效应的例子。 5.1.3 系统时间特性的分析在给定时间信息后，推荐系统从一个静态系统变成了一个时变的系统，而用户行为数据也变成了时间序列。研究一个时变系统，需要首先研究这个系统的时间特性。 本节通过研究时变 用户行为数据集来研究不同类型网站的时间特性。包含时间信息的用户行为数据集由一系列三元组构成，其中每个三元组$(u,i,t)$代表了用户$u$在时刻$t$对物品$i$产生过行为。在给定数据集后，本节通过统计如下信息研究系统的时间特性。 数据集每天独立用户数的增长情况 系统的物品变化情况 用户访问情况 1.数据集的选择本节利用Delicious数据集进行离线实验以评测不同算法的预测精度，书中这部分有一些关于Delicious数据集的介绍。 2.物品的生存周期和系统的时效性不同类型网站的物品具有不同的生命周期。可以使用如下指标度量网站中物品的生命周期。 物品平均在线天数 如果一个物品在某天被至少一个用户产生过行为，就定义该物品在这一天在线。因此，就可以通过物品的平均在线天数度量一类物品的生存周期。 相隔T天系统物品流行度向量的平均相似度 取系统中相邻T天的两天，分别计算这两天的物品流行度，从而得到两个流行度向量。然后，计算这两个向量的余弦相似度，如果相似度大，说明系统的物品在相隔T天的时间内没有发生大的变化，从而说明系统的时效性不强，物品的平均在线时间较长。反之，相似度小则说明时效性很强。 5.1.4 推荐系统的实时性用户兴趣是不断变化的，其变化体现在用户不断增加的新行为中。一个实时的推荐系统需要能够实时响应用户新的行为，让推荐列表不断变化，从而满足用户不断变化的兴趣。 实现推荐系统的实时性除了对用户行为的存取有实时性要求，还要求推荐算法本身具有实时性，而推荐算法本身的实时性意味着： 实时推荐系统不能每天都给所有用户离线计算推荐结果，然后在线展示昨天计算出来的结果。所以，要求在每个用户访问推荐系统时，都根据用户这个时间点前的行为实时计算推荐列表。 推荐算法需要平衡考虑用户的近期行为和长期行为，即要让推荐列表反应出用户近期行为所体现的兴趣变化，又不能让推荐列表完全受用户近期行为的影响，要保证推荐列表对用户兴趣预测的延续性。 5.1.5 推荐算法的时间多样性为了避免每天给用户的推荐结果相近，将推荐系统每天推荐结果的变化程度被定义为推荐系统的时间多样性。时间多样性高的推荐系统中用户会经常看到不同的推荐结果。 那么推荐系统的时间多样性和用户满意度之间是否存在关系呢？时间多样性高是否就能提高用户的满意度？为了解答这些问题，英国研究人员进行了一次实验(参见Neal Lathia、Stephen Hailes、Licia Capra和Xavier Amatriain的“Temporal Diversity in Recommender Systems”（SIGIR 2010）)，他们设计了3种推荐系统，证明了时间多样性对推荐系统的正面意义，书上有关于这个实验的简略介绍。 之后的问题就是如何在不损失精度的情况下提高推荐结果的时间多样性。提高推荐结果的时间多样性需要分两步解决：首先，需要保证推荐系统能够在用户有了新的行为后及时调整推荐结果，使推荐结果满足用户最近的兴趣；其次，需要保证推荐系统在用户没有新的行为时也能够经常变化一下结果，具有一定的时间多样性。对于第一步，又可以分成两种情况进行分析。第一是从推荐系统的实时性角度分析。有些推荐系统会每天离线生成针对所有用户的推荐结果，然后在线直接将这些结果展示给用户。这种类型的系统显然无法做到在用户有了新行为后及时调整推荐结果。第二，即使是实时推荐系统，由于使用的算法不同，也具有不同的时间多样性。对于不同算法的时间多样性，Neal Lathia博士在博士论文中进行了深入探讨(参见Neal Lathia的“Evaluating Collaborative Filtering Over Time”， 论文链接为http://www.cs.ucl.ac.uk/staff/n.lathia/thesis.html )。 紧接着需要思考的问题就是如果用户没有行为，如何保证给用户的推荐结果具有一定的时间多样性呢？一般的思路有以下几种。 在生成推荐结果时加入一定的随机性。比如从推荐列表前20个结果中随机挑选10个结果 展示给用户，或者按照推荐物品的权重采样10个结果展示给用户。 记录用户每天看到的推荐结果，然后在每天给用户进行推荐时，对他前几天看到过很多次的推荐结果进行适当地降权。 每天给用户使用不同的推荐算法。 当然，时间多样性也不是绝对的。推荐系统需要首先保证推荐的精度，在此基础上适当地考虑时间多样性。在实际应用中需要通过多次的实验才能知道什么程度的时间多样性对系统是最好的。 5.1.6 时间上下文推荐算法上一节介绍了很多时间效应，本节主要讨论如何将这些时间效应应用到系统中。建模时间信息有很多方法，本节分别介绍了不同的方法，并通过实验对比这些方法。 1.最近热门在没有时间信息的数据集中，可以给用户推荐历史上最热门的物品。在获得用户行为的时间信息后，就可以给用户推荐最近最热门的物品了。给定时间$T$，物品$i$最近的流行度$n_i(T)$可以定义为：$$n_i(T) = \sum_{(u,i,t) \in \text{Train}, t&lt;T} \frac{1}{1 + \alpha(T-t)}$$$\alpha$是时间衰减参数。下面的Python代码实现了上面的计算公式。1234567def RecentPopularity(records, alpha, T): ret = dict() for user,item,tm in records: if tm &gt;= T: continue addToDict(ret, item, 1 / (1.0 + alpha * (T - tm))) return ret 2.时间上下文相关的ItemCF算法基于物品（item-based）的个性化推荐算法是商用推荐系统中应用最广泛的，从前面几章的讨论可以看到，该算法由两个核心部分构成： 利用用户行为离线计算物品之间的相似度； 根据用户的历史行为和物品相似度矩阵，给用户做在线个性化推荐。 时间信息在上面两个核心部分中都有重要的应用，这体现在两种时间效应上。 物品相似度 用户在相隔很短的时间内喜欢的物品具有更高相似度。 在线推荐 用户近期行为相比用户很久之前的行为，更能体现用户现在的兴趣。因此在预测用户现在的兴趣时，应该加重用户近期行为的权重，优先给用户推荐那些和他近期喜欢的物品相似的物品。 首先回顾一下前面提到的基于物品的协同过滤算法，它通过如下公式计算物品的相似度：$$sim(i,j) = \frac{\sum_{u \in N(i) \cap N(j)}1}{\sqrt{\vert N(i) \vert \vert N(j)\vert}}$$而在给用户$u$做推荐时，用户$u$对物品$i$的兴趣$p(u,i)$通过如下公式计算：$$p(u,i) = \sum_{j \in N(u)} sim(i,j)$$在得到时间信息（用户对物品产生行为的时间）后，可以通过如下公式改进相似度计算：$$sim(i,j) = \frac{\sum_{u \in N(i)\cap N(j)} f(\vert t_{ui} - t_{uj} \vert)}{\sqrt{\vert N(i) \vert \vert N(j) \vert}}$$注意，上面的公式在分子中引入了和时间有关的衰减项$f(\vert t_{ui} - t_{uj} \vert)$，其中$t_{ui}$是用户$u$对物品$i$产生行为的时间。$f$函数的含义是，用户对物品$i$和物品$j$产生行为的时间越远，则$f(\vert t_{ui} - t_{uj} \vert)$越小。实际上有很多数学衰减函数，本节使用如下衰减函数：$$f(\vert t_{ui} - t_{uj} \vert)=\frac{1}{1 + \alpha \vert t_{ui} - t_{uj} \vert}$$$\alpha$是时间衰减参数，它的取指在不同系统中不同。如果一个系统用户兴趣变化很快，就应该 取比较大的$\alpha$，反之需要取比较小的$\alpha$。 改进后ItemCF的相似度可以通过如下代码实现： 123456789101112131415161718def ItemSimilarity(train, alpha): #calculate co-rated users between items C = dict() N = dict() for u, items in train.items(): for i,tui in items.items(): N[i] += 1 for j,tuj in items.items(): if i == j: continue C[i][j] += 1 / (1 + alpha * abs(tui - tuj)) #calculate finial similarity matrix W W = dict() for i,related_items in C.items(): for j, cij in related_items.items(): W[u][v] = cij / math.sqrt(N[i] * N[j]) return W 除了考虑时间信息对相关表的影响，也应该考虑时间信息对预测公式的影响。一般来说， 用户现在的行为应该和用户最近的行为关系更大。因此，可以通过如下方式修正预测公式：$$p(u,i) = \sum_{j \in N(u) \cap S(i,k)} sim(i,j) \frac{1}{1+ \beta \vert t_0 - t_{uj} \vert}$$其中，$t_0$是当前时间。上面的公式表明，$t_{uj}$越靠近$t_0$，和物品$j$相似的物品就会在用户$u$的推荐列表中获得越高的排名。$\beta$是时间衰减参数，需要根据不同的数据集选择合适的值。上面的推荐算法可以通过如下代码实现。 12345678def Recommendation(train, user_id, W, K, t0): rank = dict() ru = train[user_id] for i,pi in ru.items(): for j, wj in sorted(W[i].items(), \ key=itemgetter(1), reverse=True)[0:K]: if j,tuj in ru.items(): continue rank[j] += pi * wj / (1 + alpha * (t0 - tuj)) return rank 3.时间上下文相关的UserCF算法和ItemCF算法一样，UserCF算法同样可以利用时间信息提高预测的准确率。首先，回顾一下前面关于UserCF算法的基本思想：给用户推荐和他兴趣相似的其他用户喜欢的物品。从这个基本思想出发，可以在以下两个方面利用时间信息改进UserCF算法。 用户兴趣相似度 如果两个用户同时喜欢相同的物品，那么 这两个用户应该有更大的兴趣相似度。 相似兴趣用户的最近行为 应该给用户推荐和他兴趣相似的用户最近喜欢的物品。 回顾一下UserCF的推荐公式。UserCF通过如下公式计算用户$u$和用户$v$的兴趣相似度：$$w_{uv} = \frac{\vert N(u) \cap N(v) \vert}{\sqrt{\vert N(u) \vert \cup \vert N(u) \vert}}$$其中$N(u)$是用户$u$喜欢的物品集合，$N(v)$是用户$v$喜欢的物品集合。可以利用如下方式考虑时间信息：$$w_{uv} = \frac{\sum_{i \in N(u) \cap N(v)} \frac{1}{1 +\alpha \vert t_{ui} - t_{vi} \vert}}{\sqrt{\vert N(u) \vert \cup \vert N(u) \vert}}$$上面公式的分子对于用户$u$和用户$v$共同喜欢的物品$i$增加了一个时间衰减因子。用户$u$和用户$v$对物品$i$产生行为的时间越远，那么这两个用户的兴趣相似度就会越小。 1234567891011121314151617181920212223242526def UserSimilarity(train): # build inverse table for item_users item_users = dict() for u, items in train.items(): for i,tui in items.items(): if i not in item_users: item_users[i] = dict() item_users[i][u] = tui #calculate co-rated items between users C = dict() N = dict() for i, users in item_users.items(): for u,tui in users.items(): N[u] += 1 for v,tvi in users.items(): if u == v: continue C[u][v] += 1 / (1 + alpha * abs(tui - tvi)) #calculate finial similarity matrix W W = dict() for u, related_users in C.items(): for v, cuv in related_users.items(): W[u][v] = cuv / math.sqrt(N[u] * N[v]) return W 在得到用户相似度后，UserCF通过如下公式预测用户对物品的兴趣：$$p(u,i) = \sum_{v \in S(u,K)} w_{uv} r_{vi}$$其中，$S(u,K)$包含了和用户$u$兴趣最接近的$K$个用户。如果用户$v$对物品$i$产生过行为，那么$r_{vi}=1$，否则$r_{vi} = 0$。 如果考虑和用户$u$兴趣相似用户的最近兴趣，可以设计如下公式：$$p(u,i) = \sum_{v \in S(u,K)} w_{uv} r_{vi} \frac{1}{1 + \alpha(t_0 + t_{vi})}$$ 12345678910def Recommend(user, T, train, W): rank = dict() interacted_items = train[user] for v, wuv in sorted(W[u].items, key=itemgetter(1), reverse=True)[0:K]: for i, tvi in train[v].items: if i in interacted_items: #we should filter items user interacted before continue rank[i] += wuv / (1 + alpha * (T - tvi)) return rank 5.1.7 时间段图模型本书的作者在KDD会议上曾经提出过一个时间段图模型(参见Liang Xiang、Quan Yuan、Shiwan Zhao、Li Chen、Xiatian Zhang、Qing Yang和Jimeng Sun的“Temporal recommendation on graphs via long- and short-term preference fusion”（ACM 2010 Article，2010）)，试图解决如何将时间信息建模到图模型中的方法，最终取得了不错的效果。时间段图模型$G (U , S_U , I , S_I , E , w,\sigma )$也是一个二分图。$U$是用户节点集合，$S_U$是用户时间段节点集合。一个用户时间段节点$v_{ut} \in S_U$会和用户$u$在时刻$t$喜欢的物品通过边相连。$I$是物品节点集合，$S_I$是物品时间段节点集合。一个物品时间段节点 $v_{it} \in S_I$会和所有在时刻$t$喜欢物品$i$的用户通过边相连。$E$是边集合，它包含了3种边：(1)如果用户$u$对物品$i$有行为，那么存在边$e(v_u,v_i) \in E$；(2)如果用户$u$在$t$时刻对物品$i$有行为，那么就存在两条边$e(v_{ut},v_i )$, $e(v_u, v_{it} ) \in E$。$w(e)$定义了边的权重，$\sigma (e)$定义了顶点的权重。 定义完图的结构后，最简单的想法是可以利用前面提到的PersonalRank算法给用户进行个性化推荐。但是因为这个算法需要在全图上进行迭代计算，所以时间复杂度比较高。因此作者提出了一种称为路径融合算法的方法，通过该算法来度量图上两个顶点的相关性。一般来说，图上两个相关性比较高的顶点一般具有如下特征： 两个顶点之间有很多路径相连； 两个顶点之间的路径比较短； 两个顶点之间的路径不经过出度比较大的顶点。 从这3条原则出发，路径融合算法首先提取出两个顶点之间长度小于一个阈值的所有路径，然后根据每条路径经过的顶点给每条路径赋予一定的权重，最后将两个顶点之间所有路径的权重之和作为两个顶点的相关度。 假设$P={v_1,v_2,···,v_N}$是连接顶点$v_1$和$v_n$的一条路径，这条路径的权重$\Gamma(P)$取决于这条路径经过的所有顶点和边：$$\Gamma(p) = \sigma(v_n) \prod_{i=1}^{n-1} \frac{\sigma (v_i) \cdot w(v_I,v_{i+1})}{\vert out(v_i) \vert^\rho}$$这里$out(v)$是顶点$v$指向的顶点集合，$|out(v)|$是顶点$v$的出度，$\sigma(v_i) \in (0,1]$定义了顶点的权重，$w(v_i,v_{i+1})$定义了边$e(v_i,v_{i+1})$的权重。上面的定义符合上面3条原则的后两条。首先，因为$\frac{\sigma(v_i) \cdot w(v_i,v_{i+1})}{\vert out(v_i)\vert^\rho}$，所以路径越长$n$越大，$\Gamma(P)$就越小。同时，如果路径经过了出度大的顶点v’，那么因为$|out(v’)|$比较大，所以$\Gamma(p)$也会比较小。 在定义了一条路径的权重后，就可以定义顶点之间的相关度。对于顶点$v$和$v’$，令$p(v, v’, K )$为这两个顶点间距离小于K的所有路径，那么这两个顶点之间的相关度可以定义为：$$d(v,v’) = \sum_{P \in P(v,v’,K)} \Gamma(P)$$对于时间段图模型，所有边的权重都定义为1，而顶点的权重$\sigma(v)$定义如下：$$\sigma(v) =\begin{cases}1- \alpha &amp;(v \in U) \\\alpha &amp;(v \in S_U) \\1 - \beta &amp; (v \in I) \\\beta &amp; (v \in S_I)\end{cases}$$$\alpha,\beta \in [0,1]$是两个参数，控制了不同顶点的权重。 路径融合算法可以基于图上的广度优先搜索算法实现，下面的Python代码简单实现了路径融合算法。 1234567891011121314151617181920212223def PathFusion(user, time,G,alpha) Q = [] V = set() depth = dict() rank = dict() depth['u:' + user] = 0 depth['ut:' + user + '_' + time] = 0 rank ['u:' + user] = alpha rank ['ut:' + user + '_' + time] = 1 - alpha Q.append('u:' + user) Q.append('ut:' + user + '_' + time) while len(Q) &gt; 0: v = Q.pop() if v in V: continue if depth[v] &gt; 3: continue for v2,w in G[v].items(): if v2 not in V: depth[v2] = depth[v] + 1 Q.append(v2) rank[v2] = rank[v] * w return rank 5.1.8 离线实验为了证明时间上下文信息对推荐系统至关重要，本节利用了离线实验对比使用时间信息后不同推荐算法的离线性能，感兴趣的看一下书。 5.2 地点上下文信息除了时间，地点作为一种重要的空间特征，也是一种重要的上下文信息。不同地区的用户兴趣有所不同，用户到了不同的地方，兴趣也会有所不同。 西班牙电信的研究人员曾经设计过一个基于位置的电影推荐系统，并且提供了详细的技术报告(参见“Geolocated Recommendations”，地址为http://xavier.amatriain.net/pubs/GeolocatedRecommendations.pdf )。该报告详细地介绍了如何在iPhone上开发一个推荐系统，如何在电影推荐中融入用户的位置信息，感兴趣的读者可以仔细阅读他们的报告。 基于位置的推荐算法明尼苏达大学的研究人员提出过一个称为LARS（Location Aware Recommender System,位置感知推荐系统）的和用户地点相关的推荐系统。该系统首先将物品分成两类，一类是有空间属性的，比如餐馆、商店、旅游景点等，另一类是无空间属性的物品，比如图书和电影等。同时，它将用户也分成两类，一类是有空间属性的，比如给出了用户现在的地址（国家、城市、邮编等）， 另一类用户并没有相关的空间属性信息。它使用的数据集有3种不同的形式。 （用户，用户位置，物品，评分），每一条记录代表了某一个地点的用户对物品的评分。它们使用的是MovieLens数据集。该数据集给出了用户的邮编，从而可以知道用户的大致地址。 （用户，物品，物品位置，评分），每一条记录代表了用户对某个地方的物品的评分。LARS使用了FourSquare的数据集，该数据集包含用户对不同地方的餐馆、景点、商店的评分 （用户，用户位置，物品，物品位置，评分），每一条记录代表了某个位置的用户对某个位置的物品的评分。 LARS通过研究前两种数据集，发现了用户兴趣和地点相关的两种特征。 兴趣本地化 不同地方的用户兴趣存在着很大的差别。不同国家和地区用户的兴趣存在着一定的差异性。 活动本地化 一个用户往往在附近的地区活动。通过分析Foursqure的数据，研究人员发现45%的用户其活动范围半径不超过10英里，而75%的用户活动半径不超过50英里。 对于第一种数据集，LARS的基本思想是将数据集根据用户的位置划分成很多子集。因为位置信息是一个树状结构，比如国家、省、市、县的结构。因此，数据集也会划分成一个树状结构。然后，给定每一个用户的位置，可以将他分配到某一个叶子节点中，而该叶子节点包含了所有和他同一个位置的用户的行为数据集。然后，LARS就利用这个叶子节点上的用户行为数据，通过ItemCF给用户进行推荐。 不过这样做的缺点是，每个叶子节点上的用户数量可能很少，因此他们的行为数据可能过于稀疏，从而无法训练出一个好的推荐算法。为此，我们可以从根节点出发，在到叶子节点的过程中，利用每个中间节点上的数据训练出一个推荐模型，然后给用户生成推荐列表。而最终的推荐结果是这一系列推荐列表的加权。文章的作者将这种算法成为金字塔模型，而金字塔的深度影响了推荐系统的性能，因而深度是这个算法的一个重要指标。下文用LARS-U代表该算法，书中有关于该算法的简单例子。 对于第二种数据集，每条用户行为表示为四元组（用户、物品、物品位置、评分），表示了用户对某个位置的物品给了某种评分。对于这种数据集，LARS会首先忽略物品的位置信息，利用ItemCF算法计算用户$u$对物品$i$的兴趣$P(u,i)$，但最终物品$i$在用户$u$的推荐列表中的权重定义为：$$RecScore(u,i) = P(u,i) - TravelPenalty(u,i)$$在该公式中，$TravelPenalty(u,i)$表示了物品$i$的位置对用户$u$的代价。 计算 $TravelPenalty(u,i)$的基本思想是对于物品$i$与用户$u$之前评分的所有物品的位置计算距离的平均值 （或者最小值）。关于如何度量地图上两点的距离，最简单的是基于欧式距离(参见Gísli R. Hjaltason和Hanan Samet的“Distance browsing in spatial databases”（ACM 1999 Article，1999）)。当然，欧式距离有明显的缺点，因为人们是不可能沿着地图上的直线距离从一点走到另一点的。比较好的度量方式是利用交通网络数据，将人们实际需要走的最短距离作为距离度量(参见Jie Bao、Chi-Yin Chow、Mohamed F. Mokbel和Wei-Shinn Ku的“Efficient Evaluation of k-Range Nearest Neighbor Queries in Road Networks”（MDM，2012）)。 为了避免计算用户对所有物品的$TravelPenalty$，LARS在计算用户$u$对物品$i$的兴趣度$RecScore(u,i)$时，首先对用户每一个曾经评过分的物品（一般是餐馆、商店、景点），找到和他距离小于一个阈值$d$的所有其他物品，然后将这些物品的集合作为候选集，然后再利用上面的公式计算最终的$RecScore$。 对于第三种数据集，LARS一文没有做深入讨论。不过，从第三种数据集的定义可以看到， 它相对于第二种数据集增加了用户当前位置这一信息。而在给定了这一信息后，应该保证推荐的物品应该距离用户当前位置比较近，在此基础上再通过用户的历史行为给用户推荐离他近且他会感兴趣的物品。 为了证明兴趣本地化和活动本地化两种效应，论文作者在FourSquare和MovieLens两个数据集上进行了离线实验。论文作者使用TopN推荐的Precision作为评测指标。 作者首先在FourSquare数据集上对比了ItemCF算法和考虑了TravelPenalty之后的算法（简称为LARS-T）。结果证明考虑TravelPenality确实能够提高TopN推荐的离线准确率，LARS-T算法明显优于ItemCF算法。 然后，作者在FourSquare数据集和MovieLens数据集上对比了普通的ItemCF算法和考虑用户位置的金字塔模型后的LARS-U算法。同时，作者对比了不同深度对LARS-U算法的影响。实验表明，选择合适的深度对LARS-U算法很重要，不过在绝大多数深度的选择下，LARS-U算法在两个数据集上都优于普通的ItemCF算法。 5.3 扩展阅读时间上下文信息在Netflix Prize中得到了广泛关注，很多参赛者都研究了如何利用这一信息。这方面最著名的文章无疑是Koren的“collaborative filtering with temporal dynamics”，该文系统地总结了各种使用时间信息的方式，包括考虑用户近期行为的影响，考虑时间的周期性等。 英国剑桥大学的Neal Lathia在读博士期间对时间上下文信息以及推荐系统的时间效应进行了深入研究。他在“Temporal Diversity in Recommender Systems”一文中深入分析了时间多样性对推荐系统的影响。他的博士论文“Evaluating Collaborative Filtering Over Time”论述了各种不同推荐算法是如何随时间演化的。 如果要系统地研究与上下文推荐相关的工作， 可以参考Alexander Tuzhili 教授的工作（http://pages.stern.nyu.edu/~atuzhili/ ），他在最近几年和学生对上下文推荐问题进行了深入研究。]]></content>
      <categories>
        <category>计算机科学与技术</category>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（四）]]></title>
    <url>%2F2018%2F11%2F27%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第4章 利用用户标签数据GroupLens在一篇文章中(文章名是“Tagsplanations : Explaining Recommendations using Tags”)表示目前流行的推荐系统基本上通过3种方式联系用户兴趣和物品。 基于物品的算法 比如UserCF 基于用户的算法 比如ItemCF 基于特征的算法 比如隐语义模型 本章将讨论一种重要的特征表现方式——标签。根据维基百科的定义(参见http://en.wikipedia.org/wiki/Tag_(metadata) )，标签是一种无层次化结构的、用来描述信息的关键词，它可以用来描述物品的语义。根据给物品打标签的人的不同，标签应用一般分为两种：一种是让作者或者专家给物品打标签；另一种是让普通用户给物品打标签，也就是UGC(User Generated Content，用户生成的内容)的标签应用。UGC的标签系统是一种表示用户兴趣和物品语义的重要方式。当一个用户对一个物品打上一个标签，这个标签一方面描述了用户的兴趣，另一方面则表示了物品的语义，从而将用户和物品联系了起来。本章主要讨论UGC的标签应用，研究用户给物品打标签的行为，探讨如何通过分析这种行为给用户进行个性化推荐。 4.1 UGC标签系统的代表应用4.1.1 DeliciousDelicious允许用户给互联网上的每个网页打标签，从而通过标签重新组织整个互联网。 4.1.2 CiteULikeCiteULike是一个著名的论文书签网站，它允许研究人员提交或者收藏自己感兴趣的论文并且给论文打标签，从而帮助用户更好地发现和自己研究领域相关的优秀论文。 4.1.3 Last.fmLast.fm在前面已经介绍过，是一家著名的音乐网站，它通过分析用户的听歌行为预测用户对音乐的兴趣，从而给用户推荐个性化的音乐。 4.1.4 豆瓣豆瓣允许用户对图书和电影打标签，借此获得图书和电影的内容信息和语义，并用这种信息改善推荐效果。 4.1.5 HuluHulu是美国著名的视频网站。视频作为一种最为复杂的多媒体，获取它的内容信息是最困难的，因此Hulu也引入了用户标签系统来让用户对电视剧和电影进行标记。 总结以上标签系统的各种应用，标签系统的最大优势在于可以发挥群体的智能，获得对物品内容信息比较准确的关键词描述，而准确的内容信息是提升个性化推荐系统性能的重要资源。 关于标签系统的作用， GroupLen的Shilads Wieland Sen在MoveLens电影推荐系统上做了更为深入的、基于问卷调查的研究。在博士论文(博士论文为“Nurturing Tagging Communities”)中，他探讨了标签系统的不同作用，以及每种作用能够影响多大的人群，如下所示。 表达 标签系统帮助我表达对物品的看法。（30%的用户同意。） 组织 打标签帮助我组织我喜欢的电影。（23%的用户同意。） 学习 打标签帮助我增加对电影的了解。（27%的用户同意。） 发现 标签系统使我更容易发现喜欢的电影。（19%的用户同意。） 决策 标签系统帮助我判定是否看某一部电影。（14%的用户同意。） 上面的研究表明，标签系统确实能够帮助用户发现可能喜欢的电影。 4.2 标签系统中的推荐问题标签系统中的推荐问题主要有以下两个。 如何利用用户打标签的行为为其推荐物品（基于标签的推荐）？ 如何在用户给物品打标签时为其推荐适合该物品的标签（标签推荐）？ 为了研究上面的问题，首先需要解答下面3个问题。 用户为什么要打标签？ 用户怎么打标签？ 用户打什么样的标签？ 4.2.1 用户为什么进行标注Morgan Ames研究图片分享网站中用户标注的动机问题，并从两个维度进行探讨(参见Morgan Ames和 Mor Naaman的“Why we tag: motivations for annotation in mobile and online media”（ CHI 2007，2007）)。首先是社会维度，有些用户标注是给内容上传者使用的（便于上传者组织自己的信息），而有些用户标注是给广大用户使用的（便于帮助其他用户找到信息）。另一个维度是功能维度，有些标注用于更好地组织内容，方便用户将来的查找，而另一些标注用于传达某种信息，比如照片的拍摄时间和地点等。 4.2.2 用户如何打标签该节通过研究Delicious数据集总结用户标注行为中的一些统计规律，即标签的流行度分布同用户活跃度、物品流行度分布一致都遵循长尾分布(Power Law分布)，实验具体过程见书。 4.2.3 用户打什么样的标签用户在对物品打标签时，可能并非如我们希望地提供能够准确描述物品内容属性的关键词，而是各种奇怪的标签。 Delicious上的标签分类Scott A. Golder 总结了Delicious上的标签，将它们分为如下几类。 表明物体是什么 表明物品的种类 表明谁拥有物品 表达用户的观点 用户相关的标签 用户的任务 Hulu上的标签分类 类型(Genre) 主要表示这个电视剧的类别。 时间(Time) 主要包括电视剧的发布的时间，有时也包括电视剧中事件发生的时间。 人物(People) 主要包括电视剧的导演、演员和剧中重要人物等。 地点(Place) 剧情发生的地点，或者视频拍摄的地点等。 语言(Language) 这部电视剧使用的语言。 奖项(Awards) 这部电视剧获得的相关奖项。 其他(Details) 包含不能归类到上面各类中的其他所有标签。 4.3 基于标签的推荐系统一个用户标签行为的数据集一般由一个三元组的集合表示，其中记录$(u, i, b)$表示用户$u$给物品$i$打上了标签$b$。当然，用户的真实标签行为数据远远比三元组表示的要复杂，比如用户打标签的时间、用户的属性数据、物品的属性数据等。但是本章为了集中讨论标签数据，只考虑上面定义的三元组形式的数据，即用户的每一次打标签行为都用一个三元组（用户、物品、标签）表示。 本章将采用两个不同的数据集评测基于标签的物品推荐算法。一个是Delicious数据集，另一个是CiteULike数据集。Delicious数据集中包含用户对网页的标签记录。它每一行由4部分组成，即时间、用户ID、网页URL、标签。CiteULike数据集包含用户对论文的标签记录，它每行也由4部分组成，即物品ID、用户ID、时间、标签。 4.3.1 实验设置本节将数据集随机分成10份。这里分割的键值是用户和物品，不包括标签。也就是说，用户对物品的多个标签记录要么都被分进训练集，要么都被分进测试集，不会一部分在训练集，另一部分在测试集中。然后，我们挑选1份作为测试集，剩下的9份作为训练集，通过学习训练集中的用户标签数据预测测试集上用户会给什么物品打标签。对于用户$u$，令$R(u)$为给用户$u$的长度为$N$的推荐列表，里面包含我们认为用户会打标签的物品。令$T(u)$是测试集中用户$u$实际上打过标签的物品集合。然后，利用准确率(precision)和召回率(recall)评测个性化推荐算法的精度。将上面的实验进行10次，每次选择不同的测试集，然后将每次实验的准确率和召回率的平均值作为最终的评测结果。 为了全面评测个性化推荐的性能，实验同时评测了推荐结果的覆盖率(coverage)、多样性(diversity)和新颖度。 关于多样性，在第1章中讨论过，多样性的定义取决于相似度的定义。在本章中，实验用物品标签向量的余弦相似度度量物品之间的相似度。对于每个物品$i$，item_tags[i]存储了物品$i$的标签向量，其中item_tags[i][b]是对物品$i$打标签$b$的次数，那么物品$i$和$j$的余弦相似度可以通过如下程序计算。 1234567891011121314def CosineSim(item_tags, i, j): ret = 0 for b,wib in item_tags[i].items(): if b in item_tags[j]: ret += wib * item_tags[j][b] ni = 0 nj = 0 for b, w in item_tags[i].items(): ni += w * w for b, w in item_tags[j].items(): nj += w * w if ret == 0: return 0 return ret / math.sqrt(ni * nj) 在得到物品之间的相似度度量后，通过如下公式计算一个推荐列表的多样性。$$Diversity = 1 - \frac {\sum_{i \in R(u)} \sum_{j \in R(u),j \neq i} \text{Sim(item_tags[i],item_tags[j])}}{\begin{pmatrix}\vert R(u) \vert \\2 \\\end{pmatrix}}$$ 如果用程序实现，代码如下：12345678910def Diversity(item_tags, recommend_items): ret = 0 n = 0 for i in recommend_items.keys(): for j in recommend_items.keys(): if i == j: continue ret += CosineSim(item_tags, i, j) n += 1 return ret / (n * 1.0) 推荐系统的多样性为所有用户推荐列表多样性的平均值。 至于推荐结果的新颖性，可以简单地用推荐结果的平均热门程度(AveragePopularity)度量。 对于物品$i$，定义它的流行度item_pop(i)为给这个物品打过标签的用户数。而对推荐系统，定义它的平均热门度如下：$$Average Popularity = \frac {\sum_u \sum_{i \in R(u)} \log(1 + \text{item_pop(i))}}{\sum_u \sum_{i \in R(u)}1}$$ 4.3.2 一个最简单的算法拿到了用户标签行为数据后，最简单的个性化推荐算法描述如下： 统计每个用户最常用的标签 对于每个标签，统计被打过这个标签次数最多的物品。 对于一个用户，首先找到他常用的标签，然后找到具有这些标签的最热门物品推荐给这个用户。 对于上面的算法，用户 $u$ 对物品 $i$ 的兴趣公式如下：$$p(u,i) = \sum_b n_{u,b}n_{b,i}$$ $B(u)$是用户$u$打过的标签集合，$B(i)$是物品$i$被打过的标签集合，$n_{u,b}$是用户$u$打过标签$b$的次数，$n_{b,i}$是物品$i$被打过标签$b$的次数。本章用SimpleTagBased标记这个算法。 在Python中，遵循如下规定： 用records存储标签数据的三元组，其中records[i] = [user, item, tag]； 用user_tags存储$n_{u,b}$，其中user_tags[u][b] = $n_{u,b}$； 用tags_items存储$n_{b,i}$，其中tags_item[b][i] = $n_{b,i}$ ； 如下程序可以从records中统计出user_tags和tag_items:12345678def InitStat(records): user_tags = dict() tag_items = dict() user_items = dict() for user, item, tag in records.items(): addValueToMat(user_tags, user, tag, 1) addValueToMat(tag_items, tag, item, 1) addValueToMat(user_items, user, item, 1) 统计出user_tags和tag_items之后，可以通过如下程序对用户进行个性化推荐：12345678910111213def Recommend(user): recommend_items = dict() tagged_items = user_items[user] for tag, wut in user_tags[user].items(): for item, wti in tag_items[tag].items(): #if items have been tagged, do not recommend them if item in tagged_items: continue if item not in recommend_items: recommend_items[item] = wut * wti else: recommend_items[item] += wut * wti return recommend_items 4.3.3 算法的改进1.TF-IDF前面这个公式倾向于给热门标签对应的热门物品很大的权重，因此会造成推荐热门的物品给用户，从而降低推荐结果的新颖性。另外，这个公式利用用户的标签向量对用户兴趣建模，其中每个标签都是用户使用过的标签，而标签的权重是用户使用该标签的次数。这种建模方法的缺点是给热门标签过大的权重，从而不能反应用户个性化的兴趣。这里我们可以借鉴TF-IDF的思想， 对这一公式进行改进：$$p(u,i) = \sum_b \frac{n_{u,b}}{\log(1+ n_b^{(u)})} n_{b,i}$$$n_b^{(u)}$记录了标签$b$被多少个不同的用户使用过。这个算法记为TagBasedTFIDF。通过TagBasedTFIDF在Delicious和CiteULike两个数据集上的离线实验结果，可知该算法在所有指标上相比SimpleTagBased算法都有提高。 同理，也可以借鉴TF-IDF的思想对热门物品进行惩罚，从而得到如下公式：$$p(u,i) = \sum_b \frac{n_{u,b}}{\log(1+n_b^{(u)})}\frac{n_{b,i}}{\log(1+n_i^{(u)})}$$$n_i^{(u)}$记录了物品$i$被多少个不同的用户打过标签。这个算法记为TagBasedTFIDF++。同样通过离线实验证明和TagBasedTFIDF算法相比，除了多样性有所下降，其他指标都有明显提高。这一结果表明，适当惩罚热门标签和热门物品，在增进推荐结果个性化的同时并不会降低推荐结果的离线精度。 2.数据稀疏性对于新用户或者新物品，$B(u) \cap B(i)$中的标签数量会很少。为了提高推荐的准确率，可能要对标签集合做扩展。进行标签扩展有很多方法，其中常用的有话题模型(topic model)，不过这里遵循简单的原则介绍一种基于邻域的方法。标签扩展的本质是对每个标签找到和它相似的标签，也就是计算标签之间的相似度。最简单的相似度可以是同义词。如果有一个同义词词典，就可以根据这个词典进行标签扩展。如果没有这个词典，可以从数据中统计出标签的相似度。如果认为同一个物品上的不同标签具有某种相似度，那么当两个标签同时出现在很多物品的标签集合中时，就可以认为这两个标签具有较大的相似度。对于标签$b$，令$N(b)$为有标签$b$的物品的集合，$n_{b,i}$为给物品$i$打上标签$b$的用户数，可以通过如下余弦相似度公式计算标签$b$和标签$b’$的相似度：$$sim(b,b’) = \frac{\sum_{i \in N(b) \cap N(b’)} n_{b,i} n_{b’,i}}{\sqrt{\sum_{i \in N(b)}n_{b,i}^2 \sum_{i \in N(b’)} n_{b’,i}^2} }$$实验表明，进行标签扩展确实能够提高基于标签的物品推荐的准确率和召回率，但可能会稍微降低推荐结果的覆盖率和新颖度。 3.标签清理不是所有标签都能反应用户的兴趣。同时，标签系统里经常出现词形不同、词义相同的标签。 标签清理的另一个重要意义在于将标签作为推荐解释。如果要把标签呈现给用户，将其作为给用户推荐某一个物品的解释，对标签的质量要求就很高。首先，这些标签不能包含没有意义的停止词或者表示情绪的词，其次这些推荐解释里不能包含很多意义相同的词语。 一般来说有如下标签清理方法： 去除词频很高的停止词； 去除因词根不同造成的同义词，比如recommender system和recommendation system； 去除因分隔符造成的同义词，比如collaborative_filtering和collaborative-filtering； 为了控制标签的质量，很多网站也采用了让用户进行反馈的思想，即让用户告诉系统某个标签是否合适。MovieLens在实验系统中就采用了这种方法。关于这方面的研究可以参考GroupLens 的Shilad Wieland Sen同学的博士论文(参见Shilad Wieland Sen的“ Nurturing Tagging Communities”) 。 4.3.4 基于图的推荐算法前面讨论的简单算法很容易懂，也容易实现，但缺点是不够系统化和理论化。因此考虑利用图模型做基于标签数据的个性化推荐。 首先，需要将用户打标签的行为表示到一张图上。图是由顶点、边和边上的权重组成的。而在用户标签数据集上，有3种不同的元素，即用户、物品和标签。因此，需要定义3种不同的顶点，即用户顶点、物品顶点和标签顶点。然后，如果我们得到一个表示用户$u$给物品$i$打了标签$b$的用户标签行为$(u,i,b)$，那么最自然的想法就是在图中增加3条边，首先需要在用户u对应的顶点$v(u)$和物品i对应的顶点$v(i)$之间增加一条边（如果这两个顶点已经有边相连，那么就应该将边的权重加1），同理，在$v(u)$和$v(b)$之间需要增加一条边，$v(i)$和$v(b)$之间也需要边相连接。 在定义出用户—物品—标签图后，可以用第2章提到的PersonalRank算法计算所有物品节点相对于当前用户节点在图上的相关性，然后按照相关性从大到小的排序，给用户推荐排名最高的$N$个物品。 用图模型解释前面的简单算法基于图模型重新思考前面的简单算法。 在那个算法中，用户对物品的兴趣公式如下：$$P(i|u) = \sum_b P(i|b)P(b|u)$$这个公式假定用户对物品的兴趣通过标签传递，因此这个公式可以通过一个比本节前面介绍的图更简单的图建模（记为SimpleTagGraph）。给定用户标签行为记录$(u,i,b)$，SimpleTagGraph会增加两条有向边，一条由用户节点$v(u)$指向标签节点$v(b)$，另一条由标签节点$v(b)$指向物品节点$v(i)$。从这个定义可以看到，SimpleTagGraph相对于前面提到用户—物品—标签图少了用户节点和物品节点之间的边。在构建了SimpleTagGraph后， 利用前面的PersonalRank算法，令$K = 1$，并给出不同边权重的定义，就等价于前面提出的简单推荐算法。 4.3.5 基于标签的推荐解释书中这部分首先介绍了豆瓣基于标签的推荐系统，其中豆瓣将推荐结果的可解释性拆分成两部分这个方法值得借鉴，详细内容见书。 GroupLens的研究人员Jesse Vig对基于标签的解释进行了深入研究(参见Jesse Vig、 Shilad Wieland Sen和 John Riedl的“Tagsplanations: Explaining Recommendations Using Tags”（ACM 2009 Article，2009）)。 和4.3.2节提出的算法类似，Jesse Vig将用户和物品之间的关系变成了用户对标签的兴趣(tag preference)和标签与物品的相关度(tag relevance)，然后作者用同一种推荐算法给用户推荐物品，但设计了4种标签解释的展示界面。 RelSort 对推荐物品做解释时使用的是用户以前使用过且物品上有的标签，给出了用户对标签的兴趣和标签与物品的相关度，但标签按照和物品的相关度排序。 PreSort 对推荐物品做解释时使用的是用户以前使用过且物品上有的标签，给出了用户对标签的兴趣和标签与物品的相关度，但标签按照用户的兴趣程度排序。 RelOnly 对推荐物品做解释时使用的是用户以前使用过且物品上有的标签，给出了标签与物品的相关度，且标签按照和物品的相关度排序。 PreOnly 对推荐物品做解释时使用的是用户以前使用过且物品上有的标签，给出了用户对标签的兴趣程度，且标签按照用户的兴趣程度排序。 然后，作者对用户设计了3种调查问卷。首先是关于推荐解释的调查问卷，作者问了如下3个问题： 推荐解释帮助我理解这部电影为什么会被推荐给我：对于这个问题用户认为 RelSort&gt; PrefOnly&gt;=PrefSort&gt;RelOnly。 推荐解释帮助我判定是否喜欢推荐的电影：对于这个问题用户认为 RelSort&gt;PrefSort&gt; PrefOnly&gt;RelOnly。 推荐解释帮助我判定观看这部电影是否符合我现在的兴趣：对于这个问题用户认为RelSort&gt;PrefSort&gt;RelOnly &gt;PrefOnly。 然后，作者调查了用户对不同类型标签的看法。作者将标签分为主观类（比如对电影的看法）和客观类（比如对电影内容的描述）。作者对每种类型的标签同样问了上面3个问题。 这个标签帮助我理解这部电影为什么会被推荐给我：用户认为客观类标签优于主观类标签。 这个标签帮助我判定是否喜欢推荐的电影：用户认为客观类标签优于主观类标签。 这个标签帮助我判定观看这部电影是否符合我现在的兴趣：用户认为客观类标签优于主观类标签。 从上面的结果可以发现，客观事实类的标签优于主观感受类标签。最后，作者询问了用户对4种不同推荐解释界面的总体满意度，结果显示PrefOnly &gt; RelSort &gt; PrefSort &gt; RelOnly。 总结问卷调查的结果，作者得出了以下结论： 用户对标签的兴趣对帮助用户理解为什么给他推荐某个物品更有帮助； 用户对标签的兴趣和物品标签相关度对于帮助用户判定自己是否喜欢被推荐物品具有同样的作用； 物品标签相关度对于帮助用户判定被推荐物品是否符合他当前的兴趣更有帮助； 客观事实类标签相比主观感受类标签对用户更有作用。 4.4 给用户推荐标签4.4.1 为什么要给用户推荐标签一般认为，给用户推荐标签有以下好处。 方便用户输入标签 从键盘输入标签会增加用户打标签的难度，推荐标签则可以降低难度，从而提高用户打标签的参与度。 提高标签质量 同一个语义不同的用户可能用不同的词语来表示。这些同义词会使标签的词表变得很庞大，而且会使计算相似度不太准确。而使用推荐标签时，可以对词表进行选择，首先保证词表不出现太多的同义词，同时保证出现的词都是一些比较热门的、有代表性的词。 4.4.2 如何给用户推荐标签推荐标签的方法中比较简单的有4种。第0种方法(最简单的方法)就是给用户$u$推荐整个系统里最热门的标签（这里将这个算法称为PopularTags）令tags[b]为标签$b$的热门程度，算法的实验方法如下： 12def RecommendPopularTags(user,item, tags, N): return sorted(tags.items(), key=itemgetter(1), reverse=True)[0:N] 第1种方法就是给用户$u$推荐物品$i$上最热门的标签（这里将这个算法称为ItemPopularTags）。令item_tags[i][b]为物品$i$被打上标签$b$的次数，这个算法的实现具体如下所示： 12def RecommendItemPopularTags(user,item, item_tags, N): return sorted(item_tags[item].items(), key=itemgetter(1), reverse=True)[0:N] 第2种方法是给用户$u$推荐他自己经常使用的标签（这里将这个算法称为UserPopularTags）。令user_tags[u][b]为用户$u$使用标签$b$的次数，这个算法的实现如下所示：12def RecommendUserPopularTags(user,item, user_tags, N): return sorted(user_tags[user].items(), key=itemgetter(1), reverse=True)[0:N] 第3种算法是前面两种的融合（这里记为HybridPopularTags），该方法通过一个系数(线性融合系数)将上面的推荐结果线性加权，然后生成最终的推荐结果。这个算法的实现代码如下： 123456789101112def RecommendHybridPopularTags(user,item, user_tags, item_tags, alpha, N): max_user_tag_weight = max(user_tags[user].values()) for tag, weight in user_tags[user].items(): ret[tag] = (1 – alpha) * weight / max_user_tag_weight max_item_tag_weight = max(item_tags[item].values()) for tag, weight in item_tags[item].items(): if tag not in ret: ret[tag] = alpha * weight / max_item_tag_weight else: ret[tag] += alpha * weight / max_item_tag_weight return sorted(ret[user].items(), key=itemgetter(1), reverse=True)[0:N] 注意在上面的实现中，在将两个列表线性相加时都将两个列表按最大值做了归一化，这样的好处是便于控制两个列表对最终结果的影响，而不至于因为物品非常热门而淹没用户对推荐结果的影响，或者因为用户非常活跃而淹没物品对推荐结果的影响。 4.4.3 实验设置和前面的实验一样，用同样的方法将数据集按照9∶1分成训练集和测试集，然后通过训练集学习用户标注的模型。需要注意的是，这里切分数据集不再是以user、item为主键，而是以user、item、tag为主键。为了更好的理解如何切分数据集，请参考下面的Python代码：1234567def SplitData(records, train, test): for user,item, tag in records: if random.randint(1,10) == 1: test.append([user,item,tag]) else: train.append([user,item,tag]) return [train, test] 对于测试集中的每一个用户物品对$(u,i)$，我们都可以推荐$N$个标签给用户$u$作参考。令$R(u,i)$为给用户$u$推荐的应该在物品$i$上打的标签集合，令$T(u,i)$为用户$u$实际给物品$i$打的标签的集合，然后可以利用准确率和召回率评测标签推荐的精度。 实验结果表明，ItemPopularTags具有最好的准确率和召回率。在$α$=0.8($\alpha​$是线性融合稀疏)的时候，HybridPopularTags取得了最好的准确度。而且这个精度超过了单独的ItemPopularTags和UserPopularTags算法的精度。考虑到近70%的精度已经很高了，因此很多应用在给用户推荐标签时会直接给出用户最常用的标 签，以及物品最经常被打的标签。 不过，前面提到的基于统计用户常用标签和物品常用标签的算法有一个缺点，就是对新用户或者不热门的物品很难有推荐结果。解决这一问题有两个思路。第一个思路是从物品的内容数据中抽取关键词作为标签。这方面的研究很多，特别是在上下文广告领域(参见Wen-tau Yih、Joshua Goodman和 Vitor R. Carvalho的“Finding Advertising Keywords on Web Pages”（ACM 2006 Article，2006）)。本书3.4节也介绍了生成关键词向量的一些方法。第二个思路是针对有结果，但结果不太多的情况。可以做一些关键词扩展，加入一些与现有结果相关的标签。实现标签扩展的关键就是计算标签之间的相似度。关于这一点， 4.3.3节已经进行了深入探讨。 4.4.4 基于图的标签推荐算法图模型同样可以用于标签推荐。在根据用户打标签的行为生成图之后，可以利用PersonalRank算法进行排名。但这次遇到的问题和之前不同。这次的问题是，当用户$u$遇到物品$i$时，会给物品$i$打什么样的标签。因此，可以重新定义顶点的启动概率，如下所示：$$r_{v(k)} =\begin{cases}\alpha &amp; {(v(k)= v(u))} \\1 - \alpha &amp; (v(k) = v(i)) \\0 &amp; \text{(其他)}\end{cases}$$只有用户$u$和物品$i$对应的顶点有非0的启动概率，而其他顶点的启动概率都为0。 在上面的定义中，$v(u)$和$v(i)$的启动概率并不相同，$v(u)$的启动概率是$\alpha$，而$v(i)$的启动概率是$1-\alpha$。 参数$\alpha$可以通过离线实验选择。 4.5 扩展阅读本章主要讨论了UGC标签在推荐系统中的应用。标签作为描述语义的重要媒介，无论是对于描述用户兴趣还是表示物品的内容都有很重要的意义。标签在推荐系统中的应用主要集中在两个问题上，一个是如何利用用户打标签的行为给用户推荐物品，另一个是如何给用户推荐标签。本章在深入分析用户标签行为的基础上对这两个问题进行了深入探讨。 关于标签的问题，最近几年在学术界获得了广泛关注。ECML/PKDD在2008年曾经推出过基于标签的推荐系统比赛(1)。 在这些研究中涌现了很多新的方法， 比如张量分解(2)(tensor factorization)、基于LDA的算法(3)、基于图的算法(4)等。不过这些算法很多具有较高的复杂度，在实际系统中应用起来还有很多实际的困难需要解决。GroupLens的研究人员给MovieLens系统做了很多标签方面的工作。Shilad Sen在论文(5)中研究了如何利用标签联系用户和物品并给用户进行个性化电影推荐。Jesse Vig在论文(6)中研究了如何利用标签进行推荐解释，他将用户和物品之间的关系转化为用户对标签的兴趣（tag preference） 以及标签和物品的相关度（tag relevance）两种因素。同时他们研究了如何对标签进行清理(7)，以及如何选择合适的标签进行解释。 (1):比赛介绍见 http://www.kde.cs.uni-kassel.de/ws/rsdc08/program.html。(2):参见Panagiotis Symeonidis、Alexandros Nanopoulos和Yannis Manolopoulos的“Tag recommendations based on tensor dimensionality reduction”（ACM 2008 Article，2008）。(3):参见Ralf Krestel、 Peter Fankhauser和Wolfgang Nejdl的“Latent dirichlet allocation for tag recommendation”（ACM 2009 Article，2009）。(4):参见Andreas Hotho、 Robert Jäschke、 Christoph Schmitz和Gerd Stumme的“Folkrank: A ranking algorithm for folksonomies”（Proc. FGIR 2006，2006）。(5):参见Shilad Wieland Sen、 Jesse Vig和John Riedl的“Tagommenders: Connecting Users to Items through Tags”（ACM 2009 Article，2009）。(6):参见Jesse Vig、Shilad Wieland Sen和John Riedl的“Tagsplanations: Explaining Recommendations Using Tags”（ACM 2009 Article，2009）。(7):参见Shilad Wieland Sen、F. Maxwell Harper、Adam LaPitz和John Riedl的“The quest for quality tags”（ACM 2007 Article，2007）。]]></content>
      <categories>
        <category>计算机科学与技术</category>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（三）]]></title>
    <url>%2F2018%2F11%2F26%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第3章 推荐系统冷启动问题如何在没有大量用户数据的情况下设计个性化推荐系统并且让用户对推荐结果满意从而愿意使用推荐系统，就是冷启动的问题。本章简单介绍一下冷启动问题的分类，以及如何解决不同种类的冷启动问题。 3.1 冷启动问题简介冷启动问题(cold start)主要分3类。 用户冷启动 用户冷启动主要解决如何给新用户做个性化推荐的问题。 物品冷启动 物品冷启动主要解决如何将新的物品推荐给可能对它感兴趣的用户这一问题。 系统冷启动 系统冷启动主要解决如何在一个新开发的网站上（还没有用户，也没有用户行为，只有一些物品的信息）设计个性化推荐系统，从而在网站刚发布时就让用户体验到个性化推荐服务这一问题。 对于这3种不同的冷启动问题，有不同的解决方案。一般来说，可以参考如下解决方案。 提供非个性化的推荐。 非个性化推荐的最简单例子就是热门排行榜。 利用用户注册时提供的年龄、性别等数据做粗粒度的个性化。 利用用户的社交网络账号登录（需要用户授权），导入用户在社交网站上的好友信息，然后给用户推荐其好友喜欢的物品。 要求用户在登录时对一些物品进行反馈，收集用户对这些物品的兴趣信息，然后给用户推荐那些和这些物品相似的物品。 对于新加入的物品，可以利用内容信息，将它们推荐给喜欢过和它们相似的物品的用户。 在系统冷启动时，可以引入专家的知识，通过一定的高效方式迅速建立起物品的相关度表。 3.2 利用用户注册信息用户的注册信息分3种。 人口统计学信息 包括用户的年龄、性别、职业、民族、学历和居住地。 用户兴趣的描述 有一些网站会让用户用文字描述他们的兴趣。 从其他网站导入的用户站外行为数据 比如用户通过豆瓣、新浪微博的账号登录，就可以在得到用户同意的情况下获取用户在豆瓣或者新浪微博的一些行为数据和社交网络数据。 基于人口统计学特征的推荐系统其典型代表是Bruce Krulwich开发的Lifestyle Finder(参见论文Bruce Krulwich的“Lifestyle finder : intelligent user profiling using large scale demographic data”（1997）) 。书上这部分有关于该算法的简略介绍和评测，但并没有涉及该算法是具体如何根据人口统计学属性进行分类的，详情见书。 基于注册信息的个性化推荐流程基本如下： 获取用户的注册信息； 根据用户的注册信息对用户分类； 给用户推荐他所属分类中用户喜欢的物品。 基于用户注册信息的推荐算法其核心问题是计算每种特征的用户喜欢的物品。也就是说，对于每种特征$f$，计算具有这种特征的用户对各个物品的喜好程度$p(f, i)$。$p(f,i)$可以简单地定义为物品$i$在具有$f$的特征的用户中的热门程度：$$p(f,i)=\vert N(i) \cap U(f) \vert$$其中$N(i)$是喜欢物品$i$的用户集合，$U(f)$是具有特征$f$的用户集合。 上面这种定义可以比较准确地预测具有某种特征的用户是否喜欢某个物品。但是，在这种定义下，往往热门的物品会在各种特征的用户中都具有比较高的权重。也就是说具有比较高的$\vert N (i) \vert$的物品会在每一类用户中都有比较高的$p(f ,i)$。给用户推荐热门物品并不是推荐系统的主要任务，推荐系统应该帮助用户发现他们不容易发现的物品。因此，可以将$p( f , i )$定义为喜欢物品$i$的用户中具有特征$f$的比例：$$p(f,i) = \frac {\vert N(i) \cap U(f) \vert}{\vert N(i) \vert + \alpha}$$这里分母中使用参数$\alpha$的目的是解决数据稀疏问题。比如有一个物品只被1个用户喜欢过， 而这个用户刚好就有特征$f$，那么就有$p(f,i)$。但是，这种情况并没有统计意义，因此为分母加上一个比较大的数，可以避免这样的物品产生比较大的权重。 有两个推荐系统数据集包含了人口统计学信息， 一个是 BookCrossing 数据集。另一个是Lastfm数据集。 BookCrossing数据集:参见http://www.informatik.uni-freiburg.de/~cziegler/BX/Lastfm数据集：参见http://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/lastfm-360K.html 作者在这两个数据集上做实验验证，证明基于人口统计学特征的推荐系统准确率、召回率和覆盖率确实更高，而且利用的用户人口统计学特征越多，越能准确地预测用户兴趣，详情见书。 3.3 选择合适的物品启动用户的兴趣对于通过让用户对物品进行评分来收集用户兴趣，从而对用户进行冷启动的系统，它们需要解决的首要问题就是如何选择物品让用户进行反馈。 一般来说，能够用来启动用户兴趣的物品需要具有以下特点。 比较热门 因为用户需要知道这个物品是什么，才能对它们作出准确反馈。 具有代表性和区分性 启动用户兴趣的物品不能是大众化或老少咸宜的，因为这样的物品对用户的兴趣没有区分性。 启动物品集合需要有多样性 冷启动时，由于不清楚用户的兴趣，并且用户用户兴趣的可能性非常多，为了匹配多样的兴趣，为此需要提供具有很高覆盖率的启动物品集合，这些物品能覆盖几乎所有主流的用户兴趣。 上面这些因素都是选择启动物品时需要考虑的，但还需要考虑的是如何设计一个选择启动物品集合的系统？Nadav Golbandi在论文中(“Adaptive Bootstrapping of Recommender Systems Using Decision Trees”，下载地址为 http://research.yahoo.com/pub/3502) 探讨了这个问题，提出可以用一个决策树解决这个问题。首先，给定一群用户，Nadav Golbandi用这群用户对物品评分的方差度量这群用户兴趣的一致程度。如果方差很大，说明这一群用户的兴趣不太一致，反之则说明这群用户的兴趣比较一致。 令$\sigma_u \in U’$为用户集合$U’$中所有评分的方差，Nadav Golbandi的基本思想是通过如下方式度量一个物品的区分度$D(i)$:$$D(i) = \sigma_{u \in N^+(i)} + \sigma_{u \in N^-(i)} + \sigma_{u \in \bar N(i)}$$其中，$N^+(i)$是喜欢物品i的用户集合，$N^-(i)$是不喜欢物品i的用户集合，$\bar N(i)$是没有对物品$i$评分的用户集合。$ \sigma_{u \in N^+(i)}$是喜欢物品i的用户对其他物品评分的方差，$\sigma_{u \in N^-(i)}$是不喜欢物品$i$的用户对其他物品评分的方差，$\sigma_{u \in \bar N(i)}$是没有对物品$i$评分的用户对其他物品评分的方差。也就是说，对于物品$i$，Nadav Golbandi将用户分成3类——喜欢物品i的用户、不喜欢物品i的用户和不知道物品i的用户（即没有给i评分的用户）。如果这3类用户集合内的用户对其他的物品兴趣很不一致，说明物品i具有较高的区分度。Nadav Golbandi的算法首先会从所有用户中找到具有最高区分度的物品i，然后将用户分成3类。然后在每类用户中再找到最具区分度的物品，然后将每一类用户又各自分为3类，也就是将总用户分成9类，然后这样继续下去，最终可以通过对一系列物品的看法将用户进行分类。而在冷启动时，我们从根节点开始询问用户对该节点物品的看法，然后根据用户的选择将用户放到不同的分枝，直到进入最后的叶子节点，此时我们就已经对用户的兴趣有了比较清楚的了解，从而可以开始对用户进行比较准确地个性化推荐。 3.4 利用物品的内容信息物品冷启动需要解决的问题是如何将新加入的物品推荐给对它感兴趣的用户。 第2章介绍了两种主要的推荐算法——UserCF和ItemCF算法。首先需要指出的是，UserCF算法对物品冷启动问题并不非常敏感。因为，UserCF在给用户进行推荐时，会首先找到和用户兴趣相似的一群用户，然后给用户推荐这一群用户喜欢的物品。在很多网站中，推荐列表并不是给用户展示内容的唯一列表，那么当一个新物品加入时，总会有用户从某些途径看到这些物品，对这些物品产生反馈。那么，当一个用户对某个物品产生反馈后，和他历史兴趣相似的其他用户的推荐列表中就有可能出现这一物品，从而更多的人就会对这个物品产生反馈，导致更多的人的推荐列表中会出现这一物品，因此该物品就能不断地扩散开来，从而逐步展示到对它感兴趣用户的推荐列表中。但是，有些网站中推荐列表可能是用户获取信息的主要途径，比如豆瓣网络电台。那么对于UserCF算法就需要解决第一推动力的问题，即第一个用户从哪儿发现新的物品。只要有一小部分人能够发现并喜欢新的物品，UserCF算法就能将这些物品扩散到更多的用户中。解决第一推动力最简单的方法是将新的物品随机展示给用户，但这样显然不太个性化，因此可以考虑利用物品的内容信息，将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户。对于ItemCF算法来说，物品冷启动就是一个严重的问题了。因为ItemCF算法的原理是给用户推荐和他之前喜欢的物品相似的物品。ItemCF算法会每隔一段时间利用用户行为计算物品相似度表（一般一天计算一次），在线服务时ItemCF算法会将之前计算好的物品相关度矩阵放在内存中。因此，当新物品加入时，内存中的物品相关表中不会存在这个物品，从而ItemCF算法无法推荐新的物品。解决这一问题的办法是频繁更新物品相似度表，但基于用户行为计算物品相似度是非常耗时的事情，主要原因是用户行为日志非常庞大。而且，新物品如果不展示给用户，用户就无法对它产生行为，通过行为日志计算是计算不出包含新物品的相关矩阵的。为此，我们只能利用物品的内容信息计算物品相关表，并且频繁地更新相关表（比如半小时计算一次）。 一般来说，物品的内容可以通过向量空间模型(参见维基百科Vector Space Model词条)表示，该模型会将物品表示成一个关键词向量。如果物品的内容是一些诸如导演、演员等实体的话，可以直接将这些实体作为关键词。但如果内容是文本的形式，则需要引入一些理解自然语言的技术抽取关键词。图3-11展示了从文本生成关键词向量的主要步骤。对于中文，首先要对文本进行分词，将字流变成词流，然后从词流中检测出命名实体（如人名、地名、组织名等），这些实体和一些其他重要的词将组成关键词集合， 最后对关键词进行排名，计算每个关键词的权重，从而生成关键词向量。对于物品$d$，它的内容表示成一个关键词向量如下：$$d_i = \{ (e_1,w_1),(e_2,w_2), ···\}$$其中$e_i$是关键词，$w_i$是关键词对应的权重。如果物品是文本，我们可以用信息检索领域著名的TF-IDF公式计算词的权重：$$w_i = \frac {TF(e_i)}{\log DF(e_i)}​$$ 向量空间模型的优点是简单，缺点是丢失了一些信息，比如关键词之间的关系信息。不过在绝大多数应用中，向量空间模型对于文本的分类、聚类、相似度计算已经可以给出令人满意的结果。 在给定物品内容的关键词向量后，物品的内容相似度可以通过向量之间的余弦相似度计算：$$w_{ij} = \frac {d_i \cdot d_j}{\sqrt {\Vert d_i \Vert \Vert d_j \Vert}}$$在具体计算物品之间的内容相似度时，最简单的方法当然是对两两物品都利用上面的余弦相似度公式计算相似度，如下代码简单实现了这种方法：12345def CalculateSimilarity(D): for di in D: for dj in D: w[i][j] = CosineSimilarity(di, dj) return w D是文档集合。 但这种算法的时间复杂度很高。假设有$N$个物品，每个物品平均由$m$个实体表示，那么这个算法的复杂度是$O( N^2m)$。 在实际应用中，可以首先通过建立关键词—物品的倒排表加速这一计算过程，关于这一方法已经在前面介绍UserCF和ItemCF算法时详细介绍过了，所以这里直接给出计算的代码：12345678910def CalculateSimilarity(entity-items) w = dict() ni = dict() for e,items in entity_items.items(): for i,wie in items.items(): addToVec(ni, i, wie * wie) for j,wje in items.items(): addToMat(w, i, j, wie, wje) for i, relate_items in w.items(): relate_items = &#123;x:y/math.sqrt(ni[i] * ni[x]) for x,y in relate_items.items()&#125; 得到物品的相似度之后，可以利用上一章提到的ItemCF算法的思想，给用户推荐和他历史上喜欢的物品内容相似的物品。 既然内容相似度计算简单，能频繁更新，而且能够解决物品冷启动问题，那么为什么还需要协同过滤的算法?书中这部分在MovieLens和GitHub两个数据集上进行了实验，并加以说明，详情见书。 话题模型向量空间模型在内容数据丰富时可以获得比较好的效果。以文本为例，如果是计算长文本的相似度，用向量空间模型利用关键词计算相似度已经可以获得很高的精确度。但是，如果文本很短，关键词很少，向量空间模型就很难计算出准确的相似度。举个例子，假设有两篇论文，它们的标题分别是“推荐系统的动态特性”和“基于时间的协同过滤算法研究”。如果读者对推荐系统很熟悉，可以知道这两篇文章的研究方向是类似的，但是它们标题中没有一样的关键词。其实，它们的关键词虽然不同，但却是相似的。“动态”和“基于时间”含义相似，“协同过滤”是“推荐系统”的一种算法。换句话说，这两篇文章的关键词虽然不同，但关键词所属的话题是相同的。在这种情况下，首先需要知道文章的话题分布，然后才能准确地计算文章的相似度。如何建立文章、话题和关键词的关系是话题模型（topic model）研究的重点。 代表性的话题模型有LDA。关于LDA的详细理论介绍可以参考DM Blei的论文“Latent Dirichlet Allocation” (参见David M. Blei、 Andrew Y. Ng、 Michael I. Jordan的“ Latent dirichlet allocation”（Journal of Machine Learning Research 3， 2003）)。任何模型都有一个假设，LDA作为一种生成模型，对一篇文档产生的过程进行了建模。话题模型的基本思想是，一个人在写一篇文档的时候，会首先想这篇文章要讨论哪些话题，然后思考这些话题应该用什么词描述，从而最终用词写成一篇文章。因此，文章和词之间是通过话题联系的。LDA中有3种元素，即文档、话题和词语。每一篇文档都会表现为词的集合，这称为词袋模型(bag of words)。每个词在一篇文章中属于一个话题。令$D$为文档集合，$D[i]$是第$i$篇文档。$w[i][j]$是第$i$篇文档中的第$j$个词。$z[i][j]$是第$i$篇文档中第$j$个词属于的话题。 LDA的计算过程包括初始化和迭代两部分。首先要对$z$进行初始化，而初始化的方法很简单，假设一共有$K$个话题， 那么对第$i$篇文章中的第$j$个词， 可以随机给它赋予一个话题。同时，用$NWZ(w,z)$记录词$w$被赋予话题$z$的次数，$NZD(z,d)$记录文档$d$中被赋予话题$z$的词的个数。 123456foreach document i in range(0,|D|): foreach word j in range(0, |D(i)|): z[i][j] = rand() % K NZD[z[i][j], D[i]]++ NWZ[w[i][j], z[i][j]]++ NZ[z[i][j]]++ 在初始化之后，要通过迭代使话题的分布收敛到一个合理的分布上去。伪代码如下所示： 12345678910while not converged: foreach document i in range(0, |D|): foreach word j in range(0, |D(i)|): NWZ[w[i][j], z[i][j]]-- NZ[z[i][j]]-- NZD[z[i][j], D[i]]-- z[i][j] = SampleTopic() NWZ[w[i][j], z[i][j]]++ NZ[z[i][j]]++ NZD[z[i][j], D[i]]++ LDA可以很好地将词组合成不同的话题。 在使用LDA计算物品的内容相似度时，可以先计算出物品在话题上的分布，然后利用两个物品的话题分布计算物品的相似度。比如，如果两个物品的话题分布相似，则认为两个物品具有较高的相似度，反之则认为两个物品的相似度较低。计算分布的相似度可以利用KL散度(参见http://en.wikipedia.org/wiki/Kullback-Leibler_divergence) ：$$D_{KL}(p||q) = \sum_i p(i)ln \frac{p(i)}{q(i)}$$其中$p$和$q$是两个分布，KL散度越大说明分布的相似度越低。 3.5 发挥专家的作用书中这部分对个性化网络电台Pandora和电影推荐网站Jinni如何利用专家对物品进行标注，进而建立推荐系统作了介绍。]]></content>
      <categories>
        <category>计算机科学与技术</category>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（二）]]></title>
    <url>%2F2018%2F11%2F24%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第2章 利用用户行为数据用户行为数据中蕴涵着很多不是那么显而易见的规律，而个性化推荐算法的任务就是通过计算机去发现这些规律，从而为产品的设计提供指导，提高用户体验。基于用户行为分析的推荐算法是个性化推荐系统的重要算法，学术界一般将这种类型的算法称为协同过滤算法。顾名思义，协同过滤就是指用户可以齐心协力，通过不断地和网站互动，使自己的推荐列表能够不断过滤掉自己不感兴趣的物品，从而越来越满足自己的需求。 2.1 用户行为数据简介用户行为数据的存在形式用户行为数据在网站上最简单的存在形式就是日志。网站在运行过程中都产生大量原始日志(raw log)，并将其存储在文件系统中。很多互联网业务会把多种原始日志按照用户行为汇总成会话日志(session log)，其中每个会话表示一次用户行为和对应的服务。比如，在搜索引擎和搜索广告系统中，服务会为每次查询生成一个展示日志(impression log)，其中记录了查询和返回结果。如果用户点击了某个结果，这个点击信息会被服务器截获并存储在点击日志(click log)中。 一个并行程序会周期性地归并展示日志和点击日志，得到的会话日志中每个消息是一个用户提交的查询、得到的结果以及点击。类似地，推荐系统和电子商务网站也会汇总原始日志生成描述用户行为的会话日志。 用户行为数据的分类用户行为在个性化推荐系统中一般分两种——显性反馈行为(explicit feedback)和隐性反馈行为(implicit feedback)。显性反馈行为包括用户明确表示对物品喜好的行为，主要形式就是评分和喜欢/不喜欢。和显性反馈行为相对应的是隐性反馈行为。隐性反馈行为指的是那些不能明确反应用户喜好的行为。最具代表性的隐性反馈行为就是页面浏览行为。按照反馈的明确性分，用户行为数据可以分为显性反馈和隐性反馈，但按照反馈的方向分，又可以分为正反馈和负反馈。正反馈指用户的行为倾向于指用户喜欢该物品，而负反馈指用户的行为倾向于指用户不喜欢该物品。在显性反馈中，很容易区分一个用户行为是正反馈还是负反馈，而在隐性反馈行为中，就相对比较难以确定。 显性反馈数据和隐性反馈数据的区别下图从几个方面比较了显性反馈数据和隐性反馈数据。 用户行为的表示方式下图给出了一种表示方式，它将一个用户行为表示为六部分，即产生行为的用户和行为的对象。行为的种类、产生行为的上下文、行为的内容和权重。很多时候我们并不使用统一结构表示所有行为，而是针对不同的行为给出不同表示。有时可能会忽略一些信息(比如上下文)，但有些信息不能忽略(比如产生行为的用户和行为的对象就是所有行为都必须包含的)。 数据集的分类不同的数据集针对不同的情况，根据所包含行为的不同将数据集进行分类，目前比较有代表性的数据集有如下几个： 无上下文信息的隐性反馈数据集 每一条行为记录仅仅包含用户ID和物品ID。Book-Crossing(参见“Book-Crossing Dataset”，地址为http://www.informatik.uni-freiburg.de/~cziegler/BX/) 就是这种类型的数据集。 无上下文信息的显性反馈数据集 每一条记录包含用户ID、物品ID和用户对物品的评分。 有上下文信息的隐性反馈数据集 每一条记录包含用户ID、物品ID和用户对物品产生行为的时间戳。Lastfm数据集(参见http://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/lastfm-1K.html) 就是这种类型的数据集。 有上下文信息的显性反馈数据集 每一条记录包含用户ID、物品ID、用户对物品的评分和评分行为发生的时间戳。Netflix Prize(参见http://netflixprize.com/) 提供的就是这种类型的数据集。 2.2 用户行为分析在利用用户行为数据设计推荐算法之前，研究人员首先需要对用户行为数据进行分析，了解数据中蕴含的一般规律，这样才能对算法的设计起到指导作用。 2.2.1 用户活跃度和物品流行度的分布长尾分布很多关于互联网数据的研究发现，互联网上的很多数据分布都满足一种称为Power Law(参见“浅谈网络世界的Power Law现象”，地址为http://mmdays.com/2008/11/22/power_law_1/) 的分布，这个分布在互联网领域也称长尾分布。$$f(x) = \alpha x^k$$1932年，哈佛大学的语言学家Zipf在研究英文单词的词频时发现，如果将单词出现的频率按照由高到低排列，则每个单词出现的频率和它在热门排行榜中排名的常数次幂成反比。这个现象表明，在英文中大部分词的词频其实很低，只有很少的词被经常使用。用户行为数据也蕴含着这种规律。令$f_u(k)$为对k个物品产生过行为的用户数，令$f_i(k)$为被k个用户产生过行为的物品数。那么，$f_u(k)$和$f_i(k)$都满足长尾分布。也就是说：$$f_u(k)= \alpha_u k^{\beta_u}$$ $$f_i(k)= \alpha_i k^{\beta_i}$$ 2.2.2 用户活跃度和物品流行度的关系用户越活跃，越倾向于浏览冷门的物品。仅仅基于用户行为数据设计的推荐算法一般称为协同过滤算法。 学术界对协同过滤算法进行了深入研究，提出了很多方法，比如基于邻域的方法（ neighborhood-based ）、隐语义模型（ latent factor model）、基于图的随机游走算法（random walk on graph）等。在这些方法中，最著名的、在业界得到最广泛应用的算法是基于邻域的方法， 而基于邻域的方法主要包含下面两种算法。 基于用户的协同过滤算法 基于物品的协同过滤算法 2.3 实验设计和算法评测2.3.1 数据集采用GroupLens提供的MovieLens数据集(数据集详细信息见 http://www.grouplens.org/node/73) 介绍和评测各种算法，并且忽略了数据集中的评分记录。 2.3.2 实验设计协同过滤算法的离线实验一般如下设计。首先，将用户行为数据集按照均匀分布随机分成M份，挑选一份作为测试集，将剩下的M-1份作为训练集。然后在训练集上建立用户兴趣模型，并在测试集上对用户行为进行预测，统计出相应的评测指标。为了保证评测指标并不是过拟合的结果，需要进行M次实验，并且每次都使用不同的测试集。然后将M次实验测出的评测指标的平均值作为最终的评测指标。 下面的代码描述了将数据集随机分成训练集和测试集的过程： 12345678910def SplitData(data, M, k, seed): test = [] train = [] random.seed(seed) for user, item in data: if random.randint(0,M) == k: test.append([user,item]) else: train.append([user,item]) return train, test 这里，每次实验选取不同的k（0≤k≤M-1）和相同的随机数种子seed，进行M次实验就可以得到M个不同的训练集和测试集，然后分别进行实验，用M次实验的平均值作为最后的评测指标。这样做主要是防止某次实验的结果是过拟合的结果（over fitting），但如果数据集够大，模型够简单，为了快速通过离线实验初步地选择算法，也可以只进行一次实验。 2.3.3 评测指标召回率和准确率计算方法和第一章预测准确度中TopN推荐部分一样 覆盖率同样与之前介绍的一致。如下代码可以用来计算推荐算法的覆盖率： 12345678910def Coverage(train, test, N): recommend_items = set() all_items = set() for user in train.keys(): for item in train[user].keys(): all_items.add(item) rank = GetRecommendation(user, N) for item, pui in rank: recommend_items.add(item) return len(recommend_items) / (len(all_items) * 1.0) 新颖度使用推荐列表中物品的平均流行度度量推荐结果的新颖度。如果推荐出的物品都很热门，说明推荐的新颖度较低，否则说明推荐结果比较新颖。 12345678910111213141516def Popularity(train, test, N): item_popularity = dict() for user, items in train.items(): for item in items.keys() if item not in item_popularity: item_popularity[item] = 0 item_popularity[item] += 1 ret = 0 n = 0 for user in train.keys(): rank = GetRecommendation(user, N) for item, pui in rank: ret += math.log(1 + item_popularity[item]) n += 1 ret /= n * 1.0 return ret 计算平均流行度时对每个物品的流行度取对数，这是因为物品的流行度分布满足长尾分布，在取对数后，流行度的平均值更加稳定。 2.4 基于近邻的算法基于邻域的算法分为两大类，一类是基于用户的协同过滤算法，另一类是基于物品的协同过滤算法。 2.4.1 基于用户的协同过滤算法(UserCF算法)基于用户的协同过滤算法是推荐系统中最古老的算法。这个算法的诞生标志了推荐系统的诞生。该算法在1992年被提出，并应用于邮件过滤系统，1994年被GroupLens用于新闻过滤。在此之后直到2000年，该算法都是推荐系统领域最著名的算法。 1.基础算法在一个在线个性化推荐系统中，当一个用户A需要个性化推荐时，可以先找到和他有相似兴趣的其他用户，然后把那些用户喜欢的、而用户A没有听说过的物品推荐给A。这种方法称为基于用户的协同过滤算法。基于用户的协同过滤算法主要包括两个步骤。 找到和目标用户兴趣相似的用户集合。 找到这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户。 步骤(1)的关键是计算两个用户的兴趣相似度。协同过滤算法主要利用行为的相似度计算兴趣的相似度。给定用户u和用户v，令$N(u)$表示用户u曾经有过正反馈的物品集合，令$N(v)$为用户v曾经有过正反馈的物品集合。可以通过如下的Jaccard公式简单计算用户u和用户v的兴趣相似度：$$w_{uv} = \frac{|N(u) \cap N(v)|}{|N(u) \cup N(v)|}$$或者通过余弦相似度计算：$$w_{uv} = \frac{|N(u) \cap N(v)|}{\sqrt{|N(u)||N(v)|}}$$实现余弦相似度可以利用如下的伪码： 123456789def UserSimilarity(train): W = dict() for u in train.keys(): for v in train.keys(): if u == v: continue W[u][v] = len(train[u] &amp; train[v]) W[u][v] /= math.sqrt(len(train[u]) * len(train[v]) * 1.0) return W 该代码对两两用户都利用余弦相似度计算相似度。这种方法的时间复杂度是$O(|U|*|U|)$，这在用户数很大时非常耗时。由于实际上很多用户户相互之间并没有对同样的物品产生过行为，即$|N(u)\cap N(v)| = 0 $，因此会将很多时间浪费在计算用户之间相似度上。换个思路，首先计算出$|N(u)\cap N(v)|\neq 0$的用户对$(u, v)$，然后再对这种情况除以分母$\sqrt{|N(u)||N(v)|}$。为此，首先建立物品到用户的倒排表，对于每个物品都保存对该物品产生过行为的用户列表。令稀疏矩阵$C[u][v]= N(u) \cap N(v)$ 。那么，假设用户u和用户v同时属于倒排表中K个物品对应的用户列表，就有$C[u][v]=K$。从而，可以扫描倒排表中每个物品对应的用户列表，将用户列表中的两两用户对应的$C[u][v]$加1，最终就可以得到所有用户之间不为0的$C[u][v]$。下面的代码实现了上面提到的算法： 12345678910111213141516171819202122232425def UserSimilarity(train): # build inverse table for item_users item_users = dict() for u, items in train.items(): for i in items.keys(): if i not in item_users: item_users[i] = set() item_users[i].add(u) #calculate co-rated items between users C = dict() N = dict() for i, users in item_users.items(): for u in users: N[u] += 1 for v in users: if u == v: continue C[u][v] += 1 #calculate finial similarity matrix W W = dict() for v, cuv in related_users.items(): W[u][v] = cuv / math.sqrt(N[u] * N[v]) return W 得到用户之间的兴趣相似度后，UserCF算法会给用户推荐和他兴趣最相似的K个用户喜欢的物品。如下的公式度量了UserCF算法中用户u对物品i的感兴趣程度：$$p(u,i)=\sum_{v \in S(u,K) \cap N(i)} w_{uv}r_{vi}$$其中，$S(u,K)$包含和用户u兴趣最接近的K个用户，$N(i)$是对物品i有过行为的用户集合，$w_{uv}$是用户u和用户v的兴趣相似度，$r_{vi}$代表用户v对物品i的兴趣，因为使用的是单一行为的隐反馈数据，所以所有的$r_{vi}=1$。 如下代码实现了上面的UserCF推荐算法： 1234567891011def Recommend(user, train, W): rank = dict() interacted_items = train[user] for v, wuv in sorted(W[u].items, key=itemgetter(1), \ reverse=True)[0:K]: for i, rvi in train[v].items: if i in interacted_items: # we should filter items user interacted before continue rank[i] += wuv * rvi return rank 参数K是UserCF的一个重要参数，它的调整对推荐算法的各种指标都会产生一定的影响。 准确率和召回率 选择合适的K对于获得高的推荐系统精度比较重要。推荐结果的精度对K也不是特别敏感，只要选在一定的区域内，就可以获得不错的精度。 流行度 K越大，参考的人越多，结果就越来越趋近于全局热门的物品。 覆盖率 K越大，则UserCF推荐结果的覆盖率越低。覆盖率的降低是因为流行度的增加，随着流行度增加，UserCF越来越倾向于推荐热门的物品，从而对长尾物品的推荐越来越少，因此造成了覆盖率的降低。 2.用户相似度计算的改进之前介绍的通过余弦相似度公式计算兴趣相似度，但是由于这个公式过于粗糙，于是需要改进该公式来提高UserCF的推荐性能。研究表明，用户对冷门物品采取与热门物品同样的行为更能说明他们兴趣的相似度。因此，John S. Breese在论文(参见John S. Breese、 David Heckerman和 Carl Kadie的论文“ Empirical Analysis of Predictive Algorithms for Collaborative Filtering”（Morgan Kaufmann Publishers，1998）)中提出了如下公式，根据用户行为计算用户的兴趣相似度：$$w_{uv} = \frac {\sum_{i \in N(u) \cap N(v)}\frac{1}{\log 1 + |N(i)|}}{\sqrt{|N(u)||N(v)|}}$$该公式通过$\frac{1}{\log 1 + |N(i)|}$惩罚了用户u和用户v共同兴趣列表中热门物品对他们相似度的影响。 将基于上述用户相似度公式的UserCF算法记为User-IIF算法。下面的代码实现了上述用户相似度公式。 1234567891011121314151617181920212223242526def UserSimilarity(train): # build inverse table for item_users item_users = dict() for u, items in train.items(): for i in items.keys(): if i not in item_users: item_users[i] = set() item_users[i].add(u) #calculate co-rated items between users C = dict() N = dict() for i, users in item_users.items(): for u in users: N[u] += 1 for v in users: if u == v: continue C[u][v] += 1 / math.log(1 + len(users)) #calculate finial similarity matrix W W = dict() for u, related_users in C.items(): for v, cuv in related_users.items(): W[u][v] = cuv / math.sqrt(N[u] * N[v]) return W 通过实验评测证明计算用户兴趣相似度时考虑物品的流行度对提升推荐效果的质量确实有帮助。 3.实际在线系统中使用UserCF的例子相比我们后面要讨论的基于物品的协同过滤算法(ItemCF)，UserCF在目前的实际应用中使用并不多。其中最著名的使用者是Digg，书中这部分介绍了Digg的推荐系统设计思路。 4.UserCF算法的缺点首先，随着网站的用户数目越来越大，计算用户兴趣相似度矩阵将越来越困难，其运算时间复杂度和空间复杂度的增长和用户数的增长近似于平方关系。其次，基于用户的协同过滤很难对推荐结果作出解释。 2.4.2 基于物品的协同过滤算法(ItemCF)基于物品的协同过滤（item-based collaborative filtering）算法是目前业界应用最多的算法。无论是亚马逊网，还是Netflix、Hulu、YouTube，其推荐算法的基础都是该算法。 1.基础算法ItemCF算法并不利用物品的内容属性计算物品之间的相似度，它主要通过分析用户的行为记录计算物品之间的相似度。该算法认为，物品A和物品B具有很大的相似度是因为喜欢物品A的用户大都也喜欢物品B 。 基于物品的协同过滤算法主要分为两步： 计算物品之间的相似度。 根据物品的相似度和用户的历史行为给用户生成推荐列表。 为了避免推荐出热门的商品，用下面的公式定义物品的相似度：$$w_{ij}=\frac {|N(i)\cap N(j)|} {\sqrt{|N(i)||N(j)|}}$$这个公式惩罚了物品j的权重，因此减轻了热门物品会和很多物品相似的可能性。 和UserCF算法类似，用ItemCF算法计算物品相似度时也可以首先建立用户—物品倒排表（即对每个用户建立一个包含他喜欢的物品的列表），然后对于每个用户，将他物品列表中的物品两两在共现矩阵C中加1。 详细代码如下所示：123456789101112131415161718def ItemSimilarity(train): #calculate co-rated users between items C = dict() N = dict() for u, items in train.items(): for i in users: N[i] += 1 for j in users: if i == j: continue C[i][j] += 1 #calculate finial similarity matrix W W = dict() for i,related_items in C.items(): for j, cij in related_items.items(): W[u][v] = cij / math.sqrt(N[i] * N[j]) return W 在得到物品之间的相似度后，ItemCF通过如下公式计算用户u对一个物品j的兴趣：$$p_{uj}=\sum_{i\in N(u) \cap S(j,K)} {w_{ji}r_{ui}} $$这里$N(u)$是用户喜欢的物品的集合，$S(j,K)$是和物品$j$最相似的$K$个物品的集合，$w_{ji}$是物品$j$和$i$的相似度，$r_{ui}$是用户$u$对物品$i$的兴趣。（对于隐反馈数据集，如果用户$u$对物品$i$有过行为，即可令$r_{ui}$ =1。）该公式的含义是，和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名。 该公式的实现代码如下所示。123456789def Recommendation(train, user_id, W, K): rank = dict() ru = train[user_id] for i,pi in ru.items(): for j, wj in sorted(W[i].items(), / key=itemgetter(1), reverse=True)[0:K]: if j in ru: continue rank[j] += pi * wj return rank ItemCF的一个优势就是可以提供推荐解释，即利用用户历史上喜欢的物品为现在的推荐结果进行解释。 如下代码实现了带解释的ItemCF算法：12345678910def Recommendation(train, user_id, W, K): rank = dict() ru = train[user_id] for i,pi in ru.items(): for j, wj in sorted(W[i].items(), / key=itemgetter(1), reverse=True)[0:K]: if j in ru: continue rank[j].weight += pi * wj rank[j].reason[i] = pi * wj return rank 参数K同样也是ItemCF算法中的一个重要参数。 精度(准确率和召回率) ItemCF推荐结果的精度也是不和K成正相关或者负相关的，因此选择合适的K对获得最高精度是非常重要的。 流行度 和UserCF不同，参数K对ItemCF推荐结果流行度的影响也不是完全正相关的。随着K的增加，结果流行度会逐渐提高，但当K增加到一定程度，流行度就不会再有明显变化。 覆盖率 K增加会降低系统的覆盖率。 2.用户活跃度对物品相似度的影响John S. Breese在论文中(参见John S. Breese、 David Heckerman和 Carl Kadie的“ Empirical Analysis of Predictive Algorithms for Collaborative Filtering”（Morgan Kaufmann Publishers ，1998）)提出了一个称为IUF(Inverse User Frequence)，即用户活跃度对数的倒数的参数，他认为活跃用户对物品相似度的贡献应该小于不活跃的用户，他提出应该增加IUF 参数来修正物品相似度的计算公式：$$w_{ij}=\frac{\sum_{u\in N(i)\cap N(j)} \frac{1}{\log1 + |N(u)|}}{\sqrt{|N(i)||N(j)|}}$$ 上面的公式只是对活跃用户做了一种软性惩罚，对于很多过于活跃的用户，为了避免相似度矩阵过于稠密，在实际计算中一般直接忽略他的兴趣列表，而不将其纳入到相似度计算的数据集中。 下面代码实现了改进后的算法，并将改进后的算法记为ItemCF-IUF：123456789101112131415161718def ItemSimilarity(train): #calculate co-rated users between items C = dict() N = dict() for u, items in train.items(): for i in users: N[i] += 1 for j in users: if i == j: continue C[i][j] += 1 / math.log(1 + len(items) * 1.0) #calculate finial similarity matrix W W = dict() for i,related_items in C.items(): for j, cij in related_items.items(): W[u][v] = cij / math.sqrt(N[i] * N[j]) return W 通过离线算法评测该算法证明，ItemCF-IUF在准确率和召回率两个指标上和ItemCF相近，但ItemCF-IUF明显提高了推荐结果的覆盖率，降低了推荐结果的流行度。从这个意义上说，ItemCF-IUF确实改进了ItemCF的综合性能。 3.物品相似度的归一化Karypis在研究中发现如果将ItemCF的相似度矩阵按最大值归一化，可以提高推荐的准确率(参见George Karypis的论文“ Evaluation of Item-based Top-N Recommendation Algorithms”)。其研究表明，如果已经得到了物品相似度矩阵w，那么可以用如下公式得到归一化之后的相似度矩阵$w’$：$$w_{ij}’ = \frac{w_{ij}}{max_j{w_{ij}}}$$归一化的好处不仅仅在于增加推荐的准确度，它还可以提高推荐的覆盖率和多样性。从实验结果可以看到，归一化确实能提高ItemCF的性能，其中各项指标都有了比较明显的提高。 2.4.3 UserCF和ItemCF的综合比较UserCF和ItemCF的应用领域比较及原因UserCF多被用于新闻推荐比如Digg，而ItemCF则在电子商务和书籍电影推荐方面得到广泛应用比如Amazon和Netflix。UserCF的推荐结果着重于反映和用户兴趣相似的小群体的热点，而ItemCF 的推荐结果着重于维系用户的历史兴趣。换句话说，UserCF的推荐更社会化，反映了用户所在的小型兴趣群体中物品的热门程度，而ItemCF的推荐更加个性化，反映了用户自己的兴趣传承。在新闻网站中，用户的兴趣不是特别细化，绝大多数用户都喜欢看热门的新闻。即使是个性化，也是比较粗粒度的。因此，个性化新闻推荐更加强调抓住新闻热点，热门程度和时效性是个性化新闻推荐的重点，而个性化相对于这两点略显次要。因此，UserCF可以给用户推荐和他有相似爱好的一群其他用户今天都在看的新闻，这样在抓住热点和时效性的同时， 保证了一定程度的个性化。 这是 Digg在新闻推荐中使用UserCF的最重要原因。UserCF适合用于新闻推荐的另一个原因是从技术角度考量的。因为作为一种物品，新闻的更新非常快，每时每刻都有新内容出现，而ItemCF需要维护一张物品相关度的表，如果物品更新很快，那么这张表也需要很快更新，这在技术上很难实现。绝大多数物品相关度表都只能做到一天一次更新，这在新闻领域是不可以接受的。而UserCF只需要用户相似性表，虽然UserCF对于新用户也需要更新相似度表，但在新闻网站中，物品的更新速度远远快于新用户的加入速度，而且对于新用户，完全可以给他推荐最热门的新闻，因此UserCF显然是利大于弊。但是，在图书、电子商务和电影网站，比如亚马逊、豆瓣、Netflix中，ItemCF则能极大地发挥优势。首先，在这些网站中，用户的兴趣是比较固定和持久的。而且这些网站中有一些活跃度很高的人，例如技术人员。一个技术人员可能都是在购买 技术方面的书，而且他们对书的热门程度并不是那么敏感，事实上越是资深的技术人员，他们看的书就越可能不热门。此外，这些系统中的用户大都不太需要流行度来辅助他们判断一个物品的 好坏，而是可以通过自己熟悉领域的知识自己判断物品的质量。因此，这些网站中个性化推荐的任务是帮助用户发现和他研究领域相关的物品。因此，ItemCF算法成为了这些网站的首选算法。 此外，这些网站的物品更新速度不会特别快，一天一次更新物品相似度矩阵对它们来说不会造成太大的损失，是可以接受的。同时，从技术上考虑，UserCF需要维护一个用户相似度的矩阵，而ItemCF需要维护一个物品相似度矩阵。从存储的角度说，如果用户很多，那么维护用户兴趣相似度矩阵需要很大的空间， 同理，如果物品很多，那么维护物品相似度矩阵代价较大。在早期的研究中，大部分研究人员都是让少量的用户对大量的物品进行评价，然后研究用户兴趣的模式。对于他们来说，因为用户很少，计算用户兴趣相似度是最快也是最简单的方法。但在实际的互联网中，用户数目往往非常庞大，而在图书、电子商务网站中，物品的数目则是比较少的。此外，物品的相似度相对于用户的兴趣一般比较稳定，因此使用ItemCF是比较好的选择。当然，新闻网站是个例外，在那儿，物品的相似度变化很快，物品数目庞大， 相反用户兴趣则相对固定（都是喜欢看热门的），所以新闻网站的个性化推荐使用UserCF算法的更多。 UserCF与ItemCF的性能比较及原因离线实验结果可见，ItemCF算法在各项指标上似乎都不如UserCF，特别是其推荐结果的覆盖率和新颖度都低于UserCF。似乎与之前所说的不符合。首先要指出的是，离线实验的性能在选择推荐算法时并不起决定作用。首先应该满足产品的需求，比如如果需要提供推荐解释，那么可能得选择ItemCF算法。其次，需要看实现代价，比如若用户太多，很难计算用户相似度矩阵，这个时候可能不得不抛弃UserCF算法。最后，离线指标和点击率等在线指标不一定成正比。而且，这里对比的是最原始的UserCF和ItemCF算法，这两种算法都可以进行各种各样的改进。一般来说，这两种算法经过优化后，最终得到的离线性能是近似的。 哈利波特问题亚马逊网的研究人员在设计ItemCF算法之初发现ItemCF算法计算出的图书相关表存在一个问题，就是很多书都和《哈利波特》相关。 也就是说，购买任何一本书的人似乎都会购买《哈利波特》。后来他们研究发现，主要是因为《哈利波特》太热门了，确实是购买任何一本书的人几乎都会购买它。回顾一下ItemCF计算物品相似度的经典公式：$$w_{ij}=\frac {\vert N(i)\cap N(j) \vert} {\sqrt{\vert N(i)||N(j)\vert}}$$这个问题的原因是，如果j非常热门， 那么上面公式的分子$N (i ) \cap N ( j )$就会越来越接近$N (i)$。 尽管上面的公式分母已经考虑到了$j$的流行度，但在实际应用中，热门的j仍然会获得比较大的相似度。 哈利波特问题有几种解决方案。第一种是在分母上加大对热门物品的惩罚，比如采用如下公式：$$w_{ij} = \frac {\vert N(i) \cap N(j) \vert}{\vert N(i)\vert^{1-\alpha} \vert N(j)\vert^{\alpha}}$$其中$\alpha \in [0.5,1]$。通过提高$\alpha$，就可以惩罚热门的j。 如果α＝0.5就是标准的ItemCF算法。从离线实验结果可以看到，α只有在取值为0.5时才会导致最高的准确率和召回率，而无论α＜0.5或者α＞0.5都不会带来这两个指标的提高。但是，如果看覆盖率和平均流行度就可以发现，α越大，覆盖率就越高，并且结果的平均热门程度会降低。因此，通过这种方法可以在适当牺牲准确率和召回率的情况下显著提升结果的覆盖率和新颖性（降低流行度即提高了新颖性）。上述方法还不能彻底地解决哈利波特问题。每个用户一般都会在不同的领域喜欢一种物品。两个不同领域的最热门物品之间往往具有比较高的相似度。这个时候，仅仅靠用户行为数据是不能解决这个问题的，因为用户的行为表示这种物品之间应该相似度很高。此时，我们只能依靠引入物品的内容数据解决这个问题，比如对不同领域的物品降低权重等。这些就不是协同过滤讨论的范畴了。 2.5 隐语义模型自从Netflix Prize比赛举办以来，LFM（latent factor model）隐语义模型逐渐成为推荐系统领域耳熟能详的名词。其实该算法最早在文本挖掘领域被提出，用于找到文本的隐含语义。 2.5.1 基础算法隐语义模型的核心思想是通过特征(latent factor)联系用户兴趣和物品。针对推荐问题除了UserCF、ItemCF算法，还有一种方法就是根据用户的兴趣进行分类。对于某个用户，首先得到他的兴趣分类，然后从分类中挑选他可能喜欢的物品。这个基于兴趣分类的方法大概需要解决3个问题： 如何给物品进行分类？ 如何确定用户对哪些类的物品感兴趣，以及感兴趣的程度？ 对于一个给定的类，选择哪些属于这个类的物品推荐给用户，以及如何确定这些物品在一个类中的权重？ 对于第一个问题的简单解决方案是找编辑给物品分类。但是，即使有很系统的分类体系，编辑给出的分类仍然具有以下缺点。 编辑的意见不能代表各种用户的意见。编辑的分类大部分是从书的内容出 发，而不是从书的读者群出发。 编辑很难控制分类的粒度。 编辑很难给一个物品多个分类。有的书不仅属于一个类，而是可能属于很多的类。 编辑很难给出多维度的分类。 编辑很难决定一个物品在某一个分类中的权重。 为了解决上面的问题，研究人员提出：为什么我们不从数据出发，自动地找到那些类，然后进行个性化推荐？于是，隐含语义分析技术（latent variable analysis）出现了。隐含语义分析技术因为采取基于用户行为统计的自动聚类，较好地解决了上面提出的5个问题。 编辑的意见不能代表各种用户的意见，但隐含语义分析技术的分类来自对用户行为的统计，代表了用户对物品分类的看法。隐含语义分析技术和ItemCF在物品分类方面的思想类似，如果两个物品被很多用户同时喜欢，那么这两个物品就很有可能属于同一个类。 编辑很难控制分类的粒度，但隐含语义分析技术允许我们指定最终有多少个分类，这个数字越大，分类的粒度就会越细，反正分类粒度就越粗。 编辑很难给一个物品多个分类，但隐含语义分析技术会计算出物品属于每个类的权重，因此每个物品都不是硬性地被分到某一个类中。 编辑很难给出多维度的分类，但隐含语义分析技术给出的每个分类都不是同一个维度的，它是基于用户的共同兴趣计算出来的，如果用户的共同兴趣是某一个维度，那么LFM给出的类也是相同的维度。 编辑很难决定一个物品在某一个分类中的权重，但隐含语义分析技术可以通过统计用户行为决定物品在每个类中的权重，如果喜欢某个类的用户都会喜欢某个物品，那么这个物品在这个类中的权重就可能比较高。 隐含语义分析技术从诞生到今天产生了很多著名的模型和方法，其中和该技术相关且耳熟能详的名词有pLSA、LDA、隐含类别模型（latent class model）、隐含主题模型（latent topic model）、矩阵分解（matrix factorization）。这些技术和方法在本质上是相通的，其中很多方法都可以用于个性化推荐系统。 LFM通过如下公式计算用户u对物品i的兴趣：$$Preference(u,i)=r_{ui}=p_u^Tq_i=\sum_{f=1}^F p_{u,k} q_{i,k}$$这个公式中$p_{u,k}$和$q_{i,k}$是模型的参数，其中$p_{u,k}$度量了用户u的兴趣和第k个隐类的关系，而$q_{i,k}$度量了第k个隐类和物品i之间的关系。 要计算这两个参数，需要一个训练集，对于每个用户u，训练集里都包含了用户u喜欢的物品和不感兴趣的物品，通过学习这个数据集，就可以获得上面的模型参数。 LFM在显性反馈数据（也就是评分数据）上解决评分预测问题并达到了很好的精度。不过本章主要讨论的是隐性反馈数据集，这种数据集的特点是只有正样本（用户喜欢什么物品），而没有负样本（用户对什么物品不感兴趣）。在隐性反馈数据集上应用LFM解决TopN推荐的第一个关键问题就是如何给每个用户生成负样本。 对于这个问题，Rong Pan在文章(参见“One-Class Collaborative Filtering”)中进行了深入探讨。他对比了如下几种方法。 对于一个用户，用他所有没有过行为的物品作为负样本。 对于一个用户，从他没有过行为的物品中均匀采样出一些物品作为负样本。 对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，保证每个用户的正负样本数目相当。 对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，偏重采样不热门的物品。 对于第一种方法，它的明显缺点是负样本太多，正负样本数目相差悬殊，因而计算复杂度很高，最终结果的精度也很差。对于另外3种方法，Rong Pan在文章中表示第三种好于第二种，而第二种好于第四种。 作者认为对负样本采样时应该遵循以下原则： 对每个用户，要保证正负样本的平衡（数目相似）。 对每个用户采样负样本时，要选取那些很热门，而用户却没有行为的物品。 下面的代码实现了负样本采样过程： 1234567891011121314def RandomSelectNegativeSample(self, items): ret = dict() for i in items.keys(): ret[i] = 1 n = 0 for i in range(0, len(items) * 3): # 将上限设为len(items) * 3，主要是保证正、负样本数量接近 item = items_pool[random.randint(0, len(items_pool) - 1)] if item in ret: continue ret[item] = 0 n + = 1 if n &gt; len(items): break return ret 在上面的代码中，items_pool维护了候选物品的列表，在这个列表中，物品i出现的次数和物品i的流行度成正比。items是一个dict，它维护了用户已经有过行为的物品的集合。因此，上面的代码按照物品的流行度采样出了那些热门的、但用户却没有过行为的物品。经过采样，可以得到一个用户—物品集$K = {(u,i)}$，其中如果$(u, i)$是正样本，则有$r_{ui}$ = 1，否则有$r_{ui}$ = 0 。然后， 需要优化如下的损失函数来找到最合适的参数p和q：$$C = \sum_{(u,i) \in K} (r_{ui} - \hat r_{ui})^2 = \sum_{(u,i) \in K}(r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})^2 + \lambda \Vert p_u \Vert^2 + \lambda \Vert q_i \Vert^2$$这里$\lambda \Vert p_u \Vert^2 + \lambda \Vert q_i \Vert^2$用来防止过拟合的正则化项，$\lambda$可以通过实验获得。最小化上面的损失函数，可以利用随机梯度下降算法。该算法是最优化理论里最基础的优化算法，它首先通过求参数的偏导数找到最速下降方向，然后通过迭代法不断地优化参数。下面介绍优化方法的数学推导。 上面定义的损失函数里有两组参数$p_{u,k}$和$q_{i,k}$，随机梯度下降法需要首先对它们分别求偏导数，可以得到：$$\frac{\partial C}{\partial p_{uk}} = -2q_{ik} + 2\lambda p_{uk}$$ $$\frac{\partial C}{\partial q_{ik}} = -2p_{uk} + 2\lambda q_{ik}$$ 然后，根据随机梯度下降法，需要将参数沿着最速下降方向向前推进，因此可以得到如下递推公式：$$p_{uk}=p_{uk} + \alpha(q_{ik}-\lambda p_{uk})$$ $$q_{ik} = q_{ik} + \alpha (p_{uk} - \lambda q_{ik})$$其中，$\alpha$是学习速率(learning rate)，它的选取需要通过反复实验获得。 下面的Python代码实现了这一优化过程：12345678910111213141516171819def LatentFactorModel(user_items, F, N, alpha, lambda): [P, Q] = InitModel(user_items, F) for step in range(0,N): for user, items in user_items.items(): samples = RandSelectNegativeSamples(items) for item, rui in samples.items(): eui = rui - Predict(user, item) for f in range(0, F): P[user][f] += alpha * (eui * Q[item][f] - \ lambda * P[user][f]) Q[item][f] += alpha * (eui * P[user][f] - \ lambda * Q[item][f]) alpha *= 0.9def Recommend(user, P, Q): rank = dict() for f, puf in P[user].items(): for i, qfi in Q[f].items(): if i not in rank: rank[i] += puf * qfi return rank 经过离线实验评测证明，LFM确实可以实现通过用户行为将物品聚类的功能。 在LFM中，重要的参数有4个： 隐特征的个数F； 学习速率alpha； 正则化参数lambda； 负样本/正样本比例 ratio。 通过实验发现， ratio 参数对LFM的性能影响最大。随着负样本数目的增加， LFM 的准确率和召回率有明显提高。 不过当ratio&gt;10以后，准确率和召回率基本就比较稳定了。同时，随着负样本数目的增加，覆盖率不断降低，而推荐结果的流行度不断增加，说明ratio参数控制了推荐算法发掘长尾的能力。当数据集非常稀疏时，LFM的性能会明显下降，甚至不如UserCF和ItemCF的性能。 2.5.2 基于LFM的实际系统的例子雅虎的研究人员公布过一个使用LFM进行雅虎首页个性化设计的方案(参见Bee-Chung Chen、Deepak Agarwal、Pradheep Elango和Raghu Ramakrishnan的“Latent Factor Models for Web Recommender Systems”)。 雅虎的研究人员以CTR作为优化目标，利用LFM来预测用户是否会单击一个链接。为此， 他们将用户历史上对首页上链接的行为记录作为训练集。其中，如果用户u单击过链接i，那么就定义$(u, i)$是正样本，即$r_{ui}$ = 1。如果链接i展示给用户u，但用户u从来没有单击过，那么就定义$(u, i)$是负样本，即$r_{ui}$ = -1。然后，雅虎的研究人员利用前文提到的LFM预测用户是否会单击链接：$$\hat r_{ui} = p_u^T \cdot q_i$$ LFM模型在实际使用中有一个困难，那就是它很难实现实时的推荐。经典的LFM模型每次训练时都需要扫描所有的用户行为记录，这样才能计算出用户隐类向量$p_u$和物品隐类向量$q_i$。而且LFM的训练需要在用户行为记录上反复迭代才能获得比较好的性能。因此，LFM的每次训练都很耗时，一般在实际应用中只能每天训练一次，并且计算出所有用户的推荐结果。从而LFM模型不能因为用户行为的变化实时地调整推荐结果来满足用户最近的行为。为了解决传统LFM不能实时化，而产品需要实时性的矛盾，雅虎的研究人员提出了一个解决方案。 他们的解决方案分为两个部分。首先，他们利用新闻链接的内容属性（关键词、类别等）得到链接i的内容特征向量$y_i$。其次，他们会实时地收集用户对链接的行为，并且用这些数据得到链接i的隐特征向量$q_i$。然后，他们会利用如下公式预测用户u是否会单击链接i：$$r_{ui} = x^T_u \cdot y_i + p_u^T \cdot q_i$$ 其中，$y_i$是根据物品的内容属性直接生成的，$x_{uk}$是用户u对内容特征k的兴趣程度，用户向量$x_{u}$可以根据历史行为记录获得，而且每天只需要计算一次。而$p_u$、$q_i$是根据实时拿到的用户最近几小时的行为训练LFM获得的。因此，对于一个新加入的物品i，可以通过$ x^T_u \cdot y_i$估计用户u对物品i的兴趣，然后经过几个小时后，就可以通过$p_u^T \cdot q_i$得到更加准确的预测值。 2.5.3 LFM和基于邻域的方法比较LFM是一种基于机器学习的方法，具有比较好的理论基础。这个方法和基于邻域的方法（比如UserCF、ItemCF）相比，各有优缺点。下面将从不同的方面对比LFM和基于邻域的方法。 理论基础 LFM具有比较好的理论基础，它是一种学习方法，通过优化一个设定的指标建立最优的模型。基于邻域的方法更多的是一种基于统计的方法，并没有学习过程。 离线计算的空间复杂度 基于邻域的方法需要维护一张离线的相关表。在离线计算相关表的过程中，如果用户/物品数很多，将会占据很大的内存。假设有M个用户和N个物品，在计算相关表的过程中，我们可能会获得一张比较稠密的临时相关表（尽管最终我们对每个物品只保留K个最相关的物品，但在中间计算过程中稠密的相关表是不可避免的），那么假设是用户相关表，则需要$O(M * M)$的空间，而对于物品相关表，则需要 $O(N * N)$的空间。而LFM在建模过程中，如果是F个隐类，那么它需要的存储空间是$O(F * (M+N))$，这在M和N很大时可以很好地节省离线计算的内存。 离线计算的时间复杂度 假设有M个用户、N个物品、K条用户对物品的行为记录。那么，UserCF计算用户相关表的时间复杂度是$O(N * (K/N)^2)$，而ItemCF计算物品相关表的时间复杂度是$O(M * (K / M)^2)$。而对于LFM，如果用F个隐类，迭代S次，那么它的计算复杂度是$O(K * F * S)$。那么，如果$K / N &gt; F * S$，则代表UserCF的时间复杂度低于LFM ，如果$K / M&gt;F * S$，则说明ItemCF的时间复杂度低于LFM。在一般情况下，LFM的时间复杂度要稍微高于UserCF和ItemCF，这主要是因为该算法需要多次迭代。但总体上，这两种算法在时间复杂度上没有质的差别。 在线实时推荐 UserCF和ItemCF在线服务算法需要将相关表缓存在内存中，然后可以在线进行实时的预测。以ItemCF算法为例，一旦用户喜欢了新的物品，就可以通过查询内存中的相关表将和该物品相似的其他物品推荐给用户。因此，一旦用户有了新的行为， 而且该行为被实时地记录到后台的数据库系统中，他的推荐列表就会发生变化。而从LFM的预测公式可以看到，LFM在给用户生成推荐列表时，需要计算用户对所有物品的兴趣权重，然后排名，返回权重最大的N个物品。那么，在物品数很多时，这一过程的时间复杂度非常高，可达$O(M * N * F)$。因此，LFM不太适合用于物品数非常庞大的系统，如果要用，我们也需要一个比较快的算法给用户先计算一个比较小的候选列表，然后再用LFM重新排名。另一方面，LFM在生成一个用户推荐列表时速度太慢，因此不能在线实时计算，而需要离线将所有用户的推荐结果事先计算好存储在数据库中。因此，LFM不能进行在线实时推荐，也就是说，当用户有了新的行为后，他的推荐列表不会发生变化。 推荐解释 ItemCF算法支持很好的推荐解释，它可以利用用户的历史行为解释推荐结果。但LFM无法提供这样的解释，它计算出的隐类虽然在语义上确实代表了一类兴趣和物品，却很难用自然语言描述并生成解释展现给用户。 2.6 基于图的模型2.6.1 用户行为数据的二分图表示在研究基于图的模型之前，首先需要将用户行为数据表示成图的形式。本章讨论的用户行为数据是由一系列二元组组成的，其中每个二元组$(u, i)$表示用户u对物品i产生过行为。令$G(V,E)$表示用户物品二分图，其中$V = V_U \cup V_I$由用户顶点集合$V_U$和物品顶点集合$V_I$组成。对于数据集中每一个二元组$(u, i)$，图中都有一套对应的边$e(v_u,v_i)$，其中$v_u \in V_U$是用户u对应的顶点，$v_i \in V_I$是物品i对应的顶点。 2.6.2 基于图的推荐算法如果将个性化推荐算法放到二分图模型上，那么给用户u推荐物品的任务就可以转化为度量用户顶点$v_u$和与$v_u$没有边直接相连的物品节点在图上的相关性，相关性越高的物品在推荐列表中的权重就越高。 度量图中两个顶点之间相关性的方法很多，但一般来说图中顶点的相关性主要取决于下面3个因素： 两个顶点之间的路径数； 两个顶点之间路径的长度； 两个顶点之间的路径经过的顶点。 而相关性高的一对顶点一般具有如下特征： 两个顶点之间有很多路径相连； 连接两个顶点之间的路径长度都比较短； 连接两个顶点之间的路径不会经过出度比较大的顶点。 基于上面3个主要因素，研究人员设计了很多计算图中顶点之间相关性的方法(参见Fouss Francois、Pirotte Alain、Renders Jean-Michel和Saerens Marco的“Random-Walk Computation of Similarities between Nodes of a Graph with Application to Collaborative Recommendation”(IEEE Transactions on Knowl edge and Data Eng ineering, 2007))。本节将介绍一种基于随机游走的PersonalRank算法(参见Taher H .Haveliwala的“Topic-Sensitive PageRank”（WWW 2002, 2002）)。 假设要给用户u进行个性化推荐，可以从用户u对应的节点$v_u$开始在用户物品二分图上进行随机游走。游走到任何一个节点时，首先按照概率α决定是继续游走，还是停止这次游走并从$v_u$节点开始重新游走。如果决定继续游走，那么就从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的节点。这样，经过很多次随机游走后，每个物品节点被访问到的概率会收敛到一个数。最终的推荐列表中物品的权重就是物品节点的访问概率。 如果将上面的描述表示成公式，可以得到如下公式：$$PR(v) =\begin{cases}\alpha \sum_{v’ \in in(v)} \frac{PR(v’)}{\vert out(v’) \vert} &amp; (v \neq v_u) \\(1- alpha) + \alpha \sum_{v’ \in in(v)} \frac{PR(v’)}{\vert out(v’) \vert} &amp; (v = v_u)\end{cases}$$ 下面的代码简单实现了上面的公式： 123456789101112131415def PersonalRank(G, alpha, root): rank = dict() rank = &#123;x:0 for x in G.keys()&#125; rank[root] = 1 for k in range(20): tmp = &#123;x:0 for x in G.keys()&#125; for i, ri in G.items(): for j, wij in ri.items(): if j not in tmp: tmp[j] = 0 tmp[j] += 0.6 * rank[i] / (1.0 * len(ri)) if j == root: tmp[j] += 1 - alpha rank = tmp return rank 虽然PersonalRank算法可以通过随机游走进行比较好的理论解释，但该算法在时间复杂度上有明显的缺点。因为在为每个用户进行推荐时，都需要在整个用户物品二分图上进行迭代，直到整个图上的每个顶点的PR值收敛。这一过程的时间复杂度非常高，不仅无法在线提供实时推荐，甚至离线生成推荐结果也很耗时。 为了解决PersonalRank每次都需要在全图迭代并因此造成时间复杂度很高的问题，给出两种解决方案。第一种就是减少迭代次数，在收敛之前就停止。这样会影响最终的精度，但一般来说影响不会特别大。另一种方法就是从矩阵论出发，重新设计算法。 对矩阵运算比较熟悉的读者可以轻松将PersonalRank转化为矩阵的形式。令M为用户物品二分图的转移概率矩阵，即：$$M(v, v’) = \frac {1}{\vert out(v) \vert}​$$进而迭代公式可以转化为：$$\begin{align}r&amp; = (1-\alpha)r_0 + \alpha M^Tr \\&amp; = (1-\alpha)(1-\alpha M^T)^{-1}r_0\end{align}$$ 因此，只需要一次$(1-\alpha M^T)^{-1}$，这里$1-\alpha M^T$是稀疏矩阵。关于如何对稀疏矩阵快速求逆，可以参考矩阵计算方面的书籍和论文(比如Song Li的“Fast Algorithms For Sparse Matrix Inverse Compuataions”（2009）)。]]></content>
      <categories>
        <category>计算机科学与技术</category>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（一）]]></title>
    <url>%2F2018%2F11%2F23%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第1章 好的推荐系统在研究如何设计推荐系统前，了解什么是好的推荐系统至关重要。只有了解了优秀的推荐系统的特征，我们才能在设计推荐系统时根据实际情况进行取舍。 本章分3个步骤回答这个问题： 首先介绍了什么是推荐系统、推荐系统的主要任务、推荐系统和分类目录以及搜索引擎的区别等； 然后按照不同领域分门别类地介绍目前业界常见的个性化推荐应用； 最后介绍推荐系统的评测，通过介绍评测指标给出“好”的定义，从而最终解答“什么是好的推荐系统”这个问题。 1.1 什么是推荐系统推荐系统产生的背景随着信息技术和互联网的发展，人们逐渐从信息匮乏的时代走入了信息过载(overload)的时代。在这个时代，无论是信息消费者还是信息产生着都遇到了很大的挑战：作为信息消费者，如何从大量信息中找到自己感兴趣的信息是一件非常困难的的事情；作为信息产生者，如何让自己生产的信息脱颖而出，受到广大用户的关注，也是一件非常困难的事情。推荐系统就是解决这一矛盾的重要工具。 推荐系统的任务推荐系统的任务就是联系用户和信息，一方面帮助用户发现对自己有价值的信息，另一方面让信息能够展现在对它感兴趣的用户面前，从而实现信息消费者和信息生产者的双赢。 推荐系统与搜索引擎的异同众所周知，为了解决信息过载的问题，最具代表的解决方案是分类目录(雅虎)和搜索引擎(谷歌)。最初的分类目录网站将著名的网站分门别类，从而方便用户根据类别查找网站，然而随着互联网规模的不断扩大，门户网站也只能覆盖少量的热门网站，越来越不满足用户的需求。因此搜索引擎诞生了。但是搜索引擎需要用户主动提供准确的关键词来寻找信息，因此不能解决用户的很多其他需求，比如用户无法提供准确的关键词时，搜索引擎就无能为力了。 和搜索引擎一样，推荐系统也是一种帮助用户快速发现有用信息的工具。但和搜索引擎不同的是，推荐系统不需要用户提供明确的需求，而是通过分析用户的历史行为给用户的兴趣建模，从而主动给用户推荐能够满足他们兴趣和需求的信息。因此从某种意义上说，推荐系统和搜索引擎对于用户来说是两个互补的工具。搜索引擎满足了用户有明确目的时的主动查找需求，而推荐系统能够在用户没有明确目的的时候他们发现感兴趣的新内容。 生活中常见的推荐过程以看电影为例： 向朋友咨询。这种方式在推荐系统中称为社会化推荐(social recommendation)，即让好友给自己推荐物品。 寻找与自己之前看过的电影在内容上相似的电影。这种推荐方式在推荐系统中称为基于内容的推荐(content-based filtering)。 查看排行榜，看看别人都在看什么电影又或者看看和自己兴趣相近的人看什么电影。这种方式称为基于协同过滤(collaborative filtering)的推荐。 从上面三种方法可以看出，推荐算法的本质是通过一定的方式将用户和物品联系起来，而不同的推荐系统利用了不同的方式。 1.2 个性化推荐系统的应用在互联网的各类网站中都可以看到推荐系统的应用，而个性化推荐系统在这些网站中的主要作用是通过分析大量用户行为日志，给不同用户提供不同的个性化页面展示，以提高网站的点击率和转化率。 尽管不同的网站使用不同的推荐系统技术，但总地来说，几乎所有推荐系统应用都是由前台的展示页面、后台的日志系统、推荐算法系统3部分构成。 1.2.1 电子商务著名的电子商务网站亚马逊(Amazon)是个性化推荐系统的积极应用者和推广者。Amazon的推荐系统融入到了其各类产品中，其中最主要的应用是个性化商品推荐列表和相关商品的推荐列表。 个性化推荐列表基于物品的推荐算法(item-based method)该算法给用户用户推荐那些和他们之前喜欢的物品相似的物品。 个性化推荐列表组成部分 推荐结果的标题、缩略图以及其他内容属性。 推荐结果的平均分。 推荐理由。并且允许用户修正这一推荐 基于好友的推荐算法该算法按照用户在Facebook的好友关系，给用户推荐他们的好友在亚马逊上喜欢的物品。基于该种推荐算法生成的推荐列表的组成部分与基于物品的推荐列表类似，只不过这里的推荐理由换成了喜欢过相关物品的用户好友的头像。 相关推荐列表Amazon有两种相关商品列表： 包含购买了这个商品的用户也经常购买的其他商品 包含浏览过这个商品的用户经常购买的其他商品 这两种相关推荐列表的区别就是使用了不同用户行为计算物品的相关性。 此外，相关推荐列表最重要的应用就是打包销售(cross selling)。 1.2.2 电影和视频网站代表公司Netflix、Youtube、Hulu。其中Netflix和Youtube的算法与Amazon的算法类似，也是基于物品的推荐算法，即给用户推荐和他们曾经喜欢的视频相似的视频。 1.2.3 个性化音乐网络电台个性化推荐的成功应用需要两个条件： 存在信息过载。因为如果用户可以很容易地从所有物品中找到喜欢的物品，就不需要个性化推荐了。 用户大部分时候没有特别明确的需求。因为用户如果有明确的需求，可以直接通过搜索引擎找到感兴趣的物品。 在这两个条件下，个性化网络电台无疑是最合适的个性化推荐产品。目前有很多知名的个性化音乐网络电台。国际上著名的有Pandora和Last.fm，国内的代表则是网易云音乐。这三种应用虽然都是个性化网络电台，但背后的技术却不太一样。 PandoraPandora背后的音乐推荐系统主要来自于一个叫做音乐基因工程的项目。Pandora的算法主要基于内容，其音乐家和研究人员亲自听了上万首来自不同歌手的歌，然后对歌曲的不同特性(比如旋律、节奏、编曲和歌词等)进行标注，这些标注被称为音乐的基因。然后，Pandora会根据专家标注的基因计算歌曲的相似度，并给用户推荐和他之前喜欢的音乐在基因上相似的其他音乐。 Last.fmLast.fm记录了所有用户的听歌记录以及用户对歌曲的反馈，在这一基础上计算出不同用户在歌曲上的喜好相似度，从而给用户推荐和他有相似听歌爱好的其他用户喜欢的歌曲。同时，Last.fm也建立了一个社交网络，让用户能够和其他用户建立联系，同时也能让用户给好友推荐自己喜欢的歌曲。和Pandora相比，Last.fm没有使用专家标注，而是主要利用用户行为计算歌曲的相似度。 音乐推荐的特点2011年的Recsys大会专门要求了Pandora和研究人员对音乐推荐系统进行了演讲。演讲人总结了音乐推荐的如下特点： 物品空间大； 消费每首歌的代价很小； 物品种类丰富； 听一首歌耗时很少； 物品重用率很高； 用户充满激情； 上下文相关； 次序很重要； 很多播放列表资源； 不需要用户全神贯注； 高度社会化； 上面这些特点决定了音乐是一种非常适合用来推荐的物品。因此，尽管现在很多推荐系统都是作为一个应用存在与网站中，比如Amazon的商品推荐和Netflix的电影推荐，但唯有音乐推荐系统可以支持独立的个性化推荐网站，比如Pandora、Last.fm和豆瓣网络电台。 1.2.4 社交网络社交网络中的个性化推荐主要应用于3个方面： 利用用户的社交网络信息对用户进行个性化的物品推荐； 信息流的会话推荐； 给用户推荐好友； 1.2.5 个性化阅读个性化阅读同样符合前面提出的需要个性化推荐的两个因素：首先，互联网上的文章很多，用户面临信息过载的问题；其次，用户很多时候并没有必须看某篇具体文章的需求，他们只是想通过阅读特定领域的文章了解这些领域的动态。 Google ReaderGoogle Reader是一款流行的社会化阅读工具。它允许用户关注自己感兴趣的人，然后看到所关注用户分享的文章。 Zite和Google Reader不同，个性化阅读工具Zite则是收集用户对文章的偏好信息。在每篇文章右侧，Zite都允许用户给出喜欢或不喜欢的反馈，然后通过分析用户的反馈数据不停地更新用户的个性化文章列表。 DiggDigg是一家著名的新闻阅读网站。Digg首先根据用户的Digg历史计算用户之间的兴趣相似度，然后给用户推荐和他兴趣相似的用户喜欢的文章。 1.2.6 基于位置的服务随着移动设备的飞速发展，用户的位置信息已经非常容易获取，而位置是一种很重要的上下文信息，基于位置给用户推荐离他近的且他感兴趣的服务，用户就更有可能去消费。 Foursquare基于位置的服务往往和社交网络结合在一起。其中Foursquare推出了探索功能，给用户推荐好友在附近的行为。 1.2.7 个性化邮件使对用户重要的邮件能够让用户优先浏览。 Tapestry目前在文献中能够查到的第一个推荐系统Tapestry就是一个个性化邮件推荐系统，它通过分析用户阅读邮件的历史行为和习惯对新邮件进行重新排序，从而提高用户的工作效率。 1.2.8 个性化广告个性化广告投放目前已经成为了一门独立的学科——计算广告，但该学科和推荐系统在很多基础理论和方法上是相通的，比如它们的目的都是联系用户和物品，只是在个性化广告中，物品就是广告。 个性化广告投放和狭义个性化推荐的区别个性化推荐着重于帮助用户找到可能令他们感兴趣的物品，而广告推荐着重于帮助广告找到可能对它们感兴趣的用户，即一个是以用户为核心，而另一个是以广告为核心。 个性化广告投放技术目前个性化广告投放技术主要分为3种： 上下文广告。通过分析用户正在浏览的网页内容，投放和网页内容相关的广告。代表系统是谷歌的Adsense。 搜索广告。通过分析用户在当前会话中的搜索记录，判断用户的搜索目的，投放和用户目的相关的广告。 个性化展示广告。我们经常在很多网站看到大量的展示广告(就是那些大的横幅图片)，它们是根据用户的兴趣，对不同用户投放不同的展示广告。 Yahoo发表了大量个性化广告方面的论文，而最成功的则是Facebook。 1.3 推荐系统评测一个完整的推荐系统一般存在3个参与方：用户、物品提供者和提供推荐系统的网站。同时好的推荐系统设计，能够让推荐系统本身收集到高质量的用户反馈，不断完善推荐的质量，增加用户和网站的交互，提高网站的收入。因此在评测一个推荐算法时，需要同时考虑三方的利益，一个好的推荐系统是能够令三方共赢的系统。在推荐系统的早期研究中，很多人将好的推荐系统定义为能够作出准确预测的推荐系统。但是，后来很多研究表明，准确的预测并不代表好的推荐。举个极端点的例子，某推荐系统预测明天太阳将从东方升起，虽然预测准确率为100%，却是一种没有意义的预测。所以，好的推荐系统不仅仅能够准确预测用户的行为，而且能够扩展用户的视野，帮助用户发现那些他们可能会感兴趣，但却不那么容易发现的东西。为了全面评测推荐系统对三方利益的影响，本章从不同角度出发，提出不同的指标。 1.3.1 推荐系统实验方法首先介绍计算和获得这些指标的主要实验方法。推荐系统中主要有3种评测推荐效果的实验方法，即离线实验(offline experiment)、用户调查(user study)和在线实验(online experiment)。 离线实验离线实验的方法离线实验的方法一般由如下几个步骤构成： 通过日志系统获得用户行为数据，并按照一定格式生成一个标准的数据集； 将数据集按照一定的规则分成训练集和测试集； 在训练集上训练用户兴趣模型，在测试集上进行预测； 通过事先定义的离线指标评测算法评测在测试集上的预测结果。 从上面的步骤可以看到，推荐系统的离线实验都是在数据集上完成的，也就是说它不需要一个实际的系统来供它实验，而只要有一个从实验系统日志中提取的数据集即可。 离线实验的优缺点这种实验方法的好处是不需要真实用户参与，可以直接快速地计算出来，从而方便、快速地测试大量不同的算法。它的主要缺点是无法获得很多商业上关注的指标，如点击率、转化率等，而找到和商业指标非常相关的离线指标也是很困难的事情。 用户调查用户调查是推荐系统评测的一个重要工具，很多离线时没有办法评测的与用户主观感受有关的指标都可以通过用户调查获得。 用户调查的方法用户调查需要有一些真实用户，让他们在需要测试的推荐系统上完成一些任务。在他们完成任务时，我们需要观察和记录他们的行为，并让他们回答一些问题。最后，我们需要通过分析他们的行为和答案了解测试系统的性能。 用户调查的优缺点它的优点是可以获得很多体现用户主观感受的指标，相对在线实验风险很低，出现错误后很容易弥补。缺点是招募测试用户代价较大，很难组织大规模的测试用户，因此会使测试结果的统计意义不足。此外，在很多时候设计双盲实验非常困难，而且用户在测试环境下的行为和真实环境下的行为可能有所不同，因而在测试环境下收集的测试指标可能在真实环境下无法重现。 在线实验在完成离线实验和必要的用户调查后，可以将推荐系统上线做AB测试，将它和旧的算法进行比较。 在线实验的方法AB测试是一种很常用的在线评测算法的实验方法。它通过一定的规则将用户随机分成几组，并对不同组的用户采用不同的算法，然后通过统计不同用户的各种不同的评测指标比较不同算法。 网站http://www.abtests.com/给出了很多通过实际AB测试提高网站用户满意度的例子，从中我们可以学习到如何进行合理的AB测试。 在线实验的优缺点AB测试的优点是可以公平获得不同算法实际在线时的性能指标，包括商业上关注的指标。AB测试的缺点主要是周期比较长，必须进行长期的实验才能得到可靠的结果。因此一般不会用AB测试测试所有的算法，而只是用它测试那些在离线实验和用户调查中表现很好的算法。其次，一个大型网站的AB测试系统的设计也是一项复杂的工程。 一般来说，一个新的推荐算法最终上线，需要完成上面所说的3个实验。 首先，需要通过离线实验证明它在很多离线指标上优于现有的算法。 然后，需要通过用户调查确定它的用户满意度不低于现有的算法。 最后，通过在线的AB测试确定它在我们关心的指标上优于现有的算法。 1.3.2 评测指标1.用户满意度 用户作为推荐系统的重要参与者，其满意度是评测推荐系统的最重要指标。但是，用户满意度没有办法离线计算，只能通过用户调查或在线实验方式获得。 用户调查获得用户满意度主要是通过调查问卷的形式。用户对推荐系统的满意度分为不同的层次。因此在设计问卷时需要考虑到用户各方面的感受，这样用户才能针对问题给出自己准确的回答。 在在线系统中，用户满意度主要通过一些对用户行为的统计得到。更一般的情况下，我们可以用点击率、用户停留时间和转化率等指标度量用户的满意度。 2.预测准确度 预测准确度度量一个推荐系统或者推荐算法预测用户行为的能力。 计算方法：在计算该指标时需要有一个离线的数据集，该数据集包含用户的历史行为记录。然后，将该数据集通过时间分为训练集和测试集。最后，通过在训练集上建立用户的行为和兴趣模型预测用户在测试集上的行为，并计算预测行为和测试集上实际行为的重合度作为预测准确度。 不同的研究方向有不同的预测准确度指标。 评分预测 预测用户对物品评分的行为称为评分预测。 评分预测的预测准确度一般通过均方根误差(RMSE)和平均绝对误差(MAE)计算。对于测试集中的一个用户u和物品i，令$r_{ui}$是用户u对物品i的实际评分，而$\hat r_{ui}$是推荐算法给出的预测评分，那么RMSE的定义为：$$RMSE = \frac {\sqrt{\sum_{u,i \in T} (r_{ui} - \hat r_{ui})^2}}{|T|}$$ MAE采用绝对值计算预测误差，它的定义为：$$MAE=\frac{\sum_{u,i \in T}|r_{ui}-\hat r_{ui}|} {|T|}$$ 假设我们用一个列表records存放用户评分数据，令records[i] = [u,i,rui,pui]，其中rui是用户u对物品i的实际评分，pui是算法预测出来的用户u对物品i的评分，下面代码实现了RME和MAE的计算过程。 12345def RMSE(records): return math.sqrt(sum([(rui - pui) * (rui - pui) for u,i,rui,pui in records])/float(len(records)))def MAE(records): return sum([abs(rui-pui) for u,i,rui,pui in records])/float(len(records)) 关于RMSE和MAE这两个指标的优缺点，Netflix认为RMSE加大了对预测不准的用户物品评分的惩罚(平方项的惩罚)，因而对系统的评测更加苛刻。研究表明，如果评分系统是基于基数建立的(即用户给的评分都是整数)，那么对预测结果取整可能会降低MAE的误差。 TopN推荐网站在提供推荐服务时，一般是给用户一个个性化的推荐列表，这种推荐叫做TopN推荐。TopN推荐的预测准确率一般通过准确率(precision)/召回率(recall)度量。$R(u)$是根据用户在训练集上的行为给用户作出的推荐列表，而$T(u)$是用户在测试集上的行为列表。那么，推荐结果的召回率定义为：$$Recall=\frac {\sum_{u \in U} |R(u) \cap T(u)|}{\sum_{u \in U} |T(u)|} $$推荐结果的准确率定义为：$$Precision=\frac {\sum_{u \in U} |R(u) \cap T(u)|}{\sum_{u \in U} |R(u)|} $$下面的Python代码同时计算出了一个推荐算法的准确率和召回率： 12345678910def PrecisionRecall(test, N): hit = 0 n_recall = 0 n_precision = 0 for user, items in test.items(): rank = Recommend(user, N) hit += len(rank &amp; item) # hit是推荐列表与行为列表相交的部分 n_recall += len(items) n_precision += N return [hit/(1.0*n_recall),hit/(1.0*n_precision)] 有的时候，为了全面评测TopN推荐的准确率和召回率，一般会选取不同的推荐列表长度N，计算出一组准确率和召回率，然后画出准确率/召回率曲线(precision/recall curve)。 关于评分预测和TopN推荐的讨论评分预测一直是推荐系统研究的热点，绝大多数推荐系统的研究都是基于用户评分数据的评分预测。这主要是因为，一方面推荐系统的早期研究组GroupLens的研究主要就是基于电影评分 数据MovieLens进行的，其次，Netflix大赛也主要面向评分预测问题。因而，很多研究人员都将 研究精力集中在优化评分预测的RMSE上。 对此，亚马逊前科学家Greg Linden有不同的看法。2009年, 他在Communications of the ACM 网站发表了一篇文章 (“What is a Good Recommendation Algorithm？”,参见http://cacm.acm.org/blogs/blog-cacm/22925-what-is-a-goodrecommendation-algorithm/fulltext/) ，指出电影推荐的目的是找到用户最有可能感兴趣的电影，而不是预测用户看了电影后会给电影什么样的评分。因此，TopN推荐更符合实际的应用需求。也许有一部电影用户看了之后会给很高的分数，但用户看的可能性非常小。因此，预测用户是否会看一部电影， 应该比预测用户看了电影后会给它什么评分更加重要。因此，本书主要也是讨论TopN推荐。 3.覆盖度覆盖度(coverage)描述一个推荐系统对物品长尾的发掘能力。覆盖率有不同的定义方法，最简单的定义为推荐系统能够推荐出来的物品占总物品集合的比例。假设系统的用户集合为$U$，推荐系统给每个用户推荐一个长度为N的物品列表$R(u)$。那么推荐系统的覆盖率可以通过下面的公式计算：$$Coverage=\frac{| \bigcup_{u \in U} R(u)|}{|I|}$$从上面的定义可以看到，覆盖率是一个内容提供商会关心的指标。一个好的推荐系统不仅需要有比较高的用户满意度，也要有较高的覆盖率。但是上面的定义过于粗略。覆盖率为100%的系统可以有无数的物品流行度分布。为了更细致地描述推荐系统发掘长尾的能力，需要统计推荐列表中不同物品出现次数的分布。如果所有的物品都出现在推荐列表中，且出现的次数差不多，那么推荐系统发掘长尾的能力就很好。因此，可以通过研究物品在推荐列表中出现次数的分布描述推荐系统挖掘长尾的能力。如果这个分布比较平，那么说明推荐系统的覆盖率较高，而如果这个分布较陡峭，说明推荐系统的覆盖率较低。在信息论和经济学中有两个著名的指标可以用来定义覆盖率。第一个是信息熵：$$H = -\sum_{i=1}^n p(i) \log p(i)$$这里$p(i)$是物品i的流行度除以所有物品的流行度之和。第二个是基尼系数(Gini Index)：$$G = \frac{1}{n-1} \sum_{j=1}^n (2j-n-1)p(i_j)$$这里$i_j$是按照物品流行度$p()$从小到大排序的物品列表中第j个物品。下面代码用来计算给定物品流行度分布后的基尼系数：1234567def GiniIndex(p): j = 1 n = len(p) G = 0 for item, weight in sorted(p.items(), key=itemgetter(1)): G += (2 * j - n - 1) * weight return G / float(n - 1) 社会学领域有一个著名的马太效应，即所谓强者更强，弱者更弱的效应。推荐系统的初衷是希望消除马太效应，使得各种物品都能被展示给对它们感兴趣的某一类人群。但是，很多研究表明现在主流的推荐算法（比如协同过滤算法）是具有马太效应的。评测推荐系统是否具有马太效应的简单办法就是使用基尼系数。如果G1是从初始用户行为中计算出的物品流行度的基尼系数，G2是从推荐列表中计算出的物品流行度的基尼系数，那么如果G2 &gt; G1，就说明推荐算法具有马太效应。 4.多样性为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域，即推荐结果需要具有多样性。多样性推荐列表的好处用一句俗话表述就是“不在一棵树上吊死”。尽管用户的兴趣在较长的时间跨度中是一样的，但具体到用户访问推荐系统的某一刻，其兴趣往往是单一的，那么如果推荐列表只能覆盖用户的一个兴趣点，而这个兴趣点不是用户这个时刻的兴趣点，推荐列表就不会让用户满意。反之，如果推荐列表比较多样，覆盖了用户绝大多数的兴趣点，那么就会增加用户找到感兴趣物品的概率。因此给用户的推荐列表也需要满足用户广泛的兴趣，即具有多样性。多样性描述了推荐列表中物品两两之间的不相似性。因此，多样性和相似性是对应的。假设$s(i,j) \in [0,1]$定义了物品i和j之间的相似度，那么用户u的推荐列表$R(u)$的多样性定义如下：$$Diversity=1-\frac {\sum_{i,j \in R(u),i \neq j} s(i,j)}{\frac{1}{2}|R(u)|(|R(u)|-1)}$$而推荐系统的整体多样性可以定义为所有用户推荐列表多样性的平均值：$$Diversity=\frac{1}{|U|} \sum_{u \in U}Diversity(R(u))$$从上面的定义可以看到，不同的物品相似度度量函数$s(i, j)$可以定义不同的多样性。如果用内容相似度描述物品间的相似度，我们就可以得到内容多样性函数，如果用协同过滤的相似度函数描述物品间的相似度，就可以得到协同过滤的多样性函数。 5.新颖性新颖的推荐是指给用户推荐那些他们以前没有听说过的物品。在一个网站中实现新颖性的最简单办法是，把那些用户之前在网站中对其有过行为的物品从推荐列表中过滤掉。O’scar Celma在博士论文“Music Recommendation and Discovery in the Long Tail”(参见“Music Recommendation and Discovery in the Long Tail”，地址为http://mtg.upf.edu/static/media/PhD_ocelma.pdf) 中研究了新颖度的评测。评测新颖度的最简单方法是利用推荐结果的平均流行度，因为越不热门的物品越可能让用户觉得新颖。因此，如果推荐结果中物品的平均热门程度较低，那么推荐结果就可能有比较高的新颖性。但是，用推荐结果的平均流行度度量新颖性比较粗略，因为不同用户不知道的东西是不同的。因此，要准确地统计新颖性需要做用户调查。最近几年关于多样性和新颖性的研究越来越受到推荐系统研究人员的关注。ACM的推荐系统会议在2011年有一个专门的研讨会讨论推荐的多样性和新颖性。 (参见“International Workshop on Novelty and Diversity in Recommender Systems”，地址为http://ir.ii.uam.es/divers2011/) 该研讨会的组织者认为，通过牺牲精度来提高多样性和新颖性是很容易的，而困难的是如何在不牺牲精度的情况下提高多样性和新颖性。关心这两个指标的读者可以关注一下这个研讨会最终发表的论文。 6.惊喜度惊喜度（serendipity）是最近这几年推荐系统领域最热门的话题。惊喜度和新颖度作为推荐系统的指标，它们之间的区别并非两个词在中文里含义的区别而是意义上的区别。可以举一个例子说明这两种指标的区别。假设一名用户喜欢周星驰的电影，然后我们给他推荐了一部叫做《临歧》的电影（该电影是1983年由刘德华、周星驰、梁朝伟合作演出的，很少有人知道这部有周星驰出演的电影），而该用户不知道这部电影，那么可以说这个推荐具有新颖性。但是，这个推荐并没有惊喜度，因为该用户一旦了解了这个电影的演员，就不会觉得特别奇怪。但如果我们给用户推荐张艺谋导演的《红高粱》，假设这名用户没有看过这部电影，那么他看完这部电影后可能会觉得很奇怪，因为这部电影和他的兴趣一点关系也没有，但如果用户看完电影后觉得这部电影很不错，那么就可以说这个推荐是让用户惊喜的。这个例子的原始版本来自于Guy Shani的论文(参见Guy Shani和 Asela Gunawardana的“Evaluating Recommendation Systems”) ，他的基本意思就是，如果推荐结果和用户的历史兴趣不相似，但却让用户觉得满意，那么就可以说推荐结果的惊喜度很高，而推荐的新颖性仅仅取决于用户是否听说过这个推荐结果。目前并没有什么公认的惊喜度指标定义方式，这里只给出一种定性的度量方式。上面提到，令用户惊喜的推荐结果是和用户历史上喜欢的物品不相似，但用户却觉得满意的推荐。那么，定义惊喜度需要首先定义推荐结果和用户历史上喜欢的物品的相似度，其次需要定义用户对推荐结果的满意度。前面也曾提到，用户满意度只能通过问卷调查或者在线实验获得，而推荐结果和用户历史上喜欢的物品相似度一般可以用内容相似度定义。也就是说，如果获得了一个用户观看电影的历史，得到这些电影的演员和导演集合A，然后给用户推荐一个不属于集合A的导演和演员创作的电影，而用户表示非常满意，这样就实现了一个惊喜度很高的推荐。因此提高推荐惊喜度需要提高推荐结果的用户满意度，同时降低推荐结果和用户历史兴趣的相似度。惊喜度的问题最近几年获得了学术界的一定关注，但这方面的工作还不是很成熟。相关工作可以参考Yuan Cao Zhang等的论文(参见Yuan Cao Zhang、Diarmuid Ó Séaghdha、Daniele Quercia和 Tamas Jambor的“Auralist: introducing serendipity into music recommendation.”)和Tomoko Murakami等的论文 (参见Tomoko Murakami、 Koichiro. Mori和Ryohei Orihara的“ Metrics for evaluating the serendipity of recommendationlists”)。 7.信任度对于基于机器学习的自动推荐系统，同样存在信任度（trust）的问题，如果用户信任推荐系统，那就会增加用户和推荐系统的交互。度量推荐系统的信任度只能通过问卷调查的方式，询问用户是否信任推荐系统的推荐结果。提高推荐系统的信任度主要有两种方法。首先需要增加推荐系统的透明度(transparency)(参见Henriette Cramer、Vanessa Evers、 Satyan Ramlal、 Maarten van Someren、Lloyd Rutledge、 Natalia Stash、Lora Aroyo和Bob Wielinga的“ The effects of transparency on trust in and acceptance of a content-based art recommender”) ， 而增加推荐系统透明度的主要办法是提供推荐解释。只有让用户了解推荐系统的运行机制，让用 户认同推荐系统的运行机制，才会提高用户对推荐系统的信任度。其次是考虑用户的社交网络 信息，利用用户的好友信息给用户做推荐，并且用好友进行推荐解释。这是因为用户对他们的 好友一般都比较信任，因此如果推荐的商品是好友购买过的，那么他们对推荐结果就会相对比较信任。关于推荐系统信任度的研究(参见Paolo Massa和 Paolo Avesani的“Trust-aware recommender systems”)主要集中在评论网站Epinion的推荐系统上。这是因为Epinion创建了一套用户之间的信任系统来建立用户之间的信任关系，帮助用户判断是否信任当前用户对某一个商品的评论。 8.实时性在很多网站中，因为物品（新闻、微博等）具有很强的时效性，所以需要在物品还具有时效性时就将它们推荐给用户。推荐系统的实时性包括两个方面。首先，推荐系统需要实时地更新推荐列表来满足用户新的行为变化。很多推荐系统都会在离线状态每天计算一次用户推荐列表，然后于在线期间将推荐列表展示给用户。这种设计显然是无法满足实时性的。与用户行为相应的实时性，可以通过推荐列表的变化速率来评测。如果推荐列表在用户有行为后变化不大，或者没有变化，说明推荐系统的实时性不高。实时性的第二个方面是推荐系统需要能够将新加入系统的物品推荐给用户。这主要考验了推荐系统处理物品冷启动的能力。 9.健壮性健壮性（即robust,鲁棒性）指标衡量了一个推荐系统抗击作弊的能力。算法健壮性的评测主要利用模拟攻击。首先，给定一个数据集和一个算法，可以用这个算法给这个数据集中的用户生成推荐列表。然后，用常用的攻击方法向数据集中注入噪声数据，然后利用算法在注入噪声后的数据集上再次给用户生成推荐列表。最后，通过比较攻击前后推荐列表的相似度评测算法的健壮性。如果攻击后的推荐列表相对于攻击前没有发生大的变化，就说明算法比较健壮。在实际系统中，提高系统的健壮性，除了选择健壮性高的算法，还有以下方法。 设计推荐系统时尽量使用代价比较高的用户行为。 在使用数据前，进行攻击检测，从而对数据进行清理。 10.商业目标不同的网站会根据自己的盈利模式设有不同的商业目标。因此，设计推荐系统时需要考虑最终的商业目标，而网站使用推荐系统的目的除了满足用 户发现内容的需求，也需要利用推荐系统加快实现商业上的指标。 11.总结对于可以离线优化的指标，作者的看法是应该在给定覆盖率、多样性、新颖性等限制条件下，尽量优化预测准确度。用一个数学公式表达，离线实验的优化目标是：​ 最大化预测准确度​ 使得 覆盖率 &gt; A​ 多样性 &gt; B​ 新颖性 &gt; C其中，A、B、C的取值应该视不同的应用而定。 1.3.3 评测维度除了应该考虑评测指标，还应考虑评测维度。增加评测维度的目的就是知道一个推荐算法在什么情况下性能最好。这样可以为融合不同推荐算法取得最好的整体性能带来参考。一般情况下，评测维度分为如下3种： 用户维度：主要包括用户的人口统计学信息、活跃度以及是不是新用户等。 物品维度：包括物品的属性信息、流行度、平均分以及是不是新加入的物品等。 时间维度：包括季节，是工作日还是周末，是白天还是晚上等。 如果能够在推荐系统评测报告中包含不同维度下的系统评测指标，就能帮我们全面地了解推荐系统性能，找到一个看上去比较弱的算法的优势，发现一个看上去比较强的算法的缺点。]]></content>
      <categories>
        <category>计算机科学与技术</category>
        <category>推荐系统</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次顿悟]]></title>
    <url>%2F2018%2F11%2F11%2F%E4%B8%80%E6%AC%A1%E9%A1%BF%E6%82%9F%2F</url>
    <content type="text"><![CDATA[最近一直都在搞怎么让百度收录我的Blog的问题，最后也没有解决，耽误了两三天的时间。为什么Google就能爬取Github Pages，百度就不行呢，忍不住去吐槽(这个事真是烦死我)，对了还有Coding也是个坑。 在解决这个期间也有所思考，并且得到一个顿悟(大喜)，就是人如果想成功就要在高维度上努力而不是低维度。 人的时间都是有限的，并且假设所有人的资质都是相同的(当然是不可能的)，如果能尽可能地节省时间，那么相比其他人就会走得更远。换句话说就是尽可能地让前进的步子迈得更大。说这话什么意思呢?举个例子，如果你高中三年努力考上了清华北大，可能就会比研究生考上清北的人节省出三四年甚至更多的时间。为什么？因为你高中同样花了三年的时间，大学花去了四年时间才和人家只花高中三年的人站在同一高度，有可能还低一些，那么人家是不是比你少花了三四年呢？拿三年换七年血赚啊，谁都明白这个道理。 上升一个层次再去思考这个问题。有的人本科阶段很努力每天都在研究编程，编程技术很厉害，就比如我。但另一些人会去研究论文，刷绩点，准备出国留学。两者的努力程度是一样的，如果两种人的目标是相同的，那么很明显后者到达目标的速度会明显比前者快很多，这就是努力层次的问题。前者是在低维度努力，而后者是在高纬度努力，类似于高处的人比低处的人看得更远。更形象地距举例就是一个人在高抬腿向前跑，而另一个人则是大跨步向前跑。为什么说前者是低维度而后者是高维度呢？因为前者所做的是有一定经验的人都能去做的，虽然短期可能会得到更现实的成就感，但从长远来看后者所做的开创性研究是不可替代的，更牛逼。 令人伤心地是之前的我就是第一种人，而我本科前两年的努力都是高抬腿跑。我已经落后很多了。但凡事都有两面性，好的一方面是现在的我意识到了这点，于是我坚定了我要考研清华的决心，只有这样我才能追回来一些时间。相比那些保研的同学我还有一个优势，就是别无选择，我不会因为目标的不确定而恍惚。 背水一战，向死而生。希望我自己能谨记这次顿悟，会受益匪浅。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中常用的内置函数]]></title>
    <url>%2F2018%2F11%2F09%2FPython%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Python中常用的内置函数Python内置函数(built-in)是随着Python解释器的运行而被创建的。在Python程序中，你可以随时调用这些函数，而且不需要定义。在开发过程中，合理地使用这些内置函数能极大地提升你的开发效率。 这篇文章是对我在开发过程中经常遇到的内置函数的用法总结。 enumerate()函数描述enumerate()函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合成一个索引序列，同时列出数据和数据下标，一般用于for循环中。 语法1enumerate(sequence, [start=0]) 参数 sequence: 一个序列、迭代器或其他可迭代对象。 start: 下标开始位置。 返回值返回enumerate(枚举)对象。 实例12345&gt;&gt;&gt;seasons = ['Spring', 'Summer', 'Fall', 'Winter']&gt;&gt;&gt; list(enumerate(seasons))[(0, 'Spring'), (1, 'Summer'), (2, 'Fall'), (3, 'Winter')]&gt;&gt;&gt; list(enumerate(seasons, start=1)) # 下标从 1 开始[(1, 'Spring'), (2, 'Summer'), (3, 'Fall'), (4, 'Winter')] 普通的for循环123456789&gt;&gt;&gt;i = 0&gt;&gt;&gt; seq = ['one', 'two', 'three']&gt;&gt;&gt; for element in seq:... print i, seq[i]... i +=1... 0 one1 two2 three for循环使用enumerate()1234567&gt;&gt;&gt;seq = ['one', 'two', 'three']&gt;&gt;&gt; for i, element in enumerate(seq):... print i, element... 0 one1 two2 three isinstance()函数描述isinstance()函数用来判断一个对象是否是一个已知类型，类似type()。 isinstance()和type()的区别： type()不会认为子类是一种父类类型，不考虑继承关系； isinstance()会认为子类是一种父类类型，考虑继承关系； 如果要判断两个类型是否相同推荐使用isinstance() 语法1isinstance(object, classinfo) 参数 object: 实例对象; classinfo: 可以直接或间接是类名、基本类型或者由它们组成的元组； 说明： 对于基本类型来说classinfo可以是： 1int, float, bool, complex, str(字符串), list, dict(字典), set, tuple 要注意的是，classinfo的字符串是str而不是string，字典也是简写dict。 实例： 1234arg=123isinstance(arg, int) #输出Trueisinstance(arg, str) #输出Falseisinstance(arg, string) #报错 返回值如果对象的类型与classinfo的类型相同则返回True，否则返回False。 实例1234567&gt;&gt;&gt;a = 2&gt;&gt;&gt; isinstance (a,int)True&gt;&gt;&gt; isinstance (a,str)False&gt;&gt;&gt; isinstance (a,(str,int,list)) # 是元组中的一个返回 TrueTrue type与instance的区别12345678910class A: pass class B(A): pass isinstance(A(), A) # returns Truetype(A()) == A # returns Trueisinstance(B(), A) # returns Truetype(B()) == A # returns False]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中的列表生成式]]></title>
    <url>%2F2018%2F11%2F05%2FPython%E4%B8%AD%E7%9A%84%E5%88%97%E8%A1%A8%E7%94%9F%E6%88%90%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Python中的列表生成式顾名思义，列表生成式就是用来生成列表的特定语法形式的表达式。列表生成式即List Comprehensions，是Python内置的非常简单却强大的可以用来创建list的生成式。 语法格式基础语法格式1[exp for iter_var in iterable] 工作过程 迭代iterable中的每个元素； 每次迭代都先把结果赋值给iter_var，然后通过exp得到一个新的计算值； 最后所有通过exp得到的计算值以一个新的列表的形式返回； 相当于： 123L = []for iter_var in iterable: L.append(exp) 带过滤功能的语法格式1[exp for iter_var in iterable if_exp] 工作过程 迭代iterable中的每个元素，每次迭代都先判断if_exp表达式是否成立，即判断将iter_var代入if_exp后表达式的结果，如果为真则进行下一步，如果为假则进行下一次迭代； 把迭代结果赋值给iter_var，然后通过exp得到一个新的计算值； 最后把所有通过exp得到的计算值以一个新列表的形式返回； 相当于： 1234L = []for iter_var in iterable: if_exp: L.append(exp) 循环嵌套的语法格式1[exp for iter_var_A in iterable_A for iter_var_B in iterable_B] 工作过程 迭代iterable_A中的每个元素，但是每迭代iterable_A中的一个元素，就把iterable_B中的所有元素都迭代一遍； 将每次迭代的变量iterable_var_A和iterable_var_B传入表达式exp(当然可以只传入两者之一)，计算出结果； 最后把所有通过exp得到的结果以一个新的列表的形式返回； 应用场景其实列表生成式是Python中的一种“语法糖”，也就是说列表生成式是Python提供的一种生成列表的简洁形式，应用列表生成式可以快速生成一个新的list。它最主要的应用场景是：根据已存在的可迭代对象推导出一个新的list。 使用实例我们可以对几个生成列表的要求分别通过“不使用列表生成式”和“使用列表生成式”来实现，然后做个对比总结。 实例1：生成一个从3到10的数字列表12345# 不使用列表生成式list1 = list(range(3, 11))# 使用列表生成式list2 = [x for x in range(3, 11)] 实例2：生成一个2n+1的数字列表，n为从3到10的数字1234567# 不使用列表生成式list3 = []for n in range(3, 11): list3.append(2*n + 1) # 使用列表生成式list4 = [2*n + 1 for n in range(3, 11)] 实例3：过滤出指定的数字列表中的值大于20的元素123456789L = [3, 7, 11, 14, 19, 33, 26, 57, 99]# 不使用列表生成式list5 = []for x in L: if x &lt; 20: list5.append(x) # 使用列表生成式list6 = [x for x in L if x &lt; 20] 实例4：计算两个集合的全排列，并将结果保存至一个新的列表中1234567891011L1 = ['香蕉', '苹果', '橙子']L2 = ['可乐', '牛奶']# 不使用列表生成式list7 = []for x in L1: for y in L2: list7.append((x,y)) # 使用列表生成式list8 = [(x,y) for x in L1 for y in L2] 实例5：将一个字典转换成由一组元组组成的列表，元组的格式为(key, value)12345678910D = &#123;'Tom': 15, 'Jerry': 18, 'Peter': 13&#125;# 不使用列表生成式list9 = []for k, v in D.items(): list9.append((k, v)) # 使用列表生成式list10 = []list10 = [(k, v) for k, v in D.items()] 可见，在一些情况下使用列表生成式确实要方便、简洁很多，使用一行代码就搞定了。 列表生成式与map、filter等高阶函数对比列表生成式的功能与之前文章提到的map()和filter()高阶函数功能很像，比如下面两个例子： 实例1：把一个列表中所有的字符串转换为小写，非字符串元素保留原样123456L = ['TOM', 'Peter', 10, 'Jerry']# 用列表生成式实现list1 = [x.lower() if isinstance(x, str) else x for x in L]# 用map()函数实现list2 = list(map(lambda x : x.lower() if isinstance(x, str) else x, L)) 实例2：把一个列表中所有的字符串转换为小写，非字符串元素移除1234567L = ['TOM', 'Peter', 10, 'Jerry']# 用列表生成式实现list3 = [x.lower() for x in L if isinstance(x, str)] # 注意：这里for x in L相对if isinstance的先后位置，与上一个示例相比较# 用map()和filter()函数实现list4 = list(map(lambda x: x.lower(), filter(lambda x: isinstance(x, str), L))) 对于大部分需求来讲，使用列表生成式和使用高阶函数都能实现。但是map和filter等一些高阶函数在Python3.x中的返回值类型变成了Iterator(迭代器)对象，这对于那些元素数量很大或无限的可迭代对象来说显然是更合适的，因为可以避免不必要的内存空间浪费。 引用文章： Python之列表生成式、生成器、可迭代对象与迭代器 - 云游道士 - 博客园 列表生成式 - 廖雪峰的官方网站]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中的装饰器]]></title>
    <url>%2F2018%2F11%2F04%2FPython%E4%B8%AD%E7%9A%84%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Python中的装饰器装饰器本质上是一个Python函数，它可以让其他函数在不需要做任何代码变动的前提下增加额外功能，装饰器的返回值也是一个函数对象。 它经常用于有切面需求的场景，比如：插入日志、性能检测、事务处理、缓存、权限校验等场景。装饰器是解决这类问题的绝佳设计，有了装饰器，我们就可以抽离出大量与函数功能无关的雷同代码并继续重用。概括地讲，装饰器的作用就是为已经存在对象添加额外的功能。 先看一个简单例子： 12def foo(): print('i am foo') 现在有一个新的需求，希望可以记录下函数的执行日志，于是在代码中添加日志代码： 1234import loggingdef foo(): print('i am foo') logging.info("foo is running") 如果有些函数也有类似的需求，怎么做？都写一个logging在函数内？这样就造成了大量雷同的代码，为了减少重复写代码，可以这么做，重新定义一个函数专门处理日志，日志处理完之后再执行真正的业务代码： 123456789101112def use_logging(func): logging.warning("%s is running" % func.__name__) func() def bar(): print('i am bar')use_logging(bar)# output:# WARNING:root:bar is running# i am bar 逻辑上不难理解，但这样的话，我们每次都要将一个函数作为参数传递给use_logging函数。而且这种方式已经破坏了原有的代码逻辑结构，之前执行业务逻辑时，执行运行bar()，但是现在不得不改成use_logging(bar)。那么有没有更好的方式呢？当然有，答案就是装饰器。 简单装饰器123456789101112131415def use_logging(func): def wrapper(*args, **kwargs): logging.warning("%s is running" % func.__name__) return func(*args, **kwargs) return wrapperdef bar(): print('i am bar') bar = use_logging(bar)bar()# output:# WARNING:root:bar is running# i am bar 函数use_logging就是装饰器，它把执行真正业务方法的func包裹在函数里面，看起来像bar被logging包起来，被装饰了。在这个例子中，函数进入和退出时，被称为一个横切面(Aspect)，这种编程方法称为面向切面的编程(Aspect-Oriented Programming)。 @符号是装饰器的语法糖，在定义函数的时候使用，避免再一次赋值操作。 12345678910111213141516171819def use_logging(func): def wrapper(*args, **kwargs): logging.warning("%s is running" % func.__name__) return func(*args) return wrapper@use_loggingdef foo(): print('i am foo') @use_loggingdef bar(): print('i am bar') bar()# output:# WARNING:root:bar is running# i am bar 如上所示，使用@符号我们就可以省去bar = use_logging(bar)这一句了，直接调用bar()即可得到想要的结果。如果我们有其他的类似函数，我们就可以继续调用装饰器来修饰函数，而不用重新修改函数或者增加新的封装。这样，我们就提高了程序的可重复利用性，并增加了程序的可读性。 装饰器在Python中使用如此方便都要归功于Python的函数能像普通的对象一样能作为参数传递给其他函数，可以被赋值给其他的变量，可以作为返回值，可以被定义在另一个函数内。 带参数的装饰器装饰器还有更大的灵活性，例如带参数的装饰器：在上面的装饰器调用中，比如@use_logging，该装饰器唯一的参数就是执行业务的函数。装饰器的语法云溪我们在调用时，提供其他参数比如@decorator(a)。这样，就为装饰器的编写和使用提供了更大的灵活性。 123456789101112131415161718def use_logging(level): def decorator(func): def wrapper(*args, **kwargs): if level == "warn": logging.warning("%s is running" % func.__name__) return func(*args) return wrapper return decorator@use_logging(level="warn")def foo(name='foo'): print("i am %s" % name) foo()# output:# WARNING:root:bar is running# i am bar 上面的use_logging是允许带参数的装饰器。它实际上是对原有装饰器的一个函数封装，并返回一个装饰器。我们可以将它理解为一个含有参数的闭包。当我们使用@use_logging(level=&quot;warn&quot;)调用的时候，Python能够发现这一层的封装，并把参数传递到装饰器的环境中。 类装饰器再来看看类装饰器，相比函数装饰器，类装饰器具有灵活度大，高内聚，封装性等优点。使用类装饰器还可以依赖类内部的__call__方法，当使用@形式将装饰器附加到函数上时，就会调用此方法。 12345678910111213141516171819class Foo(object): def __init__(self, func): self._func = func def __call__(self): print('class decorator running') self._func() print('class decorator ending') @Foodef bar(): print('bar') bar()# output:# class decorator running# bar# class decorator ending functools.wraps使用装饰器极大地复用了代码，但是它有个缺点就是原函数的元信息不见了，比如函数的docstring、__name__、参数列表，先看例子： 装饰器： 12345def logged(func): def with_logging(*args, **kwargs): print(func.__name__ + "was called") return func(*args, **kwargs) return with_logging 函数： 1234@loggeddef f(x): '''do some math''' return x + x * x 该函数完全等价于： 12345def f(x): '''do some math''' return x + x * xf = logged(f) 不难发现，函数f被with_logging替代了，当然它的docstring、__name__就变成了with_logging函数的信息了。 123456print(f.__name__)print(f.__doc__)# output:# with_logging# None 这个问题就比较严重了，好在我们有function.wraps，wraps本身也是一个装饰器，它能把原函数的元信息拷贝到装饰器函数中，这使得装饰器函数也有和原函数一样的元信息了。 12345678910111213141516171819from functools import wrapsdef logged(func): @wraps(func) def with_logging(*args, **kwargs): print(func.__name__ + "was called") return func(*args, **kwargs) return with_logging@loggeddef f(x): '''do some math''' return x + x * xprint(f.__name__)print(f.__doc__)# output:# f# do some math 内置装饰器@staticmethod、@classmethod、@property 装饰器的顺序： 1234@a@b@cdef f(): 等效于 1f = a(b(c(f))) 引用资料： 如何理解Python装饰器？ - 知乎]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中的Lambda函数及其用法]]></title>
    <url>%2F2018%2F11%2F01%2FPython%E4%B8%AD%E7%9A%84Lambda%E5%87%BD%E6%95%B0%E5%8F%8A%E5%85%B6%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Python中的Lambda函数及其用法Lambda函数又称为匿名函数，匿名函数就是没有名字的函数。有些函数如果只是临时一用，而且它的业务逻辑也很简单时，就可以将其定义为匿名函数。 匿名函数有个限制，就是只能有一个表达式，不用写return，返回值就是该表达式的结果。 用匿名函数有个好处，因为函数没有名字，不必担心函数名冲突。此外，匿名函数也是一个函数对象，也可以把匿名函数赋值给一个变量，再利用变量来调用该函数。 先来看个简单的lambda函数： 12&gt;&gt;&gt; lambda x, y : x + y&lt;function &lt;lambda&gt; at 0x102bc1c80&gt; x和y是函数的两个参数，冒号后面的表达式是函数的返回值，很明显这个匿名函数就是在求两个变量的和，但作为一个函数，没有名字如何使用呢？ 这里我们暂且给这个匿名函数绑定一个名字，这样使得我们调用匿名函数成为可能。 12345&gt;&gt;&gt; add = lambda x, y : x+y&gt;&gt;&gt; add&lt;function &lt;lambda&gt; at 0x102bc2140&gt;&gt;&gt;&gt; add(1,2)3 它等同于常规函数 1234567&gt;&gt;&gt; def add1(x, y):... return x+y...&gt;&gt;&gt; add1&lt;function add1 at 0x102bc1c80&gt;&gt;&gt;&gt; add1(1,2)3 lambda函数的使用场景(函数式编程)sorted函数例如：一个整数列表，要求按照列表中元素的绝对值大小升序排列。 123&gt;&gt;&gt; list1 = [3,5,-4,-1,0,-2,-6]&gt;&gt;&gt; sorted(list1, key=lambda x: abs(x))[0, -1, -2, 3, -4, 5, -6] 排序函数sorted支持接收一个函数作为参数，该参数作为sorted的排序依据，这里按照列表元素的绝对值进行排序。 当然，也可以通过普通函数来实现： 12345&gt;&gt;&gt; def foo(x):... return abs(x)...&gt;&gt;&gt; sorted(list1, key=foo)[0, -1, -2, 3, -4, 5, -6] 只不过是使用这种方式，代码看起来不够Pythonic而已。 lambda：这是Python支持的一种有趣的语法，它允许你快速定义单行的最小函数，可以用在任何需要函数的地方: 12345&gt;&gt;&gt; add = lambda x,y : x+y&gt;&gt;&gt; add(5,6)11&gt;&gt;&gt; (lambda x,y:x+y)(5,6)11 map,reduce,filter函数123456789101112# 求1~20的平方&gt;&gt;&gt; list(map(lambda x:x*x,range(1,21))) [1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400]# 求1~20之间的偶数&gt;&gt;&gt; list(filter(lambda x:x%2 == 0,range(1,21))) [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]# 求1~100之和,再加上10000&gt;&gt;&gt; from functools import reduce&gt;&gt;&gt; reduce(lambda x,y:x+y,range(1,101),10000)15050 闭包闭包：一个定义在函数内部的函数，闭包使得变量即使脱离了该函数的作用域也依然能被访问到。 看一个用lambda函数作为闭包的例子： 123456&gt;&gt;&gt; def add(n):... return lambda x:x+n # 将匿名函数作为返回值返回...&gt;&gt;&gt; add2 = add(5)&gt;&gt;&gt; add2(15)20 这里的lambda函数就是一个闭包，在全局作用域范围中，add2(15)可以正常执行且返回值为20。之所以返回20是因为在add局部作用域中，变量n的值在闭包的作用下也可以被访问到。 参考资料 匿名函数 - 廖雪峰的官方网站 深入理解Lambda函数及其用法 - 碧水幽幽泉 - 博客园]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中的高阶函数]]></title>
    <url>%2F2018%2F10%2F29%2FPython%E4%B8%AD%E7%9A%84%E9%AB%98%E9%98%B6%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Python中的高阶函数在熟悉了Python基础知识后，我们已经可以做一些脚本开发，或者简单的程序。然而，当我们开发较为复杂的程序时，仅使用基础知识内容就会显得比较吃力。这时，了解Python中的一些高级特性会使我们的开发过程变得简单和快乐。 在函数式编程中，我们可以将函数当做变量一样自由使用。一个函数接收另一个函数作为参数，这种函数称之为高阶函数(Higher-order-Functions)。 看一个简单的例子： 12def func(g, arr): return [g(x) for x in arr] 上面的代码中func是一个高阶函数，它接收两个参数，第一个参数是函数，第二个参数是数组，func的功能是将函数g逐个作用于数组arr上，并返回一个新的数组。比如，我们可以这样用： 123456789def double(x): return 2 * x def square(x): return x * xlist = [1, 2, 3, 4]arr1 = func(double, list) # arr1 = [2, 4, 6, 8]arr2 = func(square, list) # arr2 = [1, 4, 9, 16] 说到高阶函数，就不得不提到闭包，这里介绍一下Python中闭包的定义： 如果在一个内部函数里，对外部作用域(但不是全局作用域)的变量进行引用，那么内部函数就被认为是闭包(closure)。 就拿此例来说，内部函数double中包含了对函数func中局部变量list的引用，这就是闭包。 map reduce filter sorted是Python中较为常用的内置高阶函数，它们为函数式编程提供了不少便利。 说明：本文介绍的内置高阶函数的定义可能会因为Python版本的不同而有所不同，文章以Python3.x版本中的定义为标准。 mapmap函数的使用形式如下： 1map(function, iterable, ...) 注意：这里函数一定要作为map的第一个参数，而不是第二个参数，否则会产生报错。 解释：function函数会作用于可迭代对象的每一个元素，生成结果，并返回一个迭代器。更加具体一点说就是map函数接收两个参数，一个是函数，一个是Iterable，map将传入的函数依次作用到Iterable的每个元素，并把结果作为新的Iterator返回。 举例说明，比如我们一个函数f(x)=x^2，要把这个函数作用在一个list[1, 2, 3, 4, 5, 6, 7, 8, 9]上，就可以用map()实现。 现在，我们用Python代码实现： 123456&gt;&gt;&gt; def f(x):... return x * x...&gt;&gt;&gt; r = map(f, [1, 2, 3, 4, 5, 6, 7, 8, 9])&gt;&gt;&gt; list(r)[1, 4, 9, 16, 25, 36, 49, 64, 81] map传入的第一个参数是f，即函数对象本身。由于结果r是一个Iterator，Iterator是惰性序列，因此需要通过list()函数让它把整个序列都计算出来并返回一个list。 你可能会想，不需要map函数，写一个循环，也可以计算出结果： 1234L = []for n in [1, 2, 3, 4, 5, 6, 7, 8, 9]: L.append(f(n))print(L) 的确可以，但是，从上面的循环代码，能一眼看明白“把f(x)作用在list的每一个元素并把结果生成一个新的list”吗？明显可读性就差了很多。 所以，map作为高阶函数，体现了Python的设计原则优雅、明确、简单，事实上它把运算规则抽象化。因此，我们不但可以计算简单的f(x)=x2，还可以计算任意复杂的函数，比如，把list中的所有数字转化为字符串格式： 12&gt;&gt;&gt; list(map(str, [1, 2, 3, 4]))['1', '2', '3', '4'] 只需一行代码。 看一些简单的例子： 12345678910111213&gt;&gt;&gt; def square(x):... return x * x&gt;&gt;&gt; map(square, [1, 2, 3, 4])&lt;map at 0x106adfe48&gt;&gt;&gt;&gt; list(map(square, [1, 2, 3, 4]))[1, 4, 9, 16]&gt;&gt;&gt; list(map(lambda x: x * x, [1, 2, 3, 4])) # 使用 lambda[1, 4, 9, 16]&gt;&gt;&gt; list(map(lambda x, y: x + y, [1, 2, 3, 4], [5, 6, 7, 8]))[6, 8, 10, 12] 再来看个复杂一点例子： 1234567891011121314151617def double(x): return 2 * xdef triple(x): return 3 *xdef square(x): return x * xfuncs = [double, triple, square] # 列表元素是函数对象# 相当于 [double(4), triple(4), square(4)]value = list(map(lambda f: f(4), funcs))print(value)output:[8, 12, 16] 最后我想要说明一点，迭代器有一个特点，就是所有的迭代器对象都可以作为next()内置函数的参数调用，每调用一次，就按角标顺序返回一个值，还是用代码讲吧： 123456iter = map(lambda x: x * x, [1, 2, 3, 4])print(next(iter)) # 打印值为：1print(next(iter)) # 打印值为：4print(next(iter)) # 打印值为：9print(next(iter)) # 打印值为：16print(next(iter)) # 抛出StopIteration 异常 reducereduce函数的使用形式如下： 1reduce(function, iterable[, initializer]) 解释：reduce函数必须接受两个参数，先将iterable的前两个item传给function，即function(item1, item2)，函数的返回值和iterable的下一个item再传给function，即function(function(item1, item2), item3)，如此迭代，直到iterable没有元素，如果有initializer，则作为初始值调用。 也就是说： 12reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4)# 列表中是以从左到右作为优先顺序 看一些例子，就能很快理解了。 12345678910111213&gt;&gt;&gt; from functools import reduce&gt;&gt;&gt; reduce(lambda x, y: x * y, [1, 2, 3, 4]) # 相当于 ((1 * 2) * 3) * 424&gt;&gt;&gt; reduce(lambda x, y: x - y, [8, 5, 1], 20) # ((20 - 8) - 5) - 16&gt;&gt;&gt; f = lambda a, b: a if (a &gt; b) else b # 两两比较，取最大值&gt;&gt;&gt; reduce(f, [5, 8, 1, 10])10&gt;&gt;&gt; def fn(x, y): # 把序列[1, 3, 5, 7, 9]变换成整数13579... return x * 10 + y...&gt;&gt;&gt; reduce(fn, [1, 3, 5, 7, 9])13579 filterfilter函数用于过滤元素，它的使用形式如下： 1filter(function, iterable) 解释：和map类似，filter也接收一个函数和一个序列。但和map不同的是，filter把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。将function依次作用于iterable的每个item上，即function(item)，用function返回值为True的item构成iterator作为filter的最终返回值。 看一些例子。 12345678910&gt;&gt;&gt; even_num = list(filter(lambda x: x % 2 == 0, [1, 2, 3, 4, 5, 6]))&gt;&gt;&gt; even_num[2, 4, 6]&gt;&gt;&gt; odd_num = list(filter(lambda x: x % 2, [1, 2, 3, 4, 5, 6]))&gt;&gt;&gt; odd_num[1, 3, 5]&gt;&gt;&gt; list(filter(lambda x: x &lt; 'g', 'hijack'))'ac'&gt;&gt;&gt; filter(lambda x: x &lt; 'g', 'hijack')&lt;filter object at 0x1034b4080&gt; # python3 可见用filter这个高阶函数，关键在于正确实现一个“筛选”函数。 注意到filter函数返回的同样是一个Iterator，也就是一个惰性序列，所以要强迫filter完成计算结果，需要用list()函数获得所有结果。 sortedsorted函数用于对list进行排序，它的使用形式如下： 1sorted(iterable, *, key=None, reverse=False) 解释：sorted有两个可选参数，必须指定为关键字参数。将key指定的函数作用于iterable的每一个元素上，并根据key函数返回的结果进行排序，最终返回一个新的排序列表。key默认值为None，即直接比较元素大小。 reverse是一个布尔值。如果设置为True，则列表元素将按照比较结果相反的方式进行排序。 看一些例子： 12345678910&gt;&gt;&gt; sorted([36, 5, -12, 9, -21])[-21, -12, 5, 9, 36]&gt;&gt;&gt; sorted([36, 5, -12, 9, -21], key=abs)[5, 9, -12, -21, 36]&gt;&gt;&gt; sorted(['bob', 'about', 'Zoo', 'Credit'])['Credit', 'Zoo', 'about', 'bob']&gt;&gt;&gt; sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower)['about', 'bob', 'Credit', 'Zoo']&gt;&gt;&gt; sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower, reverse=True)['Zoo', 'Credit', 'bob', 'about'] 从上述例子可以看出，高阶函数的抽象能力是非常强大的，而且核心代码可以保持得非常简洁。 小结 可接受其他函数作为参数的函数称为高阶函数； map reduce filter sorted为函数式编程提供了不少便利，可使代码变得更简洁； 通过map()来对Iterable中的每个元素进行相同的函数处理最终返回一个Iterator。 reduce()类似栈的思想，先让栈顶的两个元素出栈作为函数的两个参数，再将函数的返回值入栈，然后再让栈顶两个元素出栈，不断循环下去，直到栈里没有元素为止。 filter()的作用是从一个序列中筛选出符合条件的元素。由于filter()使用了惰性计算，所以只有在取filter()结果的时候，才会真正筛选并每次返回下一个筛出的元素。 sorted()也是一个高阶函数。用sorted()排序的关键在于实现一个映射函数。 参考资料 高阶函数 - 廖雪峰的官方网站 map/reduce/filter - Python 之旅 - 极客学院Wiki 高阶函数 - Python 之旅 - 极客学院Wiki Python笔记(二)：高级特性之高阶函数 - 简书]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中@classmethod和@staticmethod的区别]]></title>
    <url>%2F2018%2F10%2F27%2FPython%E4%B8%AD%40classmethod%E5%92%8C%40staticmethod%E7%9A%84%E5%8C%BA%E5%88%AB%E7%9A%84%E5%89%AF%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Python中@classmethod和@staticmethod的区别接上一篇介绍Python中@staticmethod和@classmethod的用法的文章。虽然@classmethod和@staticmethod非常相似，但两个修饰符的使用情况仍略有不同。 从它们的使用上来看： @classmethod必须引用一个类对象作为第一个参数，即第一个参数需要是表示自身类的cls参数。同时@classmethod因持有cls参数，所以可以调用类的属性，类的方法，实例化对象等，避免硬编码。 @staticmethod则可以完全没有参数，但在@staticmethod中要调用到这个类的一些属性方法，只能直接类名.属性名或类名.方法名()。 示例1234567891011121314151617181920class Date(object): def __init__(self, day=0, month=0, year=0): self.day = day self.month = month self.year = year @classmethod def from_string(cls, date_as_string): day, month, year = map(int, date_as_string.split("-")) date1 = cls(day, month, year) return date1 @staticmethod def is_date_valid(date_as_string): day, month, year = map(int, date_as_string.split("-")) return day &lt;= 31 and month &lt;= 12 and year &lt;= 3999 date2 = Date.from_string("27-10-2018")is_date = Date.is_date_valid("27-10-2018") 解释让我们假设这样一个类的例子，用来处理日期信息(这将是我们的样板)： 12345class Date(object): def __init__(self, day=0, month=0, year=0): self.day = day self.month = month self.year = year 显然，这个类可以用来存储关于某些日期的信息(没有时区信息；假设所有日期都以UTC表示)。 这个类中有__init__，它是Python类实例的初始化方法，它接收参数作为类实例方法，具有第一个非可选参数self(作为对新创建实例的引用)。 Class Method我们有一些任务，通过使用@classmethod可以很好地完成它们。 假设我们想要创建许多Date类实例，其日期信息来自外部输入(编码格式为’dd-mm-year’的字符串)，并假设我们必须在项目源代码的不同位置执行此操作。 所以我们这里必须做到： 解析输入的字符串以接收日、月、年作为三个整数变量或由这些变量组成的三元组。 通过将上面求到的值传递给初始化调用来创建Date类实例。 代码看起来会是这样： 12day, month, year = map(int, string_date.split('-'))date1 = Date(day, month, year) 如果使用@classmethod修饰符写在类中，将会是： 1234567 @classmethod def from_string(cls, date_as_string): day, month, year = map(int, date_as_string.split('-')) date1 = cls(day, month, year) return date1date2 = Date.from_string('27-10-2018') 让我们更仔细地看看上面的代码实现，并回想一下我们做了什么？ 我们在一个地方实现了日期字符串解析函数，现在它可以重用。 将日期字符串解析函数封装在类中并且工作正常(当然你可以在其他地方实现日期字符串解析作为单个函数，但这个解决方案更适合OOP范例)。 cls是一个保存类本身的对象，而不是类的实例。这很酷😎，因为如果我们继承Date类，所有子类也会定义from_string()。 Static Method@staticmethod确实与@classmethod很相似，但@staticmethod不需要任何强制性参数(如类方法或实例方法)。 让我们看看下一个任务(下一个用例): 假设我们有一个日期字符串，我们想要以某种方式进行验证它是否符合要求的格式。此任务也需要封装在Date类中，但不需要实例化它。 这里使用@staticmethod就会很有效。让我们看一下代码： 1234567@staticmethoddef is_date_valid(date_as_string): day, month, year = map(int, date_as_string.split('-')) return day &lt;= 31 and month &lt;= 12 and year &lt;= 3999# usage:is_date = Date.is_date_valid('27-10-2018') 运行上述代码得到is_date是个boolen型变量，而非is_date_valid函数返回的day，month，year三个整型数据。 因此，我们可以从@staticmethod的使用中看到，我们无法访问类的内容——它基本上只是一个函数，在语法上称为方法，无法访问对象及其内部(字段和其他类方法)。而使用@classmethod却可以做到。 补充上面的文章已经很全面地总结了@classmethod和@staticmethod的区别。在这里我想强调当你创建构造函数时，你应该选择@classmethod而不是@staticmethod的另一个原因。在上面的例子中，使用@classmethod from_string()作为Factory，接收不符合__init__要求的参数创建Date类实例。使用@staticmethod可以完成同样的操作，如下面代码所示： 12345678910111213141516171819202122class Date: def __init__(self, month, day, year): self.month = month self.day = day self.year = year def display(self): return "&#123;0&#125;-&#123;1&#125;-&#123;2&#125;".format(self.month, self.day, self.year) @staticmethod def millenium(month, day): return Date(month, day, 2000)new_year = Date(1, 1, 2013) # Creates a new Date objectmillenium_new_year = Date.millenium(1, 1) # also creates a Date object. # Proof:new_year.display() # "1-1-2013"millenium_new_year.display() # "1-1-2000"isinstance(new_year, Date) # Trueisinstance(millenium_new_year, Date) # True 运行结果显示new_year和millenium_new_year都是Date类实例。 但是，如果仔细观察就会发现，millenium_new_year是以硬编码的方式创建的Date类实例。这意味着即使一个类继承Date类，该子类仍将创建普通的Date对象即父类对象，而不具有该子类本身的任何属性。请参阅以下示例代码： 12345678910111213class DateTime(Date): def display(self): return "&#123;0&#125;-&#123;1&#125;-&#123;2&#125; - 00:00:00PM".format(self.month, self.day, self.year)datetime1 = DateTime(10, 10, 1990)datetime2 = DateTime.millenium(10, 10)isinstance(datetime1, DateTime) # Trueisinstance(datetime2, DateTime) # Falsedatetime1.display() # returns "10-10-1990 - 00:00:00PM"datetime2.display() # returns "10-10-2000" because it's not a DateTime object but a Date object. Check the implementation of the millenium method on the Date class DateTime类继承Date类，因此具有Date类的millenium()方法。datetime2通过调用DateTime继承来的millenium()方法来创建DateTime类实例。然而代码却显示datetime2并不是DateTime类实例(isinstance(datetime2, DateTime) # False)。怎么回事？这是因为使用了@staticmethod修饰符。 在大多数情况下，这是你不希望出现的。如果你想要的是一个”完整“的类实例，并且是通过调用它的父类方法所创建的话，那么@classmethod就是你所需要的。 将Date.millenium()重写为(这是上述代码中唯一改变的部分)： 123@classmethoddef millenium(cls, month, day): return cls(month, day, 2000) 确保该类的创建不是通过硬编码。cls可以是任何子类，生成的对象将正确地成为cls的实例。我们来试试吧： 123456789datetime1 = DateTime(10, 10, 1990)datetime2 = DateTime.millenium(10, 10)isinstance(datetime1, DateTime) # Trueisinstance(datetime2, DateTime) # Truedatetime1.display() # "10-10-1990 - 00:00:00PM"datetime2.display() # "10-10-2000 - 00:00:00PM" 看吧，用@classmethod替代@staticmethod你不希望出现的情况就会消失。使用了@staticmethod修饰符定义构造函数就是问题出现的关键。 文章的内容有点多，可能需要花一些时间进行理解，最后提供一个小示例帮助大家加深记忆一下@classmethod和@staticmethod的主要不同。 1234567891011121314151617181920212223242526class A(object): bar = 1 def foo(self): print 'foo' @staticmethod def static_foo(): print 'static_foo' print A.bar @classmethod def class_foo(cls): print 'class_foo' print cls.bar cls().foo() A.static_foo()A.class_foo()output:static_foo1class_foo1foo 引用文章： 飘逸的python - @staticmethod和@classmethod的作用与区别 - mattkang - CSDN博客 python - Meaning of @classmethod and @staticmethod for beginner? - Stack Overflow]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中@staticmethod和@classmethod的用法]]></title>
    <url>%2F2018%2F10%2F27%2FPython%E4%B8%AD%40staticmethod%E5%92%8C%40classmethod%E7%9A%84%E7%94%A8%E6%B3%95%E7%9A%84%E5%89%AF%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Python中@staticmethod和@classmethod的用法一般来说，调用某个类的方法，需要预先生成一个实例，再通过实例调用方法。Java中有静态方法，可以使用类直接进行调用。Python中提供了两个修饰符@staticmethod和@classmethod以达到类似效果，使用它们就可以不需要实例化，直接类名.方法名()来调用。这有利于组织代码，把某些应该属于某个类的函数给放到那个类中，同时有利于命名空间的整洁。 @staticmethod@staticmethod声明方法为静态方法，直接通过类名.方法名()调用。经过@staticmethod修饰的方法，不需要self参数，其使用方法和直接调用函数一样。 1234567891011121314151617181920#直接定义一个test()函数def test(): print "i am a normal method!" #定义一个类，其中包括一个类方法，采用@staticmethod修饰 class T: @staticmethod def static_test(): # 没有self参数 print "i am a static method!" if __name__ == "__main__": test() T.static_test() T().static_test()output:i am a normal method!i am a static method!i am a static method! @classmethod@classmethod声明方法为类方法，直接通过类名.方法名()调用。经过@classmethod修饰的方法，不需要self参数，但是需要一个标识类本身的cls参数。 12345678910111213class T: @classmethod def class_test(cls): # 必须有cls参数 print "i am a class method" if __name__ == "__main__": T.class_test() T().class_test()output:i am a class methodi am a class method @classmethod另一个实用的用法：在不改变已经写好的类里面的方法的情况下，对输入的数据进行处理。 12345678910111213141516# 输出年月日，正常的情况下class demo1: def __init__(self, year=0, month=0, day=0): self.year = year self.month = month self.day = day def out_date(self): return "year: %d, month: %d, day: %d" % (self.year, self.month, self.day) year = 2018month = 10day = 27demo1 = demo1(year, month, day)print(demo1.out_date()) # year: 2018, month: 10, day: 27 1234567891011121314151617181920212223242526# 如果用户输入的是2018-10-27格式，需要在输出前处理一下，就可以使用classmethod达到想要的效果class demo2: def __init__(self, year=0, month=0, day=0): self.year = year self.month = month self.day = day def out_date(self): return "year: %d, month: %d, day: %d" % (self.year, self.month, self.day) @classmethod def pre_out(cls, date_string): year, month, day = map(int, date_string.split("-")) return cls(year, month, day) date = "2018-10-27"year = 2017month = 7day = 7try: demo2 = demo2.pre_out(date)except: demo2 = demo2(year, month, day) print(demo2.out_date()) # year: 2018, month: 10, day: 6 小结 @staticmethod不需要表示自身对象的self参数和自身类的cls参数，就跟使用函数一样。 @classmethod也不需要self参数，但第一个参数需要是表示自身类的cls参数。 在Python中类和实例都是对象，都占用了内存空间，合理使用@staticmethod和@classmethod修饰符，就可以不经过实例化直接使用类的方法了。 引用文章： Python @staticmethod@classmethod用法 - sinat_34079973的博客 - CSDN博客 飘逸的python - @staticmethod和@classmethod的作用与区别 - mattkang - CSDN博客 classmethod的两个实用用法 - 简书]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中super()函数的用法及其说明]]></title>
    <url>%2F2018%2F10%2F26%2FPython%E4%B8%ADsuper()%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%B3%95%E7%9A%84%E5%89%AF%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Python中super()函数的用法及其说明为了调用父类(超类)的一个方法，可以使用super()函数，比如： 12345678class A: def spam(self): print('A.spam')class B(A): def spam(self): print('B.spam') super().spam() # Call parent spam() super()函数的一个常见用法是在__init__()中确保父类被正确的初始化： 12345678class A: def __init__(self): self.x = 0class B(A): def __init__(self): super().__init__() self.y = 1 说明__init__()函数：定义类的时候，若是添加__init__()函数，那么在创建类的实例的时候，实例会自动调用这个方法，一般用来对实例的属性进行初始化。 super()的另外一个常见用法出现在覆盖Python特殊方法的代码中，比如： 1234567891011121314class Proxy: def __init__(self, obj): self._obj = obj # Delegate attribute lookup to internal obj def __getattr__(self, name): return getattr(self._obj, name) # Delegate attribute assignment def __setattr__(self, name, value): if name.startswith('_'): super().__setattr__(name, value) # Call original __setattr__ else: setattr(self._obj, name, value) 实际上，大家对于在Python中如何正确使用super()函数普遍知之甚少。你有时候会看到像下面这样直接调用父类的一个方法： 12345678class Base: def __init__(self): print('Base.__init__')class A(Base): def __init__(self): Base.__init__(self) print('A.__init__') 尽管对于大部分代码而言这么做没什么问题，但是在更复杂的涉及到多继承的代码中就有可能导致很奇怪的问题发生。比如，考虑下面的情况： 12345678910111213141516171819class Base: def __init__(self): print('Base.__init__')class A(Base): def __init__(self): Base.__init__(self) print('A.__init__')class B(Base): def __init__(self): Base.__init__(self) print('B.__init__')class C(A,B): def __init__(self): A.__init__(self) B.__init__(self) print('C.__init__') 运行这段代码后就会发现Base.__init__被调用两次，如图所示： 123456&gt;&gt;&gt; c = C()Base.__init__A.__init__Base.__init__B.__init__C.__init__ 可能两次调用Base.__init__()没什么坏处，但有时候却不是。另一方面，假设在代码中换成使用super()，结果就很完美了： 123456789101112131415161718class Base: def __init__(self): print('Base.__init__')class A(Base): def __init__(self): super().__init__() print('A.__init__')class B(Base): def __init__(self): super().__init__() print('B.__init__')class C(A,B): def __init__(self): super().__init__() # Only one call to super() here print('C.__init__') 运行这个新版本后，你会发现Base.__init__()方法只会被调用一次： 12345&gt;&gt;&gt; c = C()Base.__init__B.__init__A.__init__C.__init__ 所以说，super()是用来解决多重继承问题的，直接用类名调用父类方法在使用单继承的时候没问题，但是如果使用多继承，会涉及到查找顺序(MRO)、重复调用(钻石继承)等种种问题。 说明：MRO就是类的方法解析顺序表，其实也就是继承父类方法时的顺序表，下面会有更详尽的介绍。 为了弄清它的原理，我们需要花点时间解释下Python是如何实现继承的。对于你定义的每一个类，Python会计算出一个所谓的方法解析顺序(MRO)列表。这个MRO列表就是一个简单的所有基类的线性顺序表。例如： 123&gt;&gt;&gt; C.__mro__(&lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;class '__main__.B'&gt;,&lt;class '__main__.Base'&gt;, &lt;class 'object'&gt;) 为了实现继承，Python会在MRO列表上从左到右开始查找基类，直到找到第一个匹配这个属性的类为止。 而这个MRO列表的构造是通过一个C3线性化算法来实现的。我们不去深究这个算法的数学原理，它实际上就是合并所有父类的MRO列表并遵循如下三条准则： 子类会先于父类被检查 多个父类会根据它们在列表中的顺序被检查 如果对下一个类存在两个合法的选择，选择第一个父类 老实说，你所要知道的就是MRO列表中的类顺序会让你定义的任意类层级关系变得有意义。 当你使用super()函数时，Python会在MRO列表上继续搜索下一个类。只要每个重定义的方法统一使用super()并只调用它一次，那么控制流最终会遍历完整个MRO列表，每个方法也只会被调用一次。这也是为什么在第二个例子中你不会调用两次Base.__init__()的原因。 super()有个令人吃惊的地方是它并不一定去查找某个类在MRO中下一个直接父类，你甚至可以在一个没有直接父类的类中使用它。例如，考虑如下这个类： 1234class A: def spam(self): print('A.spam') super().spam() 如果你试着直接使用这个类就会出错： 1234567&gt;&gt;&gt; a = A()&gt;&gt;&gt; a.spam()A.spamTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 4, in spamAttributeError: 'super' object has no attribute 'spam' 但是，如果你使用多继承的话看看会发生什么： 1234567891011&gt;&gt;&gt; class B:... def spam(self):... print('B.spam')...&gt;&gt;&gt; class C(A,B):... pass...&gt;&gt;&gt; c = C()&gt;&gt;&gt; c.spam()A.spamB.spam 你可以看到在类A中使用super().spam()实际上调用的是与类A毫无关系的类B中的spam()方法。这个用类C的MRO列表就可以完全解释清楚： 123&gt;&gt;&gt; C.__mro__(&lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;class '__main__.B'&gt;,&lt;class 'object'&gt;) 在定义混入类的时候这样使用super()是很普遍的。 然而，由于super()可能会调用不是你想要的方法，你应该遵循一些通用原则。首先，确保在继承体系中所有相同名字的方法拥有可兼容的参数签名(比如相同的参数个数和参数名称)。这样可以确保super()调用一个非直接父类方法时不会出错。其次，最好确保最顶层的类提供了这个方法的实现，这样的话在MRO上面的查找链肯定可以找到某个确定的方法。 在Python社区内对于super()的使用有时候会引来一些争议。尽管如此，如果一切顺利的话，你应该在你最新的代码中使用它。Raymond Hettinger为此写了一篇非常好的文章，有兴趣的话可以去查查看，文章通过大量的例子向我们解释了为什么super()是极好的。 最后通过一个很好的实例帮助大家加深一下记忆： 12345678910111213141516171819202122class FooParent(object): def __init__(self): self.parent = 'I\'m the parent.' print ('Parent') def bar(self,message): print ("%s from Parent" % message) class FooChild(FooParent): def __init__(self): # super(FooChild,self) 首先找到 FooChild 的父类（就是类 FooParent），然后把类B的对象 FooChild 转换为类 FooParent 的对象 super(FooChild,self).__init__() print ('Child') def bar(self,message): super(FooChild, self).bar(message) print ('Child bar fuction') print (self.parent) if __name__ == '__main__': fooChild = FooChild() fooChild.bar('HelloWorld') 执行结果： 12345ParentChildHelloWorld from ParentChild bar fuctionI&apos;m the parent. 引用文章： Python super() 函数 | 菜鸟教程 8.7 调用父类方法 — python3-cookbook 3.0.0 文档]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo使用攻略：添加搜索功能]]></title>
    <url>%2F2018%2F10%2F26%2FHexo%E4%BD%BF%E7%94%A8%E6%94%BB%E7%95%A5%EF%BC%9A%E6%B7%BB%E5%8A%A0%E6%90%9C%E7%B4%A2%E5%8A%9F%E8%83%BD%E7%9A%84%E5%89%AF%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Hexo使用攻略：添加搜索功能本教程针对的是Mac环境 前言当博文越来越多的时候，标签和分类已经不能提供太大的作用，无法准确的定位到自己想要看的博文上去了，所以添加一个站内搜索功能是很有必要的。 Hexo适配多款搜索插件，个人感觉”Local Search”已满足日常需要，所以下面介绍为Hexo添加”Local Search”搜索插件的过程。 安装插件在命令行中cd到自己的hexo文件夹下(例：/Users/rilzob/hexo)，执行npm install hexo-generator-searchdb --save命令进行安装，等待安装完成。 修改站点配置文件修改当前目录下的_config.yml文件(例：/Users/rilzob/hexo/_config.yml)，新增以下内容到该文件内的任意位置。 123456# Searchsearch: path: search.xml field: post format: html limit: 10000 注意：每个冒号后面都有空格 修改主题配置文件修改主题目录下的_config.yml文件(例：/Users/rilzob/hexo/themes/xxx/_config.yml)，找到该文件内的 1234# Local search# Dependencies: https://github.com/flashlab/hexo-generator-searchlocal_search: enable: false 代码段，将其修改为： 1234# Local search# Dependencies: https://github.com/flashlab/hexo-generator-searchlocal_search: enable: true 即将enable: false修改为enable: true。 重新部署依旧在命令行中进行操作，在hexo文件夹下依次执行hexo g,hexo server和hexo deploy指令即可。这样搜索功能就添加成功了。 引用文章: 1.Hexo博客添加搜索功能 | IT范儿 2.hexo博客添加搜索功能 - qq_40265501的博客 - CSDN博客]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo使用攻略：添加分类及标签]]></title>
    <url>%2F2018%2F10%2F25%2FHexo%E4%BD%BF%E7%94%A8%E6%94%BB%E7%95%A5%EF%BC%9A%E6%B7%BB%E5%8A%A0%E5%88%86%E7%B1%BB%E5%8F%8A%E6%A0%87%E7%AD%BE%E7%9A%84%E5%89%AF%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Hexo使用攻略：添加分类及标签本教程针对的是Mac环境 Hexo创建”分类”选项生成”分类”页并添加type属性 打开命令行，cd进入博客所在文件夹。执行命令hexo new page categories，来新建一个页面，并命名为categories。成功后会提示：INFO Created: ~/hexo/source/categories/index.md 根据上面的路径找到index.md这个文件，打开后默认内容如下： 1234---title: categoriesdate: 2018-10-25 20:11:37--- 编辑新创建的页面，添加type: &quot;categories&quot;到内容中(注意，这些属性和属性值之间必须有一个空格)，主题将自动为这个页面显示所有分类，添加后是这样的： 12345---title: categoriesdate: 2018-10-25 20:11:37type: &quot;categories&quot;--- 保存并关闭文件。 给文章添加”categories”属性 打开需要添加分类的文章，为其添加categories属性。下方的categories: Python表示添加这篇文章到“Python”这个分类中。 注意：Hexo中一篇文章只能属于一个分类，也就是说如果在”Python”下方添加”-xxx”，Hexo不会产生两个分类，而是把分类嵌套，即该文章属于”Python“下的”-xxx“分类。 1234---title: Python中*args和**kwargs的用法总结categories: Python--- 回到hexo文件夹下，依次执行hexo g，hexo server和hexo deploy命令(重新部署)。 在Hexo菜单上添加分类选项 cd进/hexo/themes/hexo-theme-next-5.1.4文件夹内，编辑该目录下的_config.yml文件(把链接加上)，将源代码: 12345678910111213menu: home: / || home #about: /about/ || user #tags: /tags/ || tags #categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat# Enable/Disable menu icons.menu_icons: enable: true 改为: 12345678910111213menu: home: / || home #about: /about/ || user #tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat# Enable/Disable menu icons.menu_icons: enable: true 即将menu中的categories:/categories || th的注释去掉，然后保存并退出。 回到hexo文件夹下，依次执行hexo g，hexo server和hexo deploy命令，即可看到菜单栏中新增了一个Categories选项。 至此，成功给文章添加分类，点击Index上的Categories可以看到所有的分类情况，再点击该分类就可以看到该分类下的所有文章。当然，前提是添加了categories: xxx字段。 Hexo创建”标签”选项生成”标签”页并添加type属性 打开命令行，cd进入博客所在文件夹。执行命令hexo new page tags，来新建一个页面，并命名为tags。成功后会提示：INFO Created: ~/hexo/source/tags/index.md 根据上面的路径找到index.md这个文件，打开后默认内容如下： 1234---title: tagsdate: 2018-10-25 21:11:00--- 编辑新创建的页面，添加type: &quot;tags&quot;到内容中，主题将自动为这个页面显示所有分类，添加后是这样的： 12345---title: tagsdate: 2018-10-25 21:11:00type: &quot;tags&quot;--- 保存并关闭文件。 给文章添加”tags”属性 打开需要添加标签的文章，为其添加tags属性。下方的tags: Django表示添加这篇文章到“Django”这个标签中。 1234---title: Python中*args和**kwargs的用法总结tags: Django--- 回到hexo文件夹下，依次执行hexo g， hexo server和hexo deploy命令(重新部署)。 在Hexo菜单上添加标签选项 cd进/hexo/themes/hexo-theme-next-5.1.4文件夹内，编辑该目录下的_config.yml文件(把链接加上)，将源代码: 12345678910111213menu: home: / || home #about: /about/ || user #tags: /tags/ || tags #categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat# Enable/Disable menu icons.menu_icons: enable: true 改为: 12345678910111213menu: home: / || home #about: /about/ || user tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat# Enable/Disable menu icons.menu_icons: enable: true 即将menu中的tags: /tags/ || tags的注释去掉，然后保存并退出。 回到hexo文件夹下，依次执行hexo g，hexo server和hexo deploy命令，即可看到菜单栏中新增了一个tags选项。 引用文章： 1.Hexo使用攻略-添加分类及标签 | linlif-blog 2.hexo怎么在菜单上添加页面和分类呢？ - SegmentFault 思否 3.hexo next 为文章添加分类 | 学而后知不足]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中*args和**kwargs的用法总结]]></title>
    <url>%2F2018%2F10%2F25%2FPython%E4%B8%AD*args%E5%92%8C**kwargs%E7%9A%84%E7%94%A8%E6%B3%95%E6%80%BB%E7%BB%93%E7%9A%84%E5%89%AF%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Python中*args和**kwargs的用法总结一、基本概念Python支持可变参数，最简单的方法莫过于使用默认参数。 123456789101112131415def test_defargs(one, two=2): # 参数one没有默认值，two的默认值为2 print('Required argument:', one) print('Optional argument:', two) test_defargs(1)'''Required argument: 1Optional argument: 2'''test_defargs(1, 3)'''Required argument: 1Optional argument: 3''' 另一种达到可变参数(Variable Argument)的方法： 使用*args和**kwargs语法。 *args是可变的位置参数(postional arguments)列表； **kwargs是可变的关键词参数(keyword arguments)列表； 并且规定位置参数必须位于关键词参数之前，即*args必须位于**kwargs之前。 二、位置参数以下是用位置参数正确调用函数的实例： 12345678910def print_hello(name, sex): sex_dict = &#123;1: '先生', 2: '女士'&#125; print('Hello %s %s, welcome to Python World!' % (name, sex_dict.get(sex, '先生'))) # if no such a key, print '先生' print_hello('Chen', 2) # 位置参数要求先后顺序，对应name和sexprint_hello('Chen', 3) # 两个参数的顺序必须一一对应，且少一个参数都不可以'''Hello Chen 女士, welcome to Python World!Hello Chen 先生, welcome to Python World!''' 三、关键字参数用于函数调用，通过“键-值”形式加以指定。 使用关键字参数可以让函数更加清晰，容易使用，同时也清除了参数的顺序需求。 以下是用关键字参数正确调用函数的实例： 123print_hello('Chen', sex=1) # 有位置参数时，位置参数必须在关键字参数的前面# print_hello(1, name='Chen') # Python 3.x中这种写法是错误的print_hello(name='Chen', sex=1) # 关键字参数之间不存在先后顺序的,等价于print_hello(sex=1, name='Chen') 以下是错误的调用方式： 12# print_hello(name='Chen', 1) # 有位置参数时，位置参数必须在关键字参数前面# print_hello(sex=1, 'Chen') 四、可变参数顾名思义，可变参数就是传入的参数个数是可变的，可以是任意个。*args和**kwargs两者都是Python中的可变参数。 1.可变位置参数*argsPython中规定参数前带*的，称为可变位置参数，只是我们通常称这个可变位置参数为*args而已，叫其他的也是一样的。 以数学题为例，给定一组数字a，b，c……，请计算a^2 + b^2 + c^2 + ……。 要定义这个函数，必须确定输入的参数。由于参数个数不确定，我们可以首先想到把a，b，c……作为一个list或者tuple传进来，这样函数就可以定义为： 12345def calc(numbers): sum = 0 for n in numbers: sum = sum + n * n return sum 但是调用的时候，需要先组装出一个list或tuple： 1234&gt;&gt;&gt; calc([1, 2, 3])14&gt;&gt;&gt; calc([1, 3, 5, 7])84 所以，为了方便起见我们把函数的参数改为可变位置函数： 12345def calc(*numbers) # 可变位置参数 sum = 0 for n in numbers: sum = sum + n * n return sum 定义可变位置参数和定义一个list或tuple参数相比，仅仅在参数前面加了一个*号。在函数内部，参数numbers接收到的是一个tuple，因此函数代码完全不变。但是，调用该函数时，可以传入任意个参数，包括0个参数： 1234&gt;&gt;&gt;calc(1,2)5&gt;&gt;&gt;calc()0 如果已经有一个list或tuple，要调用一个可变位置参数怎么办？可以这么做： 123&gt;&gt;&gt;nums = [1, 2, 3]&gt;&gt;&gt;calc(nums[0], nums[1], nums[2])14 这种做法当然是可行的，问题是太繁琐了，所以Python允许在list或tuple前面加一个*，把list或tuple的元素变成可变位置参数传进去： 123&gt;&gt;&gt;nums = [1, 2, 3]&gt;&gt;&gt;calc(*nums)14 总而言之，*args用来表示函数接收可变长度的非关键字参数列表作为函数的输入。我们可以通过以下这个例子进一步理解*args: 123456def test_args(normal_arg, *args): print('first normal arg:' + normal_arg) for arg in args: print('another arg through *args:' + arg) test_args("normal", "python", "java", "C#") 上面代码的执行结果如下： 1234first normal arg: normalanother arg through *args : pythonanother arg through *args : javaanother arg through *args :C# 2.可变关键字参数**kwargs同理，Python中规定参数前带 的，称为可变关键字参数，通常用kwargs表示。 **kwargs表示函数接收可变长度的关键字参数字典作为函数的输入。当我们需要函数接收带关键字的参数作为输入的时候，应当使用**kwargs。我们可以通过以下的例子进一步理解**kwargs: 123456789def test_kwargs(**kwargs): if kwargs is not None: for key, value in kwargs.iteritems(): print("&#123;&#125; = &#123;&#125;".format(key,value)) # Or you can visit kwargs like a dict() object # for key in kwargs: # print("&#123;&#125; = &#123;&#125;".format(key, kwargs[key])) test_kwargs(name="python", value="5") 以上代码的执行效果如下： 12name = pythonvalue = 5 以上例子只是*args和**kwargs基本使用的例子。下面再给出一个用*args和**kwargs来定义能够接受列表输入和字典输入的函数的例子。 3.使用*args和**kwargs来调用函数比如我们有如下接受普通输入参数的函数： 123456def normal_func(arg1, arg2, arg3): print("arg1: " + arg1) print("arg2: " + arg2) print("arg3: " + arg3)normal_func("python", 1, 3) 使用*args和**kwargs来调用这个函数的代码如下： 1234567# 使用*argsargs_list = ("python", 1, 3)normal_func(*args_list)# 使用**kwargskwargs_dict = &#123;"arg3": 3, "arg1": "python", "arg2": 1&#125;normal_func(**kwargs_dict) 以上三段代码的输出均为： 123arg1: pythonarg2: 1arg3: 3 引用文章： 1.Python中的 *args 和 **kwargs - 简书 2.函数的参数 - 廖雪峰的官方网站 3.python参数传递的*args和**kwargs - 简书]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[通过Hexo将文章上传到git.io的方法]]></title>
    <url>%2F2018%2F10%2F21%2F%E9%80%9A%E8%BF%87Hexo%E5%B0%86%E6%96%87%E7%AB%A0%E4%B8%8A%E4%BC%A0%E5%88%B0git.io%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[通过Hexo将文章上传到git.io的方法 编辑文章，生成markdown文件，并将文章放到/hexo/source/_posts目录下，一个md文件对应一篇博客文章。 修改文章头部： 123456---title: #博客标题date: #博客发布时间tags: #博客分类标签categories: #博客目录--- 在命令行中cd到_posts目录下并执行hexo generate命令(生成静态页面)。 再执行hexo server命令(本地上传文章)，上传后可以到http://localhost:4000/ 预览博客效果。 最后执行hexo deploy命令，上传文章到github.io上就完成了。 其他Hexo命令： hexo clean（清空资源文件，可选操作） hexo g （重新生成资源文件） 引用文章: 1.Hexo 发布文章到git.io步骤 - 程序男的专栏 - CSDN博客 2.hexo发布文章到个人博客上 - wl67920126的博客 - CSDN博客]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django中path和url的区别]]></title>
    <url>%2F2018%2F10%2F21%2FDjango%E4%B8%ADpath%E5%92%8Curl%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[Django中path和url的区别django中url和path都是配置路径，有什么不同？ from django.urls import path from django.conf.urls import url path和url是两个不同的模块，效果都是响应返回界面，path调用的是python第三方模块或框架，而url则是自定义的模块。 例如： 1234url(r'^login', views.login)def login(request): return render(request, 'login.html') 引用自：Django中path和url的用法总结 当然，主要问题在于版本，1.x版本用url，2.x版本用path。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[介绍]]></title>
    <url>%2F2018%2F04%2F25%2F%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[Rilzob的个人blog随便写，随便看 邮箱： watermirrosir@163.com]]></content>
  </entry>
</search>
