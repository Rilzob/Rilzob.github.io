<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（八）]]></title>
    <url>%2F2018%2F12%2F01%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AB%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第8章 评分预测问题之前讨论的都是TopN推荐，但同样评分预测问题也是推荐系统研究的核心。评分预测问题就是如何通过已知的用户历史评分记录预测未知的用户评分记录。 本章主要讨论评分预测这一推荐领域的经典问题。因为这一问题的研究集中在学术界，所以本章的介绍也比较偏学术，相对前面各章会增加一些公式和理论的讨论。 8.1 离线实验方法评分预测问题基本都通过离线实验进行研究。在给定用户评分数据集后，研究人员会将数据集按照一定的方式分成训练集和测试集，然后根据测试集建立用户兴趣模型来预测测试集中的用户评分。对于测试集中的一对用户和物品$(u, i)$，用户$u$对物品$i$的真实评分$r_{ui}$，而推荐算法预测的用户$u$对物品$i$的评分为$\hat r_{ui}$，那么一般可以用均方根误差RMSE度量预测的精度：$$RMSE = \frac{\sqrt{\sum_{(u,i)\in T}(r_{ui} - \hat r_{ui})^2}}{\vert Test \vert}$$评分预测的目的就是找到最好的模型最小化测试集的RMSE。 关于如何划分训练集和测试集，如果是和时间无关的预测任务，可以以均匀分布随机划分数据集，即对每个用户，随机选择一些评分记录作为测试集，剩下的记录作为测试集。如果是和时间相关的任务，那么需要将用户的旧行为作为训练集，将用户的新行为作为测试集。Netflix通过如下方式划分数据集，首先将每个用户的评分记录按照从早到晚进行排序，然后将用户最后10%的评分记录作为测试集，前90%的评分记录作为训练集。 8.2 评分预测算法本节从简单到复杂地介绍具有代表性的算法，并给出它们在Netflix数据集上的效果。 8.2.1 平均值最简单的评分预测算法是利用平均值预测用户对物品的评分的。下面各节分别介绍各种不同的平均值。 1.全局平均值在平均值里最简单的是全局平均值。它的定义为训练集中所有评分记录的评分平均值：$$\mu = \frac{\sum_{(u,i) \in Train}r_{ui}}{\sum_{(u,i) \in Train }1}$$而最终的预测函数可以直接定义为：$$\hat r_{ui} = \mu$$ 2.用户评分平均值用户$u$的评分平均值$\bar r_u$定义为用户$u$在训练集中所有评分的平均值：$$\bar r_u = \frac{\sum_{i \in N(u)}r_{ui}}{\sum_{i \in N(u)}1}$$ 而最终的预测函数可以定义为：$$\hat r_{ui} = \bar r_{u}$$ 3.物品评分平均值物品$i$的评分平均值$\bar r_i$定义为物品$i$在训练集中接收的所有评分的平均值：$$\bar r_i = \frac{\sum_{u \in N(i)}r_{ui}}{\sum_{u \in N(i)}1}$$而最终的预测函数可以定义为：$$\hat r_{ui} = \bar r_i$$ 4.用户分类对物品分类的平均值(类类平均值)假设有两个分类函数，一个是用户分类函数$\phi$，一个是物品分类函数$\varphi$。$\phi(u)$定义了用户$u$所属的类，$\varphi(u)$定义了物品$i$所属的类。那么，我们可以利用训练集中同类用户对同类物品评分的平均值预测用户对物品的评分，即：$$\hat r_{ui} = \frac{\sum_{(v,j)\in Train, \phi(u)=\phi(v),\varphi(i)=\varphi(j)} r_{vj}}{\sum_{(v,j)\in Train, \phi(u)=\phi(v),\varphi(i)=\varphi(j)}1}$$前面提出的全局平均值，用户评分平均值和物品评分平均值都是类类平均值的一种特例。 如果定义$\phi(u)=0,\varphi(i)=0$，那么$\hat r_{ui}$就是全局平均值。 如果定义$\phi(u) = u,\varphi(i) = 0$，那么$\hat r_{ui}$就是用户评分平均值。 如果定义$\phi(u) = 0,\varphi(i) = i$，那么$\hat r_{ui}$就是物品评分平均值。 除了这3种特殊的平均值，在用户评分数据上还可以定义很多不同的分类函数。 用户和物品的平均分 对于一个用户，可以计算他的评分平均分。然后将所有用户按照评分平均分从小到大排序，并将用户按照平均分平均分成N类。物品也可以用同样的方式分类。 用户活跃度和物品流行度 对于一个用户，将他评分的物品数量定义为他的活跃度。得到用户活跃度之后，可以将用户通过活跃度从小到大排序，然后平均分为N类。物品的流行度定义为给物品评分的用户数目，物品也可以按照流行度均匀分成N类。 下面的Python代码给出了类类平均值的计算方法。 123456789101112131415def PredictAll(records, user_cluster, item_cluster): total = dict() count = dict() for r in records: if r.test != 0: continue gu = user_cluster.GetGroup(r.user) gi = item_cluster.GetGroup(r.item) basic.AddToMat(total, gu, gi, r.vote) basic.AddToMat(count, gu, gi, 1) for r in records: gu = user_cluster.GetGroup(r.user) gi = item_cluster.GetGroup(r.item) average = total[gu][gi] / (1.0 * count[gu][gi] + 1.0) r.predict = average 在这段代码中，user_cluster.GetGroup函数接收一个用户ID，然后根据一定的算法返回用户的类别。item_cluster.GetGroup函数接收一个物品的ID，然后根据一定的算法返回物品的类别。total[gu][gi]/count[gu][gi]记录了第gu类用户给第gi类物品评分的平均分。 上文提到，user_cluster和item_cluster有很多不同的定义方式，下面的Python代码给出了不同的user_cluster和item_cluster定义方式。其中，Cluster是基类，对于任何用户和物品，它的GetGroup函数都返回0，因此如果user_cluster和item_cluter都是Cluster类型，那么最终的预测函数就是全局平均值。IdCluster的GetGroup函数接收一个ID，会返回这个ID，那么如果user_cluster是Cluster类型，而item_cluster是IdCluster类型，那么最终的预测函数给出的就是物品平均值。在MovieLens数据集上利用不同平均值方法计算RMSE，实验结果表明对用户使用UserVoteCluster，对物品采用ItemVoteCluster，可以获得最小的RMSE。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697class Cluster: def __init__(self,records): self.group = dict() def GetGroup(self, i): return 0class IdCluster(Cluster): def __init__(self, records): Cluster.__init__(self, records) def GetGroup(self, i): return iclass UserActivityCluster(Cluster): def __init__(self, records): Cluster.__init__(self, records) activity = dict() for r in records: if r.test != 0: continue basic.AddToDict(activity, r.user, 1) k = 0 for user, n in sorted(activity.items(), \ key=itemgetter(1), reverse=False): c = int((k * 5) / (1.0 * len(activity))) self.group[user] = c k += 1 def GetGroup(self, uid): if uid not in self.group: return -1 else: return self.group[uid] class ItemPopularityCluster(Cluster): def __init__(self, records): Cluster.__init__(self, records) popularity = dict() for r in records: if r.test != 0: continue basic.AddToDict(popularity, r.item, 1) k = 0 for item, n in sorted(popularity.items(), \ key=itemgetter(1), reverse=False): c = int((k * 5) / (1.0 * len(popularity))) self.group[item] = c k += 1def GetGroup(self, item): if item not in self.group: return -1 else: return self.group[item]class UserVoteCluster(Cluster): def __init__(self, records): Cluster.__init__(self, records) vote = dict() count = dict() for r in records: if r.test != 0: continue basic.AddToDict(vote, r.user, r.vote) basic.AddToDict(count, r.user, 1) k = 0 for user, v in vote.items(): ave = v / (count[user] * 1.0) c = int(ave * 2) self.group[user] = c def GetGroup(self, uid): if uid not in self.group: return -1 else: return self.group[uid]class ItemVoteCluster(Cluster): def __init__(self, records): Cluster.__init__(self, records) vote = dict() count = dict() for r in records: if r.test != 0: continue basic.AddToDict(vote, r.item, r.vote) basic.AddToDict(count, r.item, 1) k = 0 for item, v in vote.items(): ave = v / (count[item] * 1.0) c = int(ave * 2) self.group[item] = c def GetGroup(self, item): if item not in self.group: return -1 else: return self.group[item] 8.2.2 基于邻域的方法 基于用户的邻域算法和基于物品的邻域算法都可以应用到评分预测中。基于用户的邻域算法认为预测一个用户对一个物品的评分，需要参考和这个用户兴趣相似的用户对该物品的评分，即：$$\hat r_{ui} = \bar r_{u} + \frac{\sum_{v \in S(u,K) \cap N(i)}w_{uv}(r_{vi} - \bar r_v)}{\sum_{v \in S(u,K) \cap N(i)}\vert w_{uv} \vert}$$$S(u,K)$是和用户$u$兴趣最相似的$K$个用户的集合，$N(i)$是对物品$i$评过分的用户集合，$r_{vi}$是用户$v$对物品$i$的评分，$\bar r_v$是用户$v$对他评过分的所有物品评分的平均值。用户之间的相似度$w_{uv}$可以通过皮尔逊系数计算：$$w_{uv} = \frac{\sum_{i \in I}(r_{ui}-\bar r_u)\cdot (r_{vi} - \bar r_v)}{\sqrt{\sum_{i \in I} (r_{ui} - \bar r_u)^2 \sum_{i \in I} (r_{vi} - \bar r_v)^2}}$$下面的Python代码实现了用户相似度的计算和最终的预测函数： 12345678910111213141516171819202122232425262728293031323334353637def UserSimilarity(records): item_users = dict() ave_vote = dict() activity = dict() for r in records: addToMat(item_users, r.item, r.user, r.value) addToVec(ave_vote, r.user, r.value) addToVec(activity, r.user, 1) ave_vote = &#123;x:y/activity[x] for x,y in ave_vote.items()&#125; nu = dict() W = dict() for i,ri in item_users.items(): for u,rui in ri.items(): addToVec(nu, u, (rui - ave_vote[u])*(rui - ave_vote[u])) for v,rvi in ri.items(): if u == v: continue addToMat(W, u, v, \ (rui - ave_vote[u])*(rvi - ave_vote[v])) for u in W: W[u] = &#123;x:y/math.sqrt(nu[x]*nu[u]) for x,y in W[u].items() return W def PredictAll(records, test, ave_vote, W, K): user_items = dict() for r in records: addToMat(user_items, r.user, r.item, r.value) for r in test: r.predict = 0 norm = 0 for v,wuv in sorted(W[r.user].items(), \ key=itemgetter(1), reverse=True)[0:K]: if r.item in user_items[v]: rvi = user_items[v][r.item] r.predict += wuv * (rvi - ave_vote[v]) norm += abs(wuv) if norm &gt; 0: r.predict /= norm r.predict += ave_vote[r.user] 基于物品的邻域算法在预测用户$u$对物品$i$的评分时，会参考用户u对和物品i相似的其他物品的评分，即：$$\hat r_{ui} = \bar r_i + \frac{\sum_{j \in S(u,K) \cap N(u)}w_{ij} (r_{uj} - \bar r_i)}{\sum_{j \in S(u,K) \cap N(u)} \vert w_{ij} \vert}$$$S(i,K)$是和$i$最相似的物品集合，$N(u)$是用户$u$评过分的物品集合，$w_{ij}$是物品之间的相似度，$\bar r_i$是物品$i$的平均分。对于如何计算物品的相似度，Badrul Sarwar等在论文(参见Badrul Sarwar、George Karypis、Joseph Konstan和John Riedl的“Item-based Collaborative Filtering Recommendation Algorithms”（ACM 2001 Article，2001）)里做了详细的研究，文章比较了3种主要的相似度。 第一种是普通的余弦相似度(cosine similarity):$$w_{ij} = \frac{\sum_{u \in U} r_{ui} \cdot r_{uj}}{\sqrt{\sum_{u \in U} r_{ui}^2 \sum_{u \in U} r_{uj}^2}}$$第二种是皮尔逊系数(pearson correlation):$$w_{ij} = \frac{\sum_{u \in U}(r_{ui}-\bar r_i)\cdot (r_{uj} - \bar r_j)}{\sqrt{\sum_{u \in U} (r_{ui} - \bar r_i)^2 \sum_{u \in U} (r_{uj} - \bar r_j)^2}}$$第三种是被Sarwar称为修正的余弦相似度(adjust cosine similarity):$$w_{ij} = \frac{\sum_{u \in U}(r_{ui}-\bar r_u)\cdot (r_{uj} - \bar r_u)}{\sqrt{\sum_{u \in U} (r_{ui} - \bar r_u)^2 \sum_{u \in U} (r_{uj} - \bar r_u)^2}}$$Sarwar利用MovieLens最小的数据集对3种相似度进行了对比 ，并将MAE作为评测指标。实验结果表明利用修正后的余弦相似度进行评分预测可以获得最优的MAE。不过需要说明的是，在一个数据集上的实验并不意味着在其他数据集上也能获得相同的结果。 8.2.3 隐语义模型与矩阵分解模型做机器学习和数据挖掘研究的人经常会看到下面的各种名词，即隐含类别模型(Latent Class Model)、隐语义模型(Latent Factor Model)、pLSA、LDA、Topic Model、Matrix Factorization、Factorized Model。 这些名词在本质上应该是同一种思想体系的不同扩展。在推荐系统领域，提的最多的就是潜语义模型和矩阵分解模型。这两个名词说的是一回事，就是如何通过降维的方法将评分矩阵补全。 用户的评分行为可以表示成一个评分矩阵$R$，其中$R[u][i]$就是用户$u$对物品$i$的评分。但是，用户不会对所有的物品评分， 所以这个矩阵里有很多元素都是空的， 这些空的元素称为缺失值(missing value)。因此，评分预测从某种意义上说就是填空，如果一个用户对一个物品没有评过分，那么推荐系统就要预测这个用户是否是否会对这个物品评分以及会评几分。 1.传统的SVD分解一个空的矩阵有很多种补全方法，选择其中一种对矩阵扰动最小的补全方法。什么是对矩阵扰动最小？就是补全后矩阵的特征值和补全之前矩阵的特征值相差不大，就算是扰动比较小。所以，最早的矩阵分解模型就是从数学上的SVD(奇异值分解)开始的(参见Daniel Billsus和Michael J. Pazzani的“Learning Collaborative Information Filters”（1998）)。给定$m$个用户和$n$个物品，和用户对物品的评分矩阵$\mathbb R^{m \times n}$。首先需要对评分矩阵中的缺失值进行简单地补全，比如用全局平均值，或者用户/物品平均值补全，得到补全后的矩阵$R’$。接着，可以用SVD分解将$R’$分解成如下形式：$$R’ = U^TSV$$其中$U \in \mathbb R^{k \times m}$，$V \in \mathbb R^{k \times m}$是两个正交矩阵，$S \in \mathbb R^{k \times k}$是对角阵，对角线上的每一个元素都是矩阵的奇异值。为了对$R’$进行降维，可以取最大的$f$个奇异值组成对角矩阵$S_f$，并且找到这$f$个奇异值中每个值在$U$、$V$矩阵中对应的行和列，得到$U_f$、$V_f$，从而可以得到一个降维后的评分矩阵：$$R_f’ = U^T_f S_f V_f$$其中，$R_(u, i )$就是用户$u$对物品$i$评分的预测值。 SVD分解是早期推荐系统研究常用的矩阵分解方法，不过该方法具有以下缺点，因此很难在实际系统中应用。 该方法首先需要用一个简单的方法补全稀疏评分矩阵。一般来说，推荐系统中的评分矩阵是非常稀疏的，一般都有95%以上的元素是缺失的。而一旦补全，评分矩阵就会变成一个稠密矩阵，从而使评分矩阵的存储需要非常大的空间，这种空间的需求在实际系统中是不可能接受的。 该方法依赖的SVD分解方法的计算复杂度很高，特别是在稠密的大规模矩阵上更是非常慢。 2.Simon Funk的SVD分解正是由于上面的两个缺点，SVD分解算法提出几年后在推荐系统领域都没有得到广泛的关注。直到2006年Netflix Prize开始后，Simon Funk在博客上公布了一个算法(称为Funk-SVD)(参见Simon Funk的博客，文章地址为http://sifter.org/~simon/journal/20061211.html )，一下子引爆了学术界对矩阵分解类方法的关注。而且，Simon Funk的博客也成为了很多学术论文经常引用的对象。 Simon Funk 提出的矩阵分解方法后来被 Netflix Prize 的冠军Koren称为Latent Factor Model(简称为LFM)。 第3章曾经简单介绍过LFM在TopN推荐中的应用，因此这里不再详细介绍这一方面背后的思想。从矩阵分解的角度说，如果将评分矩阵$R$分解为两个低维矩阵相乘：$$\hat R = P^TQ$$其中$P \in \mathbb R^{f \times m}$和$Q \in \mathbb R^{f \times n}$是两个降维后的矩阵。 那么，对于用户$u$对物品$i$的评分的预测值$\hat R(u,i) = \hat r_{ui}$，可以通过如下公式计算：$$\hat r_{ui} = \sum_f{p_{uf} q_{if}}$$其中$p_{uf} = P(u,f)$，$q_{if} = Q(i,f) $。那么，Simon Funk的思想很简单：可以直接通过训练集中的观察值利用最小化RMSE学习$P$、$Q$矩阵。 Simon Funk认为，既然用RMSE作为评测指标，那么如果能找到合适的$P$、$Q$来最小化训练集的预测误差，那么应该也能最小化测试集的预测误差。因此，Simon Funk定义损失函数为：$$C(p,q) = \sum_{(u,i) \in Train}(r_{ui} - \hat r_{ui})^2 = \sum_{(u,i) \in Train}(r_{ui} - \sum_{f = 1}^F p_{uf}q_{if})^2$$直接优化上面的损失函数可能会导致学习的过拟合， 因此还需要加入防止过拟合项$\lambda(\Vert p_u \Vert^2 + \Vert q_i \Vert^2)$，其中$\lambda$是正则化参数，从而得到：$$C(p,q) = \sum_{(u,i) \in Train}(r_{ui} - \sum_{f = 1}^F p_{uf}q_{if})^2 + \lambda(\Vert p_u \Vert^2 + \Vert q_i \Vert^2)$$要最小化上面的损失函数，可以利用随机梯度下降法(参见http://en.wikipedia.org/wiki/Stochastic_gradient_descent )。该算法是最优化理论里最基础的优化算法，它首先通过求参数的偏导数找到最速下降方向，然后通过迭代法不断地优化参数。下面介绍优化方法的数学推导。 上面定义的损失函数里有两组参数$p_{uf}$和$q_{if}$，最速下降法需要首先对它们分别求偏导数，可以得到：$$\frac{\partial C}{\partial p_{uf}} = -2q_{ik} + 2\lambda p_{uk}$$ $$\frac{\partial C}{\partial p_{if}} = -2p_{uk} + 2\lambda q_{ik}$$ 然后，根据随机梯度下降法，需要将参数沿着最速下降方向向前推进，因此可以得到如下递推公式：$$p_{uf} = p_{uf} + \alpha(q_{ik} - \lambda p_{uk}) \\q_{if} = q_{if} + \alpha(p_{uk} - \lambda q_{ik})$$其中，$\alpha$是学习速率(learning rate)，它的取值需要通过反复实验获得。 下面的代码实现了学习LFM模型时的迭代过程。在LearningLFM函数中，输入train是训练集中的用户评分记录，F是隐类的格式，n是迭代次数。 1234567891011def LearningLFM(train, F, n, alpha, lambda): [p,q] = InitLFM(train, F) for step in range(0, n): for u,i,rui in train.items(): pui = Predict(u, i, p, q) eui = rui - pui for f in range(0,F): p[u][k] += alpha * (q[i][k] * eui - lambda * p[u][k]) q[i][k] += alpha * (p[u][k] * eui - lambda * q[i][k]) alpha *= 0.9 return list(p, q) 如上面的代码所示，LearningLFM主要包括两步。(1)需要对P、Q矩阵进行初始化，(2)需要通过随机梯度下降法的迭代得到最终的$P$、$Q$矩阵。在迭代时，需要在每一步对学习参数$\alpha$进行衰减(alpha *= 0.9)，这是随机梯度下降法算法要求的，其目的是使算法尽快收敛。如果形象一点说就是，如果需要在一个区域找到极值，一开始可能需要大范围搜索，但随着搜索的进行，搜索范围会逐渐缩小。 初始化$P、Q$矩阵的方法很多，一般都是将这两个矩阵用随机数填充，但随机数的大小还是有讲究的，根据经验，随机数需要和$1/sqrt(F)$成正比。下面的代码实现了初始化功能。 123456789def InitLFM(train, F): p = dict() q = dict() for u, i, rui in train.items(): if u not in p: p[u] = [random.random()/math.sqrt(F) \ for x in range(0,F)] if i not in q: q[i] = [random.random()/math.sqrt(F) \ for x in range(0,F)] return list(p, q) 而预测用户$u$对物品$i$的评分可以通过如下代码实现： 12def Predict(u, i, p, q): return sum(p[u][f] * q[i][f] for f in range(0,len(p[u])) LFM提出之后获得了很大的成功，后来很多著名的模型都是通过对LFM修修补补获得的，下面的各节分别介绍一下改进LFM的各种方法。这些改进有些是对模型的改进，有些是将新的数据引入到模型当中。 3.加入偏置项后的LFM上节提出的LFM预测公式通过隐类将用户和物品联系在一起。但是，实际情况下，一个评分系统有些固有属性和用户物品无关，而用户也有些属性和物品无关，物品也有些属性和用户无关。因此， Netflix Prize中提出了另一种LFM，其预测公式如下：$$\hat r_{ui} = \mu + b_u + b_i + p_u^T \cdot q_i$$相比上节的LFM预测公式增加了3项$\mu$、$b_u$、$b_i$。本章将这个模型称为BiasSVD。新增三项的作用如下： $\mu$ 训练集中所有记录的评分的全局平均数。在不同网站中，因为网站定位和销售的物品不同，网站的整体评分分布也会显示出一些差异。比如有些网站中的用户就是喜欢打高分，而另一些网站的用户就是喜欢打低分。而全局平均数可以表示网站本身对用户评分的影响。 $b_u$ 用户偏置(user bias)项。这一项表示了用户的评分习惯中和物品没有关系的那种因素。有的用户对什么都喜欢打高分或者低分。 $b_i$ 物品偏置(item bias)项。这一项表示了物品接受的评分中和用户没有什么关系的因素。与用户偏置项同理。 增加的3个参数中，只有$b_u$、$b_i$是要通过机器学习训练出来的。同样可以求导，然后用梯度下降法求解这两个参数，只需对LearningLFM稍做修改，就可以支持BiasLFM模型： 12345678910111213def LearningBiasLFM(train, F, n, alpha, lambda, mu): [bu, bi, p,q] = InitLFM(train, F) for step in range(0, n): for u,i,rui in train.items(): pui = Predict(u, i, p, q, bu, bi, mu) eui = rui - pui bu[u] += alpha * (eui - lambda * bu[u]) bi[i] += alpha * (eui - lambda * bi[i]) for f in range(0,F): p[u][k] += alpha * (q[i][k] * eui - lambda * p[u][k]) q[i][k] += alpha * (p[u][k] * eui - lambda * q[i][k]) alpha *= 0.9 return list(bu, bi, p, q) 而$b_u$、$b_i$在一开始只要初始化成全0的向量。 123456789101112131415161718def InitBiasLFM(train, F): p = dict() q = dict() bu = dict() bi = dict() for u, i, rui in train.items(): bu[u] = 0 bi[i] = 0 if u not in p: p[u] = [random.random()/math.sqrt(F) for x in range(0,F)] if i not in q: q[i] = [random.random()/math.sqrt(F) for x in range(0,F)] return list(p, q)def Predict(u, i, p, q, bu, bi, mu): ret = mu + bu[u] + bi[i] ret += sum(p[u][f] * q[i][f] for f in range(0,len(p[u])) return ret 4.考虑邻域影响的LFM前面的LFM模型中并没有显式地考虑用户的历史行为对用户评分预测的影响。为此，Koren在Netflix Prize比赛中提出了一个模型(参见Yehuda Koren的“Factor in the Neighbors: Scalable and Accurate Collaborative Filtering”（ACM 2010 Article，2010）)，将用户历史评分的物品加入到了LFM模型中，Koren将该模型称为SVD++。 为了将基于邻域的方法设计成一个像LFM那样可以学习的模型，可以将ItemCF的预测算法改成如下形式：$$\hat r_{ui} = \frac{1}{\sqrt{\vert N(u) \vert}} \sum_{j \in N(u)}w_{ij}$$公式中的$w_{ij}$不再是根据ItemCF算法计算出的物品相似度矩阵，而是一个和P、Q一样的参数，它通过优化如下的损失函数进行优化：$$C(w) = \sum_{(u,i) \in Train}(r_{ui} - \sum_{j \in N(u)} w_{ij}r_{uj})^2 + \lambda w_{ij}^2$$这个模型有一个缺点，就是$w$将是一个比较稠密的矩阵，存储它需要比较大的空间。此外，如果有$n$个物品，那么该模型的参数个数就是$n^2$个，这个参数个数比较大容易造成结果的过拟合。因此，Koren提出用该对$w$矩阵也进行分解，将参数个数降低到$2 \times n \times F$个，模型如下：$$\hat r_{ui} = \frac{1}{\sqrt{\vert N(u) \vert}} \sum_{j \in N(u)}x_i^Ty_j = \frac{1}{\sqrt{\vert N(u) \vert}}x_i^T \sum_{j \in N(u)}y_j$$$x_i$、$y_j$是两个$F$维的向量。由此可见，该模型用$x_i^Ty_j$代替了$w_{ij}$，从而大大降低了参数的数量和存储空间。 再进一步，可以将前面的LFM和上面的模型相加，从而得到如下模型：$$\hat r_{ui} = \mu + b_u + b_i + p_u^T \cdot q_i + \frac{1}{\sqrt{\vert N(u) \vert}}x_i^T \sum_{j \in N(u)}y_j$$Koren又提出为了不增加太多参数造成过拟合，可以令$x=q$，从而得到最终的SVD++模型：$$\hat r_{ui} = \mu + b_u + b_i + q_i^T \cdot (p_u + \frac{1}{\sqrt{\vert N(u) \vert}} \sum_{j \in N(u)}y_j)$$通过将损失函数对各个参数求偏导数，也可以轻松推导出迭代公式。下面给出SVD++模型训练的实现代码，如下所示： 12345678910111213141516171819202122232425def LearningBiasLFM(train_ui, F, n, alpha, lambda, mu): [bu, bi, p, q, y] = InitLFM(train, F) z = dict() for step in range(0, n): for u,items in train_ui.items(): z[u] = p[u] ru = 1 / math.sqrt(1.0 * len(items)) for i,rui in items items(): for f in range(0,F): z[u][f] += y[i][f] * ru sum = [0 for i in range(0,F)] for i,rui in items items(): pui = Predict() eui = rui - pui bu[u] += alpha * (eui - lambda * bu[u]) bi[i] += alpha * (eui - lambda * bi[i]) for f in range(0,F): sum[k] += q[i][k] * eui * ru p[u][k] += alpha * (q[i][k] * eui - lambda * p[u][k]) q[i][k] += alpha * ((z[u][k] + p[u][k]) * eui - lambda * q[i][k]) for i,rui in items items(): for f in range(0,F): y[i][f] += alpha * (sum[f] - lambda * y[i][f]) alpha *= 0.9 return list(bu, bi, p, q) 8.2.4 加入时间信息利用时间信息的方法也主要分为两种，一种是将时间信息应用到基于邻域的模型中，另一种是将时间信息应用到矩阵分解模型中。 1.基于邻域的模型融合时间信息由于实际生活中用户数目太大，所以基于用户的邻域模型很少被使用，主要是因为存储用户相似度矩阵非常困难。因此，本节主要讨论如何将时间信息融合到基于物品的邻域模型中。 Netflix Prize 的参赛队伍 BigChaos在技术报告中提到了一种融入时间信息的基于邻域的模型，本节将这个模型称为TItemCF。该算法通过如下公式预测用户在某一个时刻会给物品什么评分：$$\hat r_{uit} = \frac{\sum_{j \in N(u) \cap S(i,K)}f(w_{ij}, \Delta t)r_{uj}}{\sum_{j \in N(u) \cap S(i,K)}f(w_{ij},\Delta t)}$$$\Delta t = t_{ui} - t_{uj}$是用户$u$对物品$i$和物品$j$评分的时间差，$w_{ij}$是物品$i$和$j$的相似度，$f(w_{ij}, \Delta t)$是一个考虑了时间衰减后的相似度函数，它的主要目的是提高用户最近的评分行为对推荐结果的影响，BigChaos在模型中采用了如下的$f$：$$f(w_{ij},\Delta t) = \sigma(\delta \cdot w_{ij} \cdot \text{exp}(\frac{-|\Delta t|}{\beta}) + \gamma) \\\sigma(x) = \frac{1}{1+ \text{exp}(-x)}$$$\sigma(x)$是sigmoid函数，它的目的是将相似度压缩到(0，1)区间中。从上面的定义可以发现，随着$\Delta t$增加，$f(w_{ij}, \Delta t)$会越来越小，也就是说用户很久之前的行为对预测用户当前评分的影响越来越小。 2.基于矩阵分解的模型融合时间信息在引入时间信息后，用户评分矩阵不再是一个二维矩阵，而是变成了一个三维矩阵。不过可以仿照二维矩阵的方式对三维矩阵进行分解(参见Liang Xiang和Qing Yang的“Time-Dependent Models in Collaborative Filtering Based Recommender S WI-IAT 09)。回顾之前的BiasSVD模型：$$\hat r_{ui} = \mu + b_u + b_i + p^T_u \cdot q_i$$$\mu$可以看做对二维矩阵的零维分解，$b_u$、$b_i$可以看做对二维矩阵的一维分解，而$p^T_u \cdot q_i$则看做对二维矩阵的二维分解。仿照这种分解，将用户-物品-时间三维矩阵如下分解：$$\hat r_{uit} = \mu + b_u +b_i + b_t+ p^T_u \cdot q_i + x^T_u \cdot y_t + s^T_i z_t + \sum_f g_{u,f} h_{i,f}l_{t,f}$$这里$b_t$建模了系统整体平均分随时间变化的效应，$x^T_u \cdot y_t$建模了用户平均分随时间变化的效应，$s^T_i z_t$建模了物品平均分随时间变化的效应，而$\sum_f g_{u,f} h_{i,f}l_{t,f}$建模了用户兴趣随时间影响的效应。这个模型也可以很容易地利用前面提出的随机梯度下降法进行训练。本章将这个模型记为TSVD。 Koren在SVD++模型的基础上也引入了时间效应(参见Yehuda Koren的“Collaborative Filtering with temporal dynamics”（ACM 2009 Article，2009）)，回顾一下SVD++模型：$$\hat r_{ui} = \mu + b_u + b_i + q_i^T \cdot (p_u + \frac{1}{\sqrt{\vert N(u) \vert}} \sum_{j \in N(u)}y_j)$$对这个模型做如下改进以融合时间信息：$$\hat r_{ui} = \mu + b_u(t) + b_i(t) + q_i^T \cdot (p_u(t) + \frac{1}{\sqrt{\vert N(u) \vert}} \sum_{j \in N(u)}y_j) \\b_u(t) = b_u + \alpha_u \cdot dev_u(t) + b_{ut} + b_{u,period(t)} \\dev_u(t) = sign(t - t_u) \cdot \vert t - t_u \vert^\beta \\b_i(t) = b_i + b_{it} + b_{i, period(t)}\\p_{uf}(t) = p_{uf} + p_{utf}$$这里$t_u$是用户所有评分的平均时间。$period(t)$考虑了季节效应，可以定义为时刻$t$所在的月份。该模型同样可以通过随机梯度下降法进行优化。 8.2.5 模型融合Netflix Prize的最终获胜队伍通过融合上百个模型的结果才取得了最终的成功。由此可见模型融合对提高评分预测的精度至关重要。本节讨论模型融合的两种不同技术。 1.模型级联融合假设已经有一个预测器$\hat r^{(k)}$，对于每个用户-物品对$(u,i)$都给出预测值，那么可以在这个预测器的基础上设计骗一个预测期$\hat r^{(k + 1)}$来最小化损失函数： $$C = \sum_{(u,i) \in Train}(r_{ui} - \hat r_{ui}^{(k)} - \hat r_{ui}^{(k+1)})$$由上面的描述可以发现，级联融合很像Adaboost算法。和Adaboost算法类似，该方法每次产生一个新模型，按照一定的参数加到旧模型上去，从而使训练集误差最小化。不同的是，这里每次生成新模型时并不对样本集采样，针对那些预测错的样本，而是每次都还是利用全样本集进行预测，但每次使用的模型都有区别。 一般来说，级联融合的方法都用于简单的预测器，比如前面提到的平均值预测器。下面的Python代码实现了利用平均值预测器进行级联融合的方法。 12345678910111213def Predict(train, test, alpha): total = dict() count = dict() for record in train: gu = GetUserGroup(record.user) gi = GetItemGroup(record.item) AddToMat(total, gu, gi, record.vote - record.predict) AddToMat(count, gu, gi, 1) for record in test: gu = GetUserGroup(record.user) gi = GetUserGroup(record.item) average = total[gu][gi] / (1.0 * count[gu][gi] + alpha) record.predict += average 通过在MovieLens数据集计算对平均值方法采用级联融合后的RMSE，可见即使是利用简单的算法进行级联融合，也能得到比较低的评分预测误差。 2.模型加权融合假设有$K$个不同的预测器${\hat r^{(1)}，\hat r^{(2)}，···，\hat r^{(K)}}，本节主要讨论如何将它们融合起来获得最低的预测误差。 最简单的融合算法就是线性融合，即最终的预测器$\hat r$是这$K$个预测器的线性加权：$$\hat r = \sum_{k = 1}^K \alpha_k \hat r^{(k)}$$一般来说，评分预测问题的解决需要在训练集上训练$K$个不同的预测器，然后在测试集上作出预测。但是，如果我们继续在训练集上融合$K$个预测器，得到线性加权系数，就会造成过拟合的问题。因此，在模型融合时一般采用如下方法。 假设数据集已经被分为了训练集A和测试集B，那么首先需要将训练集A按照相同的分割方法分为A1和A2，其中A2的生成方法和B的生成方法一致，且大小相似。 在A1上训练$K$个不同的预测器，在A2上作出预测。因为我们知道A2上的真实评分值，所以可以在A2上利用最小二乘法计算出线性融合系数$\alpha_k$。 在A上训练$K$个不同的预测器，在B上作出预测，并且将这$K$个预测器在B上的预测结果按照已经得到的线性融合系数加权融合，以得到最终的预测结果。 除了线性融合，还有很多复杂的融合方法，比如利用人工神经网络的融合算法。其实，模型融合问题就是一个典型的回归问题，因此所有的回归算法都可以用于模型融合。 8.2.6 Netflix Prize的相关实验结果Netflix Prize比赛的３年时间里，很多研究人员在同一个数据集上重复实验了前面几节提到的各种算法。本节引用他们的实验结果对比各个算法的性能。Netflix Prize采用RMSE评测预测准确度，因此本节的评测指标也是RMSE，具体见表8-4。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（七）]]></title>
    <url>%2F2018%2F11%2F30%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第7章 推荐系统实例前面几章介绍了各种各样的数据和基于这些数据的推荐算法。在实际系统中，前面几章提到的数据大都存在，因此如何设计一个真实的推荐系统处理不同的数据，根据不同的数据设计算法，并将这些算法融合到一个系统当中是本章讨论的主要问题。 本章首先介绍推荐系统的外围架构，然后介绍推荐系统的架构，并对架构中每个模块的设计进行深入讨论。 7.1 外围架构这一节主要讨论推荐系统是如何和网站的其他系统接口的。 UI系统负责给用户展示网页并和用户交互。网站会通过日志系统将用户在UI上的各种各样的行为记录到用户行为日志中。日志可能存储在内存缓存里，也可能存储在数据库中，也可能存储在文件系统中。而推荐系统通过分析用户的行为日志，给用户生成推荐列表，最终展示到网站的界面上。因此可以发现，推荐系统要发挥强大的作用，除了推荐系统本身，主要还依赖于两个条件——界面展示和用户行为数据。 目前流行的推荐系统界面存在一些共性： 通过一定方式展示物品，主要包括物品的标题、缩略图和介绍等。 很多推荐界面都提供了推荐理由，理由可以增加用户对推荐结果的信任度。 推荐界面还需要提供一些按钮让用户对推荐结果进行反馈，这样才能让推荐算法不断改 善用户的个性化推荐体验。 在设计推荐界面时，可以综合考虑其他网站的设计并结合自己网站的特点。 数据收集和存储从产生行为的用户角度看，有些行为是只有注册用户才能产生的，而有些行为是所有用户都可以产生的。从规模上看，浏览网页、搜索记录的规模都很大，因为这种行为所有用户都能产生，而且平均每个用户都会产生很多这些行为。购买、收藏行为规模中等，因为只有注册用户才能产生这种行为，但购买行为又是电商网站的主要行为，所以它们相对于评论来说规模更大，但相对于网页浏览行为来说规模要小得多，最后剩下的行为是注册用户里的一小部分人才有的，所以规模不会很大。同样有些行为需要实时存取，而有些并不需要。 按照前面数据的规模和是否需要实时存取，不同的行为数据将被存储在不同的媒介中。一般来说，需要实时存取的数据存储在数据库和缓存中，而大规模的非实时地存取数据存储在分布式文件系统（如HDFS）中。 数据能否实时存取在推荐系统中非常重要，因为推荐系统的实时性主要依赖于能否实时拿到用户的新行为。只有快速拿到大量用户的新行为，推荐系统才能够实时地适应用户当前的需求，给用户进行实时推荐。 7.2 推荐系统架构推荐系统联系用户和物品的方式主要有3种，在第4章开头部分介绍过，分别是： 基于用户的推荐算法 基于物品的推荐算法 基于特征的推荐算法 其中上述三种都可以将其抽象为基于特征的推荐算法，因为用户喜欢的物品可以算是用户特征，同样与用户兴趣相似的其他用户也是一种用户特征。然后根据抽象设计一种基于特征的推荐系统架构。当用户到来之后，推荐系统需要为用户生成特征，然后对每个特征找到和特征相关的物品，从而最终生成用户的推荐列表。因而，推荐系统的核心任务就被拆解成两部分，一个是如何为给定用户生成特征，另一个是如何根据特征找到物品。 用户特征种类很多，主要包括如下几类： 人口统计学特征 用户行为特征 用户的话题特征 可以根据用户的历史行为利用话题模型(topic model)将电视剧和电影聚合成不同的话题，并且计算出每个用户对什么话题感兴趣。 同时推荐系统的推荐任务也有很多种，如果要在一个系统中把上面提到的各种特征和任务都统筹考虑，那么系统将会非常复杂，而且很难通过配置文件方便地配置不同特征和任务的权重。因此，推荐系统需要由多个推荐引擎组成，每个推荐引擎负责一类特征和一种任务，而推荐系统的任务只是将推荐引擎的结果按照一定权重或者优先级合并、排序然后返回。 这样做有两个好处： 可以方便地增加/删除引擎，控制不同引擎对推荐结果的影响。对于绝大多数需求，只需要通过不同的引擎组合实现。 可以实现推荐引擎级别的用户反馈。每一个推荐引擎其实代表了一种推荐策略，而不同的用户可能喜欢不同的推荐策略。可以将每一种策略都设计成一个推荐引擎，然后通过分析用户对推荐结果的反馈了解用户比较喜欢哪些引擎推荐出来的结果，从而对不同的用户给出不同的引擎组合权重。 将推荐系统拆分成不同推荐引擎后，如何设计一个推荐引擎变成了推荐系统设计的核心部分。下一节讨论推荐引擎的设计方法。 7.3 推荐引擎的架构推荐系统架构主要包括3部分： 该部分负责(1)从数据库或者缓存中拿到用户行为数据，通过(2)分析不同行为，(3)生成当前用户的特征向量。不过如果是使用非行为特征，就不需要使用行为提取和分析模块了。该模块的输出是用户特征向量。 该部分负责将用户的特征向量通过特征-物品相关矩阵转化为初始推荐物品列表。 该部分负责对初始的推荐列表进行过滤、排名等处理，从而生成最终的推荐结果。 下节对各个不同的部分分别详细解释。 7.3.1 生成用户特征向量一般来说，用户的特征包括两种，一种是用户的注册信息中可以提取出来的，另一种特征主要是从用户的行为中计算出来的，本节着重讨论如何生成特征。 一个特征向量由特征以及特征的权重组成，在利用用户行为计算特征向量时需要考虑以下因素。 用户行为的种类 不同行为的影响不同，大多时候很难确定什么行为更加重要，一般的标准就是用户付出代价越大的行为权重越高。 用户行为产生的时间 距离现在越近的行为权重越高。 用户行为的次数 用户对同一个物品的同一种行为发生的次数也反映了用户对物品的兴趣，行为次数多的物品对应的特征权重越高。 物品的热门程度 用户对热门物品的行为不能够反映用户的兴趣，而冷门物品则可以能够反映。推荐引擎在生成用户特征时会加重不热门物品对应的特征的权重。 7.3.2 特征—物品相关推荐在得到用户的特征向量后，可以根据离线相关表得到初始的物品推荐列表。离线相关表可以存储在MySQL中。对于每个特征，我们可以在相关表中存储和它最相关的N个物品的ID。 在线使用的特征—物品相关表一般都不止一张。因为可能使用了不同的推荐算法。总之，对于一个推荐引擎可以在配置文件中配置很多相关表以及它们的权重，而在线服务在启动时会将这些相关表按照配置的权重相加，然后将最终的相关表保存在内存中，而在给用户进行推荐时，用的已经是加权后的相关表了。 特征—物品相关推荐模块还可以接受一个候选物品集合。候选物品集合的目的是保证推荐结果只包含候选物品集合中的物品。对推荐物品的范围进行限定。 书中对为什么不在过滤模块中将候选集合外的电视剧过滤掉，而要在相关推荐模块中处理候选物品列表作出了解释，不过我没有看明白，有机会再看一次这部分。 特征—物品相关推荐模块除了给用户返回物品推荐列表，还需要给推荐列表中的每个推荐结果产生一个解释列表，表明这个物品是因为哪些特征推荐出来的。下面的代码给出了相关推荐模块的大体工作流程。 1234567def RecommendationCore(features, related_table): ret = dict() for fid, fweight in features.items() for item, sim in related_table[fid].items(): ret[item].weight += sim * fweight ret[item].reason[fid] = sim * fweight return ret 7.3.3 过滤模块在得到初步的推荐列表后，需要先按照产品需求对结果进行过滤，过滤掉不符合要求的物品，然后再把推荐列表展现给用户。 一般来说，过滤模块会过滤掉以下物品： 用户已经产生过行为物品 为了保证结果的新颖性 候选物品以外的物品 候选物品集合一般有两个来源，一个是产品需求。另一个来源是用户自己的选择，过滤掉不满足用户所选条件的物品。 7.3.4 排名模块对推荐列表进行排名可以更好地提升用户满意度，一般排名模块需要包括很多不同的子模块，下面对不同的模块分别加以介绍。 1.新颖性排名新颖性排名模块的目的是给用户尽量推荐他们不知道的、长尾中的物品。虽然前面的过滤模块已经过滤掉了用户曾经有过行为的物品，保证了一定程度的新颖性，但是用户在当前网站对某个物品没有行为并不代表用户不知道这个物品。 要准确了解用户是否已经知道某个物品是非常困难的，因此只能通过某种近似的方式知道，比如使用如下公式对推荐结果中热门的物品进行降权。$$p_{ui} = \frac{p_{ui}}{\log{(1 + \alpha \cdot popularity(i))}}$$不过，要实现推荐结果的新颖性，仅仅在最后对热门物品进行降权是不够的，而应在推荐引擎的各个部分考虑新颖性问题。 本章提到推荐系统架构主要是基于物品的推荐算法的，因此回顾一下基于物品的推荐算法的基本公式：$$p_{ui} = \sum_{j \in N(u) \cap S(i,K)} w_{ji} r_{uj}$$在上述公式中$j$是联系用户和推荐物品的特征。最终$p_{ui}$的大小主要取决于两个参数——$w_{ji}$和$r_{uj}$。其中，$r_{uj}$在通过用户行为生成用户特征向量时计算，而$w_{ji}$是离线计算的物品相似度。如果要提高推荐结果的新颖性，在计算这两个数时都要考虑新颖性。与上面同理对$r_{uj}$和$w_{ji}$进行降权。$$r_{uj} = \frac{r_{uj}}{\log(1+\alpha \cdot popularity(j))}$$ $$w_{ji} = \frac{w_{ji}}{\log(1+\alpha \cdot popularity(i))} (popularity(i) &gt; popularity(j))$$ 此外，也可以引入内容相似度矩阵，因为内容相似度矩阵中和每个物品相似的物品都不是很热门，所以引入内容相似度矩阵也能够提高最终推荐结果的新颖度。 2.多样性增加多样性可以让推荐结果覆盖尽可能多的用户兴趣。这里需要指出的是提高多样性并不是时时刻刻都很好。 第一种提高多样性的方法是将推荐结果按照某种物品的内容属性分成几类，然后在每个类中都选择该类中排名最高的物品组合成最终的推荐列表。这种方法的好处是比较简单直观，但这种方法也有严重的缺点。首先，选择什么样的内容属性进行分类对结果的影响很大。其次，就算选择了某种类别，但物品是否属于某个类别是编辑确定的，并不一定能够得到用户的公认。 第二种提高推荐结果多样性的方法是控制不同推荐结果的推荐理由出现的次数。本章提出的推荐系统对于每个推荐出来的物品都有一个推荐理由，这个推荐理由一般是产生推荐结果的重要特征。那么，要提高推荐结果的多样性，就需要让推荐结果尽量来自不同的特征，具有不同的推荐理由，而不是所有的推荐结果都对应一个理由。 下面的代码根据推荐理由增加推荐结果的多样性，这里输入的recommendations是按照权重从大到小排序的，程序中每次拿出一个推荐结果，如果这个结果已经被用过了，就会对推荐结果的权重除以2降权（这里具体除以几可以在实际应用中自己调整），最终将推荐结果重新按照权重从大到小排序。 1234567def ReasonDiversity(recommendations): reasons = set() for i in recommendations: if i.reason in reasons: i.weight /= 2 reasons.add(i.reason) recommendations = sortByWeight(recommendations) 3.时间多样性时间多样性主要是为了保证用户不要每天来推荐系统都看到同样的推荐结果。在第5章已经提到，提高推荐系统的时间多样性要从两个地方着手。首先要保证推荐系统的实时性，在用户有新行为时实时调整推荐结果以满足用户最近的需求。这一点，在本章的推荐系统设计中已经考虑到了。如果用户有实时行为发生，那么行为提取和分析模块就能实时拿到行为数据并转化为新的特征，然后经过特征-物品相关模块转换成和新特征最相关的物品，因而推荐列表中就立即反应了用户最新行为的影响。提高推荐结果多样性的第二个方面是要在用户没有新的行为时，也要保证推荐结果每天都有变化。要实现这一点，只能通过如下方式。 记录用户每次登陆推荐系统看到的推荐结果。 将这些结果发回日志系统。这种数据不需要实时存储，只要能保证小于一天的延时就足够了。 在用户登录时拿到用户昨天及之前看过的推荐结果列表，从当前推荐结果中将用户已经看到的推荐结果降权。 4.用户反馈排名模块最重要的部分就是用户反馈模块。用户反馈模块主要通过分析用户之前和推荐结果的交互日志，预测用户会对什么样的推荐结果比较感兴趣。 如果推荐系统的目标是提高用户对推荐结果的点击率，那么可以利用点击模型(click model)预测用户是否会点击推荐结果。点击模型在很多领域得到了广泛应用，比如搜索结果的点击预测(参见论文“A dynamic bayesian network click model for web search ranking”，作者为Olivier Chapelle和Ya Zhang)、 搜索广告的点击预测(参见论文“Online learning from click data for sponsored search”，作者为Massimiliano Ciaramita、Vanessa Murdock和Vassilis Plachouras )、上下文广告的点击预测(参见论文“Contextual advertising by combining relevance with click feedback”，作者为Deepayan chakrabarti、Deepak Agarwal和Vanja Josifovski。)。点击预测的主要问题是预测用户看到某个推荐结果时是否会点击。那么要进行点击率预测，首先需要提取特征。在推荐系统的点击率预测中可以用如下特征预测用户$u$会不会点击物品$i$： 用户$u$相关的特征，比如年龄、性别、活跃程度、之前有没有点击行为； 物品$i$相关的特征，比如流行度，平均分，内容属性； 物品$i$在推荐列表中的位置。用户的点击和用户界面的设计有很高的相关性，因此物品$i$在推荐列表中的位置对预测用户是否点击很重要； 用户之前是否点击过和推荐物品$i$具有同样推荐解释的其他推荐结果； 用户之前是否点击过和推荐物品$i$来自同样推荐引擎的其他推荐结果。 点击模型需要离线计算好，在线将模型加载到内存中。为了提高在线预测的效率，一般只可以使用线性模型。 7.4 扩展阅读关于推荐系统架构方面的文章很多，不过详细介绍架构的技术报告不多。知名公司亚马逊和Netflix等都只给出了一些简单的线索。本章提到的推荐系统架构主要是基于本书作者在Hulu工作时使用的架构抽象发挥出来的，对于Hulu架构感兴趣的读者可以参考Hulu的技术博客(参见http://tech.hulu.com/blog/2011/09/19/recommendation-system/ )。MyMedia(参见http://mymediaproject.codeplex.com/ )是一个比较著名的开源推荐系统架构。它是由欧洲研究人员开发的一个推荐系统开源框架。该框架同时支持评分预测和TopN推荐，全面支持各种数据和各种算法，对该项目感兴趣的用户可以访问该项目的网站http://www.mymediaproject.org/default.aspx 。本章提出的推荐系统架构基本上是从基于物品的推荐算法衍生出来的，因此本章的架构并不适合用来解决社会化推荐问题。如果要了解社会化推荐方面的架构，可以参考Twitter公开的一些文档。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（六）]]></title>
    <url>%2F2018%2F11%2F29%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第6章 利用社交网络数据美国著名的第三方调查机构尼尔森调查了影响用户相信某个推荐的因素(参见“Global Advertising Consumers Trust Real Friends and Virtual Strangers the Most”，http://blog.nielsen.com/nielsen-wire/consumer/global-advertising-consumers-trust-real-friends-and-virtual-strangers-the-most/ )。书中这部分有关于这次调查的简略介绍。实验证明了好友的推荐对于增加用户对推荐结果的信任度非常重要，并且该实验也从侧面说明了社交网络在推荐系统中可能具有重要的作用。 本章详细讨论了如何利用社交网络数据给用户进行个性化推荐。本章不仅讨论如何利用社交网络给用户推荐物品，而且将讨论如何利用社交网络给用户推荐好友。 6.1 获取社交网络数据的途径6.1.1 电子邮件谷歌在2010年的KDD会议上发表了一篇文章(参见Maayan Roth、Assaf Ben-David、David Deutscher、Guy Flysher、Ilan Horn、Ari Leichtberg、Naty Leiser、Yossi Matias、Ron Merom的“Suggesting Friends Using the Implicit Social Graph”（ACM 2010 Article，2010）)，其中就研究了如何通过Gmail系统中、一些不违反隐私协议的数据预测用户之间的社交关系，以便给用户推荐好友的问题。 其次，如果能够获得用户的邮箱，也可以通过邮箱后缀得到一定的社交关系信息。 6.1.2 用户注册信息用户注册时输入的信息也是一种隐性社交网络数据，可以用来分析。 6.1.3 用户的位置数据可以通过得到的IP地址，GPS数据作为用户位置信息，进而分析出用户的同事、邻居等关系。 6.1.4 讨论和讨论组类似于豆瓣上的小组。兴趣相近的人可能会加入一些相同的小组。 6.1.5 即时聊天工具通过即时聊天工具上的联系人列表和分组信息，知道用户的社交网络关系，并且能够通过统计用户之间聊天的频繁程度，度量出用户之间的熟悉程度。但与电子邮件一样，存在隐私问题。 6.1.6 社交网络上述各种获取用户社交关系的途径，要么就是因为隐私问题很难获取，要么就是虽然容易获取，但却都是隐性社交关系数据，很难推断出用户之间的显性社交关系。但以Facebook和Twitter为代表的新一代社交网络突破了这个瓶颈。 社交网站的另一个好处是自然地减轻了信息过载问题。在社交网站中，我们可以通过好友给自己过滤信息。比如，我们只关注那些和我们兴趣相似的好友，只阅读他们分享的信息，因此可以避免阅读很多和自己无关的信息。个性化推荐系统可以利用社交网站公开的用户社交网络和行为数据，辅助用户更好地完成信息过滤的任务，更好地找到和自己兴趣相似的好友，更快地找到自己感兴趣的内容。 1.社会图谱和兴趣图谱Facebook和Twitter作为社交网站中的两个代表，它们其实代表了不同的社交网络结构。在Facebook里，人们的好友一般都是自己在现实社会中认识的人(参见“Friends &amp; Frenemies: Why We Add and Remove Facebook Friends”，地址为http://blog.nielsen.com/nielsenwire/online_mobile/friends-frenemies-why-we-add-and-remove-facebook-friends/ ，尼尔森的这个报告表明82%的用户会因为在现实社会中认识而在Facebook中加好友。)，并且Facebook中的好友关系是需要双方确认的。在Twitter里，人们的好友往往都是现实中自己不认识的， 而只是出于对对方言论的兴趣而建立好友关系， 好友关系也是单向的关注关系。 以Facebook为代表的社交网络称为社交图谱(social graph)，而以Twitter为代表的社交网络称为兴趣图谱(interest graph)。 关于这两种社交网络的分类早在19世纪就被社会学家研究过。19世纪，德国社会学家斐迪南·滕尼斯（Ferdinand Tönnies）认为社会群体分为两种，一种是通过人们之间的共同兴趣和信念形成的，他将这种社会群体称为Gemeinschaft，而Gemeinschaft这个词后来被翻译成英语就是community，即汉语中的社区。另一种社会群体则是由于人们之间的亲属关系，工作关系而形成的，他称之为Gesellschaft，英文翻译为society，即汉语中的“社会”。因此，斐迪南·滕尼斯说的Gemeinschaft就是兴趣图谱，而Gesellschaft就是社会图谱。 但是，每个社会化网站都不是单纯的社交图谱或者兴趣图谱。 6.2 社交网络数据简介可以用图定义社交网络并表示用户之间的关系。用图$G(V,E,w)$定义一个社交网络，其中$V$是顶点集合，每个顶点代表一个用户，$E$是边集合，如果用户$v_a$和$v_b$有社交网络关系，那么就有一条边$e(v_a , v_b)$连接这两个用户，而$w(v_a , v_b)$定义了边的权重。业界有两种著名的社交网络。一种以Facebook为代表，它的朋友关系是需要双向确认的，因此用无向边连接有社交网络关系的用户。另一种以Twitter为代表，它的朋友关系是单向的，因此用有向边代表这种社交网络上的用户关系。 此外，对图$G$中的用户顶点$u$，定义$out(u)$为顶点$u$指向的顶点集合（如果套用微博中的术语，$out(u)$就是用户$u$关注的用户集合），定义$in(u)$为指向顶点$u$的顶点集合（也就是关注用户$u$的用户集合）。那么，在Facebook这种无向社交网络中显然有$out(u)$=$in(u)$。 一般来说，有3种不同的社交网络数据。 双向确认的社交网络数据 以Facebook为代表的社交网络。用户A和B之间形成好友关系需要通过双方的确认。此种社交网络一般可以通过无向图表示。 单向关注的社交网络数据 以Twitter为代表的社交网络。用户A可以关注用户B而不需要得到用户B的允许。此种社交网络一般可以通过有向图表示。 基于社区的社交网络数据 以豆瓣小组为代表的社交网络。用户之间没有明确的关系，但这种社交网络数据办函了用户属于不同社区的数据。 社交网络数据中的长尾分布该节利用了Slashdot的社交网络数据集(数据集来自Stanford Large Network Dataset Collection，参见http://snap.stanford.edu/data/ )统计了用户入度(in degree)和出度(out degree)的分布，得到了两个结论： 用户的入度近似长尾分布，说明在一个社交网络中影响力大的用户总是占少数。 用户的出度同样近似长尾分布，说明在一个社交网络中，关注很多人的用户占少数，而绝大多数用户只关注很少的人。 6.3 基于社交网络的推荐社会化推荐之所以受到很多网站的重视，是缘于如下优点。 好友推荐可以增加推荐的信任度 好友往往是用户最信任的。用户往往不一定信任计算机的智能，但会信任好朋友的推荐。 社交网络可以解决冷启动问题 当新用户使用社交网络账号登录网站时，网站可以从社交网站中获取用户的好友列表，然后给用户推荐好友在网站上喜欢的物品。 社会化推荐同样拥有缺点，其中最主要的就是很多时候并不一定能提高推荐算法的离线精度（准确率和召回率）。特别是在基于社交图谱数据的推荐系统中，因为用户的好友关系不是基于共同兴趣产生的，所以用户好友的兴趣往往和用户的兴趣并不一致。举个例子就是我们和父母在社交网络上虽然是好友，但兴趣差别很大。 2010年，ACM推荐系统大会的一个讨论组CAMRa曾经举办过一个关于社交网络的推荐系统比赛(参见http://www.dai-labor.de/camra2010/ )。该比赛希望参赛者能够利用用户之间的好友关系给用户推荐电影，并且利用准确率相关的指标评测参赛者的推荐算法。对社会化推荐感兴趣的读者可以关注一下该会议的相关论文。 6.3.1 基于邻域的社会化推荐算法如果给定一个社交网络和一份用户行为数据集。其中社交网络定义了用户之间的好友关系，而用户行为数据集定义了不同用户的历史行为和兴趣数据。那么最简单算法是给用户推荐好友喜欢的物品集合。即用户$u$对物品$i$的兴趣$p_{ui}$可以通过如下公式计算。$$p_{ui} = \sum_{v \in \text{out(u)}} r_{vi}$$$\text{out(u)}$是用户$u$的好友集合，如果用户$v$喜欢物品$i$，则$r_{vi} =1$，否则$r_{vi} = 0$。同时由于不同的好友和用户$u$的熟悉程度和兴趣相似度也是不同的。因此，应该在推荐算法中考虑好友和用户的熟悉程度以及兴趣相似度：$$p_{ui} = \sum_{v \in \text{out(u)}} w_{uv}r_{vi}$$$w_{uv}$由两部分相似度构成，一部分是用户$u$和用户$v$的熟悉程度，另一部分是用户$u$和用户$v$的兴趣相似度。用户$u$和用户$v$的熟悉程度(familiarity)描述了用户$u$和用户$v$在现实社会中的熟悉程度。一般来说，用户更加相信自己熟悉的好友的推荐，因此我们需要考虑用户之间的熟悉度。熟悉度可以用用户之间的共同好友比例来度量。也就是说如果用户$u$和用户$v$很熟悉，那么一般来说他们应该有很多共同的好友。$$familiarity(u,v) = \frac{\vert out(u) \cap out(v) \vert}{\vert out(u) \cup out(v) \vert}$$除了熟悉程度，还需要考虑用户之间的兴趣相似度，而兴趣相似度可以通过和UserCF类似的方法度量，即如果两个用户喜欢的物品集合重合度很高，两个用户的兴趣相似度很高。$$similarity(u,v) = \frac{N(u) \cap N(v)}{N(u) \cup N(v)}$$其中$N(u)$是用户$u$喜欢的物品集合。 下面的代码实现社会化推荐的逻辑。在代码中，familiarity存储了每个用户最熟悉的$K$个好友和他们的熟悉程度，similarity存储了和每个用户兴趣最相关的$K$好友和他们的兴趣相似度。train记录了每个用户的行为记录，其中train[u]记录了用户$u$喜欢的物品列表。 12345678910111213141516def Recommend(uid, familiarity, similarity, train): rank = dict() interacted_items = train[uid] for fid,fw in familiarity[uid]: for item,pw in train[fid]: # if user has already know the item # do not recommend it if item in interacted_items: continue addToDict(rank, item, fw * pw) for vid,sw in similarity[uid]: for item,pw in train[vid]: if item in interacted_items: continue addToDict(rank, item, sw * pw) return rank 6.3.2 基于图的社会化推荐算法图模型的优点是可以将各种数据和关系都表示到图上去。在社交网站中存在两种关系，一种是用户对物品的兴趣关系，一种是用户之间的社交网络关系。本节主要讨论如何将这两种关系建立到图模型中，从而实现对用户的个性化推荐。 用户的社交网络可以表示为社交网络图，用户对物品的行为可以表示为用户物品二分图，而这两种图可以结合成一个图。该图上有用户顶点和物品顶点两种顶点。如果用户$u$对物品$i$产生过行为，那么两个节点之间就有边相连。如果用户$u$和用户$v$是好友，那么也会有一条边连接这两个用户。 在定义完图中的顶点和边后，需要定义边的权重。其中用户和用户之间边的权重可以定义为用户之间相似度的$\alpha$倍（包括熟悉程度和兴趣相似度），而用户和物品之间的权重可以定义为用户对物品喜欢程度的$\beta$倍。$\alpha$和$\beta$需要根据应用的需求确定。如果希望用户好友的行为对推荐结果产生比较大的影响，那么就可以选择比较大的$\alpha$。相反，如果希望用户的历史行为对推荐结果产生比较大的影响，就可以选择比较大的。 在定义完图中的顶点、边和边的权重后，就可以利用前面几章提到的PersonalRank图排序算法给每个用户生成推荐结果。 在社交网络中，除了常见的、用户和用户之间直接的社交网络关系，还有一种关系，即两个用户属于同一个社群。Quan Yuan等详细研究了这两种社交网络关系(参见Quan Yuan、Li Chen和Shiwan Zhao的“Factorization vs. regularization: fusing heterogeneous social relationships in top-n recommendation”（ACM 2011 Article，2011）)，他们将第一种社交网络关系称为friendship，而将第二种社交网络关系称为membership。如果要在前面提到的基于邻域的社会化推荐算法中考虑membership的社交关系，可以利用两个用户加入的社区重合度计算用户 相似度，然后给用户推荐和他相似的用户喜欢的物品。但是，如果利用图模型则更为容易，可以加入一种节点表示社群，而如果用户属于某一社群，图中就有一条边联系用户对应的节点和社群对应的节点。建立图模型后，就可以通过前面提到的基于图的推荐算法(例如PersonalRank)给用户推荐物品。 6.3.3 实际系统中的社会化推荐算法6.3.1节提出的基于邻域的社会化推荐算法看似简单，但在实际系统中却是很难操作的，这主要是因为该算法需要拿到用户所有好友的历史行为数据，而这一操作在实际系统中是比较重的操作。因为大型网站中用户数目非常庞大，用户的历史行为记录也非常庞大，所以不太可能将用户的所有行为都缓存在内存中，只能在数据库前做一个热数据的缓存。 由于ItemCF算法只需要当前用户的历史行为数据和物品的相关表就可以生成推荐结果。对于物品数不是很多的网站，可以将物品相关表缓存在内存中，因此ItemCF算法很容易在实际环境下实现。 可以从几个方面改进基于邻域的社会化推荐算法，让它能够具有比较快的响应时间。改进的方向有两种，一种是治标不治本的方法。简单地说，就是可以做两处截断。第一处截断在拿用户好友集合时只拿出用户相似度最高的N个好友而非全部，从而给该用户做推荐时可以只查询N次用户历史行为接口。此外，在查询每个用户的历史行为时，只返回用户最近1个月的行为，这样就可以在用户行为缓存中缓存更多用户的历史行为数据，从而加快查询用户历史行为接口的速度。此外，还可以牺牲一定的实时性，降低缓存中用户行为列表过期的频率。 而第二种解决方案需要重新设计数据库。Twitter的解决方案是给每个用户维护一个消息队列(message queue)，当一个用户发表一条微博时，所有关注他的用户的消息队列中都会加入这条微博。这个实现的优点是用户获取信息墙时可以直接读消息队列，所以终端用户的读操作很快。不过这个实现也有缺点，当一个用户发表了一条微博，就会触发很多写操作，因为要更新所有关注他的用户的消息队列，特别是当一个人被很多人关注时，就会有大量的写操作。Twitter通过大量的缓存解决了这一问题。具体的细节可以参考InfoQ对Twitter架构的介绍(参见“Twitter, an Evolving Architecture”，地址为http://www.infoq.com/news/2009/06/Twitter-Architecture )。 如果将Twitter的架构搬到社会化推荐系统中，就可以按照如下方式设计系统： 首先，为每个用户维护一个消息队列，用于存储他的推荐列表； 当一个用户喜欢一个物品时，就将（物品ID、用户ID和时间）这条记录写入关注该用户的推荐列表消息队列中； 当用户访问推荐系统时，读出他的推荐列表消息队列，对于这个消息队列中的每个物品，重新计算该物品的权重。计算权重时需要考虑物品在队列中出现的次数，物品对应的用户和当前用户的熟悉程度、物品的时间戳。同时，计算出每个物品被哪些好友喜欢过，用这些好友作为物品的推荐解释。 6.3.4 社会化推荐系统和协同过滤推荐系统关于社会化推荐系统的离线评测可以参考Georg Groh和Christian Ehmig的工作成果(参见“Recommendations in Taste Related Domains: Collaborative Filtering vs. Social Filtering”，2007年)。不过社会化推荐系统的效果往往很难通过离线实验评测，因为社会化推荐的优势不在于增加预测准确度，而是在于通过用户的好友增加用户对推荐结果的信任度，从而让用户单击那些很冷门的推荐结果。此外，很多社交网站（特别是基于社交图谱的社交网站）中具有好友关系的用户并不一定有相似的兴趣。因此，利用好友关系有时并不能增加离线评测的准确率和召回率。因此，很多研究人员利用用户调查和在线实验的方式评测社会化推荐系统。 对社会化推荐系统进行用户调查的代表性工作成果是Rashmi Sinha和Kirsten Swearingen对比社会化推荐系统和协同过滤推荐系统的论文(参见“Comparing Recommendations Made by Online Systems and Friends”，2001年 )。这一节简单介绍了他们的工作方法和结果，详细见书。 6.3.5 信息流推荐信息墙已经是个性化的，但里面仍夹杂了很多垃圾信息。因此，信息流的个性化推荐要解决的问题就是如何进一步帮助用户从信息墙上挑选有用的信息。 目前最流行的信息流推荐算法是Facebook的EdgeRank，该算法综合考虑了信息流中每个会话的时间、长度与用户兴趣的相似度。EdgeRank算法比较神秘，没有相关的论文，不过TechCrunch曾经公开过它的主要思想(参见“EdgeRank: The Secret Sauce That Makes Facebook’s News Feed Tick”， 地址为http://techcrunch.com/2010/04/22/facebook-edgerank/ )。Facebook将其他用户对当前用户信息流中的会话产生过行为的行为称为edge，而一条会话的权重定义为： $$\sum_{\text{edge} \ e}u_e w_e d_e$$ $u_e$指产生行为的用户和当前用户的相似度，这里的相似度主要是在社交网络图中的熟悉度； $w_e$指行为的权重，这里的行为包括创建、评论、like(喜欢)、打标签等，不同的行为有不同的权重。 $d_e$指时间衰减参数，越早的行为对权重的影响越低。 从上面的描述中可以得出如下结论：如果一个会话被你熟悉的好友最近产生过重要的行为，它就会有比较高的权重。 不过，EdgeRank算法的个性化因素仅仅是好友的熟悉度，它并没有考虑帖子内容和用户兴趣的相似度。所以EdgeRank仅仅考虑了“我”周围用户的社会化兴趣，而没有重视“我”个人的个性化兴趣。为此，GroupLens的研究人员Jilin Chen深入研究了信息流推荐中社会兴趣和个性化兴趣之间的关系。 (参见Jilin Chen、Rowan Nairn和Ed H. Chi的“Speak Little and Well: Recommending Conversations in Online Social Streams”（ACM 2011 Article, 2011）)他们的排名算法考虑了如下因素。 会话的长度 越长的会话包括越多的信息。 话题相关性 度量了会话中主要话题和用户兴趣之间的相关性。这里Jilin Chen用了简单的TF-IDF建立用户历史兴趣的关键词向量和当前会话的关键词向量，然后用这两个向量的相似度度量话题相关性。 用户熟悉程度 主要度量了会话中涉及的用户（比如会话的创建者、讨论者等）和当前用户的熟悉程度。对于如何度量用户的熟悉程度下一节将详细介绍。计算熟悉度的主要思想是考虑用户之间的共同好友数等。 为了验证算法的性能，Jilin Chen同样也设计了一个用户调查。首先，他通过问卷将用户分成两种类型。第一种类型的用户使用Twitter的目的是寻找信息，也就是说他们将Twitter看做一种信息源和新闻媒体。而第二种用户使用Twitter的目的是了解好友的最新动态以及和好朋友聊天。然后，他让参试者对如下5种算法的推荐结果给出1~5分的评分，其中1分表示不喜欢，5分表示最喜欢。 Random 给用户随机推荐会话 Length 给用户推荐比较长的会话 Topic 给用户推荐和他兴趣相关的会话。 Tie 给用户推荐和他熟悉的好友参与的会话。 Topic+Tie 综合考虑会话和用户的兴趣相关度以及用户好友参与会话的程度。 通过收集用户反馈，Jilin Chen发现对于所有用户不同算法的平均得分是：Topic+Tie &gt; Tie &gt; Topic &gt; Length &gt; Random而对于主要目的是寻找信息的用户，不同算法的得分是：Topic+Tie ≥ Topic &gt; Length &gt; Tie &gt; Random对于主要目的是交友的用户，不同算法的得分是：Topic+Tie &gt; Tie &gt; Topic &gt; Length &gt; Random 实验结果说明，综合考虑用户的社会兴趣和个人兴趣对于提高用户满意度是有帮助的。因此，当我们在一个社交网站中设计推荐系统时，可以综合考虑这两个因素，找到最合适的融合参数来融合用户的社会兴趣和个人兴趣，从而给用户提供最令他们满意的推荐结果。 6.4 给用户推荐好友好友推荐系统的目的是根据用户现有的好友、 用户的行为记录给用户推荐新的好友，从而增加整个社交网络的稠密程度和社交网站用户的活跃度。 好友推荐算法在社交网络上被称为链接预测(link prediction)。关于链接预测算法研究的代表文章是Jon Kleinberg的“Link Prediction in Social Network”。该文对各种用户好友关系的预测方法进行了系统地研究和对比。本节介绍其中一些比较直观和简单的算法。 6.4.1 基于内容的匹配给用户推荐和他们有相似内容属性的用户作为好友。 常用属性如下： 用户人口统计学属性，包括年龄、性别、职业、毕业学校和工作单位等。 用户的兴趣，包括用户喜欢的物品和发布过的言论等。 用户的位置信息，包括用户的住址、IP地址和邮编等。 利用内容信息计算用户的相似度和前面介绍的利用内容信息计算物品的相似度类似。 6.4.2 基于共同兴趣的好友推荐在Twitter和微博为代表的以兴趣图谱为主的社交网络中，用户往往不关心对于一个人是否在现实社会中认识，而只关心是否和他们有共同的兴趣爱好。因此，在这种网站中需要给用户推荐和他有共同兴趣的其他用户作为好友。 在第3章介绍基于用户的协同过滤算法(UserCF)时已经详细介绍了如何计算用户之间的兴趣相似度，其主要思想就是如果用户喜欢相同的物品，则说明他们具有相似的兴趣。 此外，也可以根据用户在社交网络中的发言提取用户的兴趣标签，来计算用户的兴趣相似度。关于如何分析用户发言的内容、提取文本的关键词、计算文本的相似度，可以参考第4章。 6.4.3 基于社交网络图的好友推荐最简单的好友推荐算法是给用户推荐好友的好友。 下面介绍3中基于社交网络的好友推荐算法。对于用户$u$和用户$v$，可以用他们共同好友比例计算他们的相似度：$$w_{out}(u,v) = \frac{\vert out(u) \cap out(v) \vert}{\sqrt {\vert out(u) \vert \vert out(v) \vert}}$$ 下面的代码实现了这种相似度： 1234567891011def FriendSuggestion(user, G, GT): suggestions = dict() friends = G[user] for fid in G[user]: for ffid in GT[fid]: if ffid in friends: continue if ffid not in suggestions: suggestions[ffid] = 0 suggestions[ffid] += 1 suggestions = &#123;x: y / math.sqrt(len(G[user]) * len(G[x]) for x,y in suggestions&#125; $w_{out}(u,v)$公式中$out(u)$是在社交网络图中用户$u$指向的其他好友的集合。同理$in(u)$是在社交网络图中指向用户$u$的用户的集合。在无向社交网络图中，$out(u)$和$in(u)$是相同的集合。但在有向社交网络中，两个集合就不同了，因此可以通过$in(u)$定义另一种相似度：$$w_{in}(u,v) = \frac{\vert in(u) \cap in(v) \vert}{\sqrt{\vert in(u) \vert \vert in(v) \vert}}$$ 12345678910def FriendSuggestion(user, G, GT): suggestions = dict() for fid in GT[user]: for ffid in G[fid]: if ffid in friends: continue if ffid not in suggestions: suggestions[ffid] = 0 suggestions[ffid] += 1 suggestions = &#123;x: y / math.sqrt(len(GT[user]) * len(GT[x]) for x,y in suggestions&#125; 这两种相似度的定义有着不同的含义，用微博中的关注来解释这两种相似度。如果用户$u$关注了用户$v$，那么$v$就属于$out(u)$，而$u$就属于$in(v)$。因此，$w_{out} (u , v )$越大表示用户$u$和$v$关注的用户集合重合度越大，而$w_{in }(u, v) $越大表示关注用户$u$和关注用户$v$的用户的集合重合度越大。 前面两种相似度都是对称的，也就是也就是$w_{in} (u, v) = w_{in} (v, u )$，$w_{out} (u , v ) = w_{out} (v, u ) $。同时，我们还可以定义第三种有向的相似度：$$w_{out,in}(u,v) = \frac{\vert out(u) \cap in(v) \vert}{out(u)}$$这个相似度的含义是用户$u$关注的用户中，有多大比例也关注了用户v。但是，这个相似度有一个缺点，就是在该相似度的定义下所有人都和名人有很大的相似度。这是因为这个相似度在分母的部分没有考虑$|in(v)|$的大小。因此，可以用如下公式改进上面的相似度：$$w_{out,in}’(u,v) = \frac{\vert out(u) \cap in(v) \vert}{\sqrt{\vert out(u) \vert \vert in(v) \vert}}$$ 123456789def FriendSuggestion(user, G, GT): suggestions = dict() for fid in GT[user]: for ffid in G[fid]: if ffid in friends: continue if ffid not in suggestions: suggestions[ffid] = 0 suggestions[ffid] += 1 suggestions = &#123;x: y / math.sqrt(len(GT[user]) * len(GT[x]) for x,y in suggestions&#125; 前面讨论的这些相似度都是基于一些简单计算公式给出的。这些相似度的计算无论时间复杂度还是空间复杂度都不是很高，非常适合在线应用使用。 离线实验本节通过一些离线实验评测本节提出的几种相似度，评测哪种相似度能更好地预测用户之间的好友关系。实验详情见书。最终的结论是在实际系统中没有哪一种相似度公式绝对合适，只有在自己的数据集上对不不同的算法，才能找到最适合自己数据集的好友推荐算法。 6.4.4 基于用户调查的好友推荐算法对比对于前面3节提出的几种不同的好友推荐算法，上一节提到的GroupLen的Jilin Chen也进行了研究。他通过用户调查对比了不同算法的用户满意度(参见Jilin Chen、Werner Geyer、Casey Dugan Michael Muller、Ido Guy的“‘Make New Friends, but Keep the Old’ ——Recommending People on Social Networking Site”（CHI 2009）)。实验介绍和结果见书。 6.5 扩展阅读社交网络分析的研究已经有很悠久的历史了。其中关于社交网络最让人耳熟能详的结论就是六度原理。六度原理讲的是社会中任意两个人都可以通过不超过6个人的路径相互认识，如果转化为图的术语，就是社交网络图的直径为6。不过喜欢刨根问底的读者一定好奇六度原理的正确性。六度原理在均匀随机图上已经得到了完美证明，对此感兴趣的读者可以参考Random Graph一书。很多对社交网络的研究都是基于随机图理论的，因此深入研究社交网络必须掌握随机图理论的相关知识。 社交网络研究中有两个最著名的问题。第一个是如何度量人的重要性，也就是社交网络顶点的中心度(centrality)，第二个问题是如何度量社交网络中人和人之间的关系，也就是链接预测。这两个问题的研究都有着深刻的实际意义，因此得到了业界和学术界的广泛关注。对这两个问题感兴趣的读者可以参考社交网络分析方面的书(比如（Social Network Analysis: Methods and Applications）和（Social Network Analysis: A Handbook）)。 对于基于社交网络的推荐算法，因为数据集的限制，最早的研究都是基于Epinion的用户信任网络的。Ma Hao在Epinion数据集上提出了很多基于矩阵分解的社会化推荐算法用来解决评分预测问题(参见Hao Ma、Haixuan Yang、Michael R. Lyu和Irwin King的“SoRec: Social Recommendation Using Probabilistic Matrix Factorization”（ACM 2008 Article , 2008）)，其主要思想是在矩阵分解模型中加入正则化项，让具有社交关系的用户的隐语义向量具有比较高的相似度。 ACM推荐系统大会在2010年曾经举办过一个社会化推荐比赛(即CAMRa201: Challenge on Context-aware Movie Recommendation )，该比赛将社交网络看做一种上下文，希望参赛者能够利用社交网络信息提高推荐系统的性能。关注社交化推荐的读者可以关注一下该比赛最后发出的论文集。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（五）]]></title>
    <url>%2F2018%2F11%2F28%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第5章 利用上下文信息上下文信息对于提高推荐系统的各项评测指标是十分重要的，因此不能忽略上下文信息。准确了解用户的上下文信息(context)，并将该信息应用于推荐算法是设计好的推荐系统的关键步骤。关于上下文推荐的研究， 可以参考Alexander Tuzhilin(个人主页为http://people.stern.nyu.edu/atuzhili/ )教授的一篇综述“Context Aware Recommender Systems”。 本章主要讨论了时间上下文，并简单介绍一下地点上下文，讨论如何将时间信息和地点信息建模到推荐算法中，从而让推荐系统能够准确预测用户在某个特定时刻及特定地点的兴趣。本章仍然研究TopN推荐，即如何给用户生成一个长度为$N$的推荐列表，而该列表包含了用户在某一时刻或者某个地方最可能喜欢的物品。 5.1 时间上下文信息本节重点讨论了上下文信息中最重要的时间上下文信息。本节首先介绍了各种不同的时间效应，然后研究如何将这些时间效应建模到推荐系统的模型中，最后通过实际数据集对比不同模型的效果。 5.1.1 时间效应简介一般认为，时间信息对用户兴趣的影响表现在以下几个方面。 用户兴趣是变化的 这里提到的用户兴趣变化是因为用户自身原因发生的变化，并且考虑用户最近的兴趣只能针对渐变的用户兴趣，而对突变的用户兴趣很难起作用。 物品也是有生命周期的 不同系统的物品具有不同的生命周期。 季节效应 季节效应主要反映了时间本身对用户兴趣的影响。 5.1.2 时间效应举例这节通过Google Insights工具提供的某个搜索词的搜索频率曲线对时间效应进行一些分析，并且罗列了一些用户兴趣变化及节日效应的例子。 5.1.3 系统时间特性的分析在给定时间信息后，推荐系统从一个静态系统变成了一个时变的系统，而用户行为数据也变成了时间序列。研究一个时变系统，需要首先研究这个系统的时间特性。 本节通过研究时变 用户行为数据集来研究不同类型网站的时间特性。包含时间信息的用户行为数据集由一系列三元组构成，其中每个三元组$(u,i,t)$代表了用户$u$在时刻$t$对物品$i$产生过行为。在给定数据集后，本节通过统计如下信息研究系统的时间特性。 数据集每天独立用户数的增长情况 系统的物品变化情况 用户访问情况 1.数据集的选择本节利用Delicious数据集进行离线实验以评测不同算法的预测精度，书中这部分有一些关于Delicious数据集的介绍。 2.物品的生存周期和系统的时效性不同类型网站的物品具有不同的生命周期。可以使用如下指标度量网站中物品的生命周期。 物品平均在线天数 如果一个物品在某天被至少一个用户产生过行为，就定义该物品在这一天在线。因此，就可以通过物品的平均在线天数度量一类物品的生存周期。 相隔T天系统物品流行度向量的平均相似度 取系统中相邻T天的两天，分别计算这两天的物品流行度，从而得到两个流行度向量。然后，计算这两个向量的余弦相似度，如果相似度大，说明系统的物品在相隔T天的时间内没有发生大的变化，从而说明系统的时效性不强，物品的平均在线时间较长。反之，相似度小则说明时效性很强。 5.1.4 推荐系统的实时性用户兴趣是不断变化的，其变化体现在用户不断增加的新行为中。一个实时的推荐系统需要能够实时响应用户新的行为，让推荐列表不断变化，从而满足用户不断变化的兴趣。 实现推荐系统的实时性除了对用户行为的存取有实时性要求，还要求推荐算法本身具有实时性，而推荐算法本身的实时性意味着： 实时推荐系统不能每天都给所有用户离线计算推荐结果，然后在线展示昨天计算出来的结果。所以，要求在每个用户访问推荐系统时，都根据用户这个时间点前的行为实时计算推荐列表。 推荐算法需要平衡考虑用户的近期行为和长期行为，即要让推荐列表反应出用户近期行为所体现的兴趣变化，又不能让推荐列表完全受用户近期行为的影响，要保证推荐列表对用户兴趣预测的延续性。 5.1.5 推荐算法的时间多样性为了避免每天给用户的推荐结果相近，将推荐系统每天推荐结果的变化程度被定义为推荐系统的时间多样性。时间多样性高的推荐系统中用户会经常看到不同的推荐结果。 那么推荐系统的时间多样性和用户满意度之间是否存在关系呢？时间多样性高是否就能提高用户的满意度？为了解答这些问题，英国研究人员进行了一次实验(参见Neal Lathia、Stephen Hailes、Licia Capra和Xavier Amatriain的“Temporal Diversity in Recommender Systems”（SIGIR 2010）)，他们设计了3种推荐系统，证明了时间多样性对推荐系统的正面意义，书上有关于这个实验的简略介绍。 之后的问题就是如何在不损失精度的情况下提高推荐结果的时间多样性。提高推荐结果的时间多样性需要分两步解决：首先，需要保证推荐系统能够在用户有了新的行为后及时调整推荐结果，使推荐结果满足用户最近的兴趣；其次，需要保证推荐系统在用户没有新的行为时也能够经常变化一下结果，具有一定的时间多样性。对于第一步，又可以分成两种情况进行分析。第一是从推荐系统的实时性角度分析。有些推荐系统会每天离线生成针对所有用户的推荐结果，然后在线直接将这些结果展示给用户。这种类型的系统显然无法做到在用户有了新行为后及时调整推荐结果。第二，即使是实时推荐系统，由于使用的算法不同，也具有不同的时间多样性。对于不同算法的时间多样性，Neal Lathia博士在博士论文中进行了深入探讨(参见Neal Lathia的“Evaluating Collaborative Filtering Over Time”， 论文链接为http://www.cs.ucl.ac.uk/staff/n.lathia/thesis.html )。 紧接着需要思考的问题就是如果用户没有行为，如何保证给用户的推荐结果具有一定的时间多样性呢？一般的思路有以下几种。 在生成推荐结果时加入一定的随机性。比如从推荐列表前20个结果中随机挑选10个结果 展示给用户，或者按照推荐物品的权重采样10个结果展示给用户。 记录用户每天看到的推荐结果，然后在每天给用户进行推荐时，对他前几天看到过很多次的推荐结果进行适当地降权。 每天给用户使用不同的推荐算法。 当然，时间多样性也不是绝对的。推荐系统需要首先保证推荐的精度，在此基础上适当地考虑时间多样性。在实际应用中需要通过多次的实验才能知道什么程度的时间多样性对系统是最好的。 5.1.6 时间上下文推荐算法上一节介绍了很多时间效应，本节主要讨论如何将这些时间效应应用到系统中。建模时间信息有很多方法，本节分别介绍了不同的方法，并通过实验对比这些方法。 1.最近热门在没有时间信息的数据集中，可以给用户推荐历史上最热门的物品。在获得用户行为的时间信息后，就可以给用户推荐最近最热门的物品了。给定时间$T$，物品$i$最近的流行度$n_i(T)$可以定义为：$$n_i(T) = \sum_{(u,i,t) \in \text{Train}, t&lt;T} \frac{1}{1 + \alpha(T-t)}$$$\alpha$是时间衰减参数。下面的Python代码实现了上面的计算公式。1234567def RecentPopularity(records, alpha, T): ret = dict() for user,item,tm in records: if tm &gt;= T: continue addToDict(ret, item, 1 / (1.0 + alpha * (T - tm))) return ret 2.时间上下文相关的ItemCF算法基于物品（item-based）的个性化推荐算法是商用推荐系统中应用最广泛的，从前面几章的讨论可以看到，该算法由两个核心部分构成： 利用用户行为离线计算物品之间的相似度； 根据用户的历史行为和物品相似度矩阵，给用户做在线个性化推荐。 时间信息在上面两个核心部分中都有重要的应用，这体现在两种时间效应上。 物品相似度 用户在相隔很短的时间内喜欢的物品具有更高相似度。 在线推荐 用户近期行为相比用户很久之前的行为，更能体现用户现在的兴趣。因此在预测用户现在的兴趣时，应该加重用户近期行为的权重，优先给用户推荐那些和他近期喜欢的物品相似的物品。 首先回顾一下前面提到的基于物品的协同过滤算法，它通过如下公式计算物品的相似度：$$sim(i,j) = \frac{\sum_{u \in N(i) \cap N(j)}1}{\sqrt{\vert N(i) \vert \vert N(j)\vert}}$$而在给用户$u$做推荐时，用户$u$对物品$i$的兴趣$p(u,i)$通过如下公式计算：$$p(u,i) = \sum_{j \in N(u)} sim(i,j)$$在得到时间信息（用户对物品产生行为的时间）后，可以通过如下公式改进相似度计算：$$sim(i,j) = \frac{\sum_{u \in N(i)\cap N(j)} f(\vert t_{ui} - t_{uj} \vert)}{\sqrt{\vert N(i) \vert \vert N(j) \vert}}$$注意，上面的公式在分子中引入了和时间有关的衰减项$f(\vert t_{ui} - t_{uj} \vert)$，其中$t_{ui}$是用户$u$对物品$i$产生行为的时间。$f$函数的含义是，用户对物品$i$和物品$j$产生行为的时间越远，则$f(\vert t_{ui} - t_{uj} \vert)$越小。实际上有很多数学衰减函数，本节使用如下衰减函数：$$f(\vert t_{ui} - t_{uj} \vert)=\frac{1}{1 + \alpha \vert t_{ui} - t_{uj} \vert}$$$\alpha$是时间衰减参数，它的取指在不同系统中不同。如果一个系统用户兴趣变化很快，就应该 取比较大的$\alpha$，反之需要取比较小的$\alpha$。 改进后ItemCF的相似度可以通过如下代码实现： 123456789101112131415161718def ItemSimilarity(train, alpha): #calculate co-rated users between items C = dict() N = dict() for u, items in train.items(): for i,tui in items.items(): N[i] += 1 for j,tuj in items.items(): if i == j: continue C[i][j] += 1 / (1 + alpha * abs(tui - tuj)) #calculate finial similarity matrix W W = dict() for i,related_items in C.items(): for j, cij in related_items.items(): W[u][v] = cij / math.sqrt(N[i] * N[j]) return W 除了考虑时间信息对相关表的影响，也应该考虑时间信息对预测公式的影响。一般来说， 用户现在的行为应该和用户最近的行为关系更大。因此，可以通过如下方式修正预测公式：$$p(u,i) = \sum_{j \in N(u) \cap S(i,k)} sim(i,j) \frac{1}{1+ \beta \vert t_0 - t_{uj} \vert}$$其中，$t_0$是当前时间。上面的公式表明，$t_{uj}$越靠近$t_0$，和物品$j$相似的物品就会在用户$u$的推荐列表中获得越高的排名。$\beta$是时间衰减参数，需要根据不同的数据集选择合适的值。上面的推荐算法可以通过如下代码实现。 12345678def Recommendation(train, user_id, W, K, t0): rank = dict() ru = train[user_id] for i,pi in ru.items(): for j, wj in sorted(W[i].items(), \ key=itemgetter(1), reverse=True)[0:K]: if j,tuj in ru.items(): continue rank[j] += pi * wj / (1 + alpha * (t0 - tuj)) return rank 3.时间上下文相关的UserCF算法和ItemCF算法一样，UserCF算法同样可以利用时间信息提高预测的准确率。首先，回顾一下前面关于UserCF算法的基本思想：给用户推荐和他兴趣相似的其他用户喜欢的物品。从这个基本思想出发，可以在以下两个方面利用时间信息改进UserCF算法。 用户兴趣相似度 如果两个用户同时喜欢相同的物品，那么 这两个用户应该有更大的兴趣相似度。 相似兴趣用户的最近行为 应该给用户推荐和他兴趣相似的用户最近喜欢的物品。 回顾一下UserCF的推荐公式。UserCF通过如下公式计算用户$u$和用户$v$的兴趣相似度：$$w_{uv} = \frac{\vert N(u) \cap N(v) \vert}{\sqrt{\vert N(u) \vert \cup \vert N(u) \vert}}$$其中$N(u)$是用户$u$喜欢的物品集合，$N(v)$是用户$v$喜欢的物品集合。可以利用如下方式考虑时间信息：$$w_{uv} = \frac{\sum_{i \in N(u) \cap N(v)} \frac{1}{1 +\alpha \vert t_{ui} - t_{vi} \vert}}{\sqrt{\vert N(u) \vert \cup \vert N(u) \vert}}$$上面公式的分子对于用户$u$和用户$v$共同喜欢的物品$i$增加了一个时间衰减因子。用户$u$和用户$v$对物品$i$产生行为的时间越远，那么这两个用户的兴趣相似度就会越小。 1234567891011121314151617181920212223242526def UserSimilarity(train): # build inverse table for item_users item_users = dict() for u, items in train.items(): for i,tui in items.items(): if i not in item_users: item_users[i] = dict() item_users[i][u] = tui #calculate co-rated items between users C = dict() N = dict() for i, users in item_users.items(): for u,tui in users.items(): N[u] += 1 for v,tvi in users.items(): if u == v: continue C[u][v] += 1 / (1 + alpha * abs(tui - tvi)) #calculate finial similarity matrix W W = dict() for u, related_users in C.items(): for v, cuv in related_users.items(): W[u][v] = cuv / math.sqrt(N[u] * N[v]) return W 在得到用户相似度后，UserCF通过如下公式预测用户对物品的兴趣：$$p(u,i) = \sum_{v \in S(u,K)} w_{uv} r_{vi}$$其中，$S(u,K)$包含了和用户$u$兴趣最接近的$K$个用户。如果用户$v$对物品$i$产生过行为，那么$r_{vi}=1$，否则$r_{vi} = 0$。 如果考虑和用户$u$兴趣相似用户的最近兴趣，可以设计如下公式：$$p(u,i) = \sum_{v \in S(u,K)} w_{uv} r_{vi} \frac{1}{1 + \alpha(t_0 + t_{vi})}$$ 12345678910def Recommend(user, T, train, W): rank = dict() interacted_items = train[user] for v, wuv in sorted(W[u].items, key=itemgetter(1), reverse=True)[0:K]: for i, tvi in train[v].items: if i in interacted_items: #we should filter items user interacted before continue rank[i] += wuv / (1 + alpha * (T - tvi)) return rank 5.1.7 时间段图模型本书的作者在KDD会议上曾经提出过一个时间段图模型(参见Liang Xiang、Quan Yuan、Shiwan Zhao、Li Chen、Xiatian Zhang、Qing Yang和Jimeng Sun的“Temporal recommendation on graphs via long- and short-term preference fusion”（ACM 2010 Article，2010）)，试图解决如何将时间信息建模到图模型中的方法，最终取得了不错的效果。时间段图模型$G (U , S_U , I , S_I , E , w,\sigma )$也是一个二分图。$U$是用户节点集合，$S_U$是用户时间段节点集合。一个用户时间段节点$v_{ut} \in S_U$会和用户$u$在时刻$t$喜欢的物品通过边相连。$I$是物品节点集合，$S_I$是物品时间段节点集合。一个物品时间段节点 $v_{it} \in S_I$会和所有在时刻$t$喜欢物品$i$的用户通过边相连。$E$是边集合，它包含了3种边：(1)如果用户$u$对物品$i$有行为，那么存在边$e(v_u,v_i) \in E$；(2)如果用户$u$在$t$时刻对物品$i$有行为，那么就存在两条边$e(v_{ut},v_i )$, $e(v_u, v_{it} ) \in E$。$w(e)$定义了边的权重，$\sigma (e)$定义了顶点的权重。 定义完图的结构后，最简单的想法是可以利用前面提到的PersonalRank算法给用户进行个性化推荐。但是因为这个算法需要在全图上进行迭代计算，所以时间复杂度比较高。因此作者提出了一种称为路径融合算法的方法，通过该算法来度量图上两个顶点的相关性。一般来说，图上两个相关性比较高的顶点一般具有如下特征： 两个顶点之间有很多路径相连； 两个顶点之间的路径比较短； 两个顶点之间的路径不经过出度比较大的顶点。 从这3条原则出发，路径融合算法首先提取出两个顶点之间长度小于一个阈值的所有路径，然后根据每条路径经过的顶点给每条路径赋予一定的权重，最后将两个顶点之间所有路径的权重之和作为两个顶点的相关度。 假设$P={v_1,v_2,···,v_N}$是连接顶点$v_1$和$v_n$的一条路径，这条路径的权重$\Gamma(P)$取决于这条路径经过的所有顶点和边：$$\Gamma(p) = \sigma(v_n) \prod_{i=1}^{n-1} \frac{\sigma (v_i) \cdot w(v_I,v_{i+1})}{\vert out(v_i) \vert^\rho}$$这里$out(v)$是顶点$v$指向的顶点集合，$|out(v)|$是顶点$v$的出度，$\sigma(v_i) \in (0,1]$定义了顶点的权重，$w(v_i,v_{i+1})$定义了边$e(v_i,v_{i+1})$的权重。上面的定义符合上面3条原则的后两条。首先，因为$\frac{\sigma(v_i) \cdot w(v_i,v_{i+1})}{\vert out(v_i)\vert^\rho}$，所以路径越长$n$越大，$\Gamma(P)$就越小。同时，如果路径经过了出度大的顶点v’，那么因为$|out(v’)|$比较大，所以$\Gamma(p)$也会比较小。 在定义了一条路径的权重后，就可以定义顶点之间的相关度。对于顶点$v$和$v’$，令$p(v, v’, K )$为这两个顶点间距离小于K的所有路径，那么这两个顶点之间的相关度可以定义为：$$d(v,v’) = \sum_{P \in P(v,v’,K)} \Gamma(P)$$对于时间段图模型，所有边的权重都定义为1，而顶点的权重$\sigma(v)$定义如下：$$\sigma(v) =\begin{cases}1- \alpha &amp;(v \in U) \\\alpha &amp;(v \in S_U) \\1 - \beta &amp; (v \in I) \\\beta &amp; (v \in S_I)\end{cases}$$$\alpha,\beta \in [0,1]$是两个参数，控制了不同顶点的权重。 路径融合算法可以基于图上的广度优先搜索算法实现，下面的Python代码简单实现了路径融合算法。 1234567891011121314151617181920212223def PathFusion(user, time,G,alpha) Q = [] V = set() depth = dict() rank = dict() depth['u:' + user] = 0 depth['ut:' + user + '_' + time] = 0 rank ['u:' + user] = alpha rank ['ut:' + user + '_' + time] = 1 - alpha Q.append('u:' + user) Q.append('ut:' + user + '_' + time) while len(Q) &gt; 0: v = Q.pop() if v in V: continue if depth[v] &gt; 3: continue for v2,w in G[v].items(): if v2 not in V: depth[v2] = depth[v] + 1 Q.append(v2) rank[v2] = rank[v] * w return rank 5.1.8 离线实验为了证明时间上下文信息对推荐系统至关重要，本节利用了离线实验对比使用时间信息后不同推荐算法的离线性能，感兴趣的看一下书。 5.2 地点上下文信息除了时间，地点作为一种重要的空间特征，也是一种重要的上下文信息。不同地区的用户兴趣有所不同，用户到了不同的地方，兴趣也会有所不同。 西班牙电信的研究人员曾经设计过一个基于位置的电影推荐系统，并且提供了详细的技术报告(参见“Geolocated Recommendations”，地址为http://xavier.amatriain.net/pubs/GeolocatedRecommendations.pdf )。该报告详细地介绍了如何在iPhone上开发一个推荐系统，如何在电影推荐中融入用户的位置信息，感兴趣的读者可以仔细阅读他们的报告。 基于位置的推荐算法明尼苏达大学的研究人员提出过一个称为LARS（Location Aware Recommender System,位置感知推荐系统）的和用户地点相关的推荐系统。该系统首先将物品分成两类，一类是有空间属性的，比如餐馆、商店、旅游景点等，另一类是无空间属性的物品，比如图书和电影等。同时，它将用户也分成两类，一类是有空间属性的，比如给出了用户现在的地址（国家、城市、邮编等）， 另一类用户并没有相关的空间属性信息。它使用的数据集有3种不同的形式。 （用户，用户位置，物品，评分），每一条记录代表了某一个地点的用户对物品的评分。它们使用的是MovieLens数据集。该数据集给出了用户的邮编，从而可以知道用户的大致地址。 （用户，物品，物品位置，评分），每一条记录代表了用户对某个地方的物品的评分。LARS使用了FourSquare的数据集，该数据集包含用户对不同地方的餐馆、景点、商店的评分 （用户，用户位置，物品，物品位置，评分），每一条记录代表了某个位置的用户对某个位置的物品的评分。 LARS通过研究前两种数据集，发现了用户兴趣和地点相关的两种特征。 兴趣本地化 不同地方的用户兴趣存在着很大的差别。不同国家和地区用户的兴趣存在着一定的差异性。 活动本地化 一个用户往往在附近的地区活动。通过分析Foursqure的数据，研究人员发现45%的用户其活动范围半径不超过10英里，而75%的用户活动半径不超过50英里。 对于第一种数据集，LARS的基本思想是将数据集根据用户的位置划分成很多子集。因为位置信息是一个树状结构，比如国家、省、市、县的结构。因此，数据集也会划分成一个树状结构。然后，给定每一个用户的位置，可以将他分配到某一个叶子节点中，而该叶子节点包含了所有和他同一个位置的用户的行为数据集。然后，LARS就利用这个叶子节点上的用户行为数据，通过ItemCF给用户进行推荐。 不过这样做的缺点是，每个叶子节点上的用户数量可能很少，因此他们的行为数据可能过于稀疏，从而无法训练出一个好的推荐算法。为此，我们可以从根节点出发，在到叶子节点的过程中，利用每个中间节点上的数据训练出一个推荐模型，然后给用户生成推荐列表。而最终的推荐结果是这一系列推荐列表的加权。文章的作者将这种算法成为金字塔模型，而金字塔的深度影响了推荐系统的性能，因而深度是这个算法的一个重要指标。下文用LARS-U代表该算法，书中有关于该算法的简单例子。 对于第二种数据集，每条用户行为表示为四元组（用户、物品、物品位置、评分），表示了用户对某个位置的物品给了某种评分。对于这种数据集，LARS会首先忽略物品的位置信息，利用ItemCF算法计算用户$u$对物品$i$的兴趣$P(u,i)$，但最终物品$i$在用户$u$的推荐列表中的权重定义为：$$RecScore(u,i) = P(u,i) - TravelPenalty(u,i)$$在该公式中，$TravelPenalty(u,i)$表示了物品$i$的位置对用户$u$的代价。 计算 $TravelPenalty(u,i)$的基本思想是对于物品$i$与用户$u$之前评分的所有物品的位置计算距离的平均值 （或者最小值）。关于如何度量地图上两点的距离，最简单的是基于欧式距离(参见Gísli R. Hjaltason和Hanan Samet的“Distance browsing in spatial databases”（ACM 1999 Article，1999）)。当然，欧式距离有明显的缺点，因为人们是不可能沿着地图上的直线距离从一点走到另一点的。比较好的度量方式是利用交通网络数据，将人们实际需要走的最短距离作为距离度量(参见Jie Bao、Chi-Yin Chow、Mohamed F. Mokbel和Wei-Shinn Ku的“Efficient Evaluation of k-Range Nearest Neighbor Queries in Road Networks”（MDM，2012）)。 为了避免计算用户对所有物品的$TravelPenalty$，LARS在计算用户$u$对物品$i$的兴趣度$RecScore(u,i)$时，首先对用户每一个曾经评过分的物品（一般是餐馆、商店、景点），找到和他距离小于一个阈值$d$的所有其他物品，然后将这些物品的集合作为候选集，然后再利用上面的公式计算最终的$RecScore$。 对于第三种数据集，LARS一文没有做深入讨论。不过，从第三种数据集的定义可以看到， 它相对于第二种数据集增加了用户当前位置这一信息。而在给定了这一信息后，应该保证推荐的物品应该距离用户当前位置比较近，在此基础上再通过用户的历史行为给用户推荐离他近且他会感兴趣的物品。 为了证明兴趣本地化和活动本地化两种效应，论文作者在FourSquare和MovieLens两个数据集上进行了离线实验。论文作者使用TopN推荐的Precision作为评测指标。 作者首先在FourSquare数据集上对比了ItemCF算法和考虑了TravelPenalty之后的算法（简称为LARS-T）。结果证明考虑TravelPenality确实能够提高TopN推荐的离线准确率，LARS-T算法明显优于ItemCF算法。 然后，作者在FourSquare数据集和MovieLens数据集上对比了普通的ItemCF算法和考虑用户位置的金字塔模型后的LARS-U算法。同时，作者对比了不同深度对LARS-U算法的影响。实验表明，选择合适的深度对LARS-U算法很重要，不过在绝大多数深度的选择下，LARS-U算法在两个数据集上都优于普通的ItemCF算法。 5.3 扩展阅读时间上下文信息在Netflix Prize中得到了广泛关注，很多参赛者都研究了如何利用这一信息。这方面最著名的文章无疑是Koren的“collaborative filtering with temporal dynamics”，该文系统地总结了各种使用时间信息的方式，包括考虑用户近期行为的影响，考虑时间的周期性等。 英国剑桥大学的Neal Lathia在读博士期间对时间上下文信息以及推荐系统的时间效应进行了深入研究。他在“Temporal Diversity in Recommender Systems”一文中深入分析了时间多样性对推荐系统的影响。他的博士论文“Evaluating Collaborative Filtering Over Time”论述了各种不同推荐算法是如何随时间演化的。 如果要系统地研究与上下文推荐相关的工作， 可以参考Alexander Tuzhili 教授的工作（http://pages.stern.nyu.edu/~atuzhili/ ），他在最近几年和学生对上下文推荐问题进行了深入研究。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（四）]]></title>
    <url>%2F2018%2F11%2F27%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第4章 利用用户标签数据GroupLens在一篇文章中(文章名是“Tagsplanations : Explaining Recommendations using Tags”)表示目前流行的推荐系统基本上通过3种方式联系用户兴趣和物品。 基于物品的算法 比如UserCF 基于用户的算法 比如ItemCF 基于特征的算法 比如隐语义模型 本章将讨论一种重要的特征表现方式——标签。根据维基百科的定义(参见http://en.wikipedia.org/wiki/Tag_(metadata) )，标签是一种无层次化结构的、用来描述信息的关键词，它可以用来描述物品的语义。根据给物品打标签的人的不同，标签应用一般分为两种：一种是让作者或者专家给物品打标签；另一种是让普通用户给物品打标签，也就是UGC(User Generated Content，用户生成的内容)的标签应用。UGC的标签系统是一种表示用户兴趣和物品语义的重要方式。当一个用户对一个物品打上一个标签，这个标签一方面描述了用户的兴趣，另一方面则表示了物品的语义，从而将用户和物品联系了起来。本章主要讨论UGC的标签应用，研究用户给物品打标签的行为，探讨如何通过分析这种行为给用户进行个性化推荐。 4.1 UGC标签系统的代表应用4.1.1 DeliciousDelicious允许用户给互联网上的每个网页打标签，从而通过标签重新组织整个互联网。 4.1.2 CiteULikeCiteULike是一个著名的论文书签网站，它允许研究人员提交或者收藏自己感兴趣的论文并且给论文打标签，从而帮助用户更好地发现和自己研究领域相关的优秀论文。 4.1.3 Last.fmLast.fm在前面已经介绍过，是一家著名的音乐网站，它通过分析用户的听歌行为预测用户对音乐的兴趣，从而给用户推荐个性化的音乐。 4.1.4 豆瓣豆瓣允许用户对图书和电影打标签，借此获得图书和电影的内容信息和语义，并用这种信息改善推荐效果。 4.1.5 HuluHulu是美国著名的视频网站。视频作为一种最为复杂的多媒体，获取它的内容信息是最困难的，因此Hulu也引入了用户标签系统来让用户对电视剧和电影进行标记。 总结以上标签系统的各种应用，标签系统的最大优势在于可以发挥群体的智能，获得对物品内容信息比较准确的关键词描述，而准确的内容信息是提升个性化推荐系统性能的重要资源。 关于标签系统的作用， GroupLen的Shilads Wieland Sen在MoveLens电影推荐系统上做了更为深入的、基于问卷调查的研究。在博士论文(博士论文为“Nurturing Tagging Communities”)中，他探讨了标签系统的不同作用，以及每种作用能够影响多大的人群，如下所示。 表达 标签系统帮助我表达对物品的看法。（30%的用户同意。） 组织 打标签帮助我组织我喜欢的电影。（23%的用户同意。） 学习 打标签帮助我增加对电影的了解。（27%的用户同意。） 发现 标签系统使我更容易发现喜欢的电影。（19%的用户同意。） 决策 标签系统帮助我判定是否看某一部电影。（14%的用户同意。） 上面的研究表明，标签系统确实能够帮助用户发现可能喜欢的电影。 4.2 标签系统中的推荐问题标签系统中的推荐问题主要有以下两个。 如何利用用户打标签的行为为其推荐物品（基于标签的推荐）？ 如何在用户给物品打标签时为其推荐适合该物品的标签（标签推荐）？ 为了研究上面的问题，首先需要解答下面3个问题。 用户为什么要打标签？ 用户怎么打标签？ 用户打什么样的标签？ 4.2.1 用户为什么进行标注Morgan Ames研究图片分享网站中用户标注的动机问题，并从两个维度进行探讨(参见Morgan Ames和 Mor Naaman的“Why we tag: motivations for annotation in mobile and online media”（ CHI 2007，2007）)。首先是社会维度，有些用户标注是给内容上传者使用的（便于上传者组织自己的信息），而有些用户标注是给广大用户使用的（便于帮助其他用户找到信息）。另一个维度是功能维度，有些标注用于更好地组织内容，方便用户将来的查找，而另一些标注用于传达某种信息，比如照片的拍摄时间和地点等。 4.2.2 用户如何打标签该节通过研究Delicious数据集总结用户标注行为中的一些统计规律，即标签的流行度分布同用户活跃度、物品流行度分布一致都遵循长尾分布(Power Law分布)，实验具体过程见书。 4.2.3 用户打什么样的标签用户在对物品打标签时，可能并非如我们希望地提供能够准确描述物品内容属性的关键词，而是各种奇怪的标签。 Delicious上的标签分类Scott A. Golder 总结了Delicious上的标签，将它们分为如下几类。 表明物体是什么 表明物品的种类 表明谁拥有物品 表达用户的观点 用户相关的标签 用户的任务 Hulu上的标签分类 类型(Genre) 主要表示这个电视剧的类别。 时间(Time) 主要包括电视剧的发布的时间，有时也包括电视剧中事件发生的时间。 人物(People) 主要包括电视剧的导演、演员和剧中重要人物等。 地点(Place) 剧情发生的地点，或者视频拍摄的地点等。 语言(Language) 这部电视剧使用的语言。 奖项(Awards) 这部电视剧获得的相关奖项。 其他(Details) 包含不能归类到上面各类中的其他所有标签。 4.3 基于标签的推荐系统一个用户标签行为的数据集一般由一个三元组的集合表示，其中记录$(u, i, b)$表示用户$u$给物品$i$打上了标签$b$。当然，用户的真实标签行为数据远远比三元组表示的要复杂，比如用户打标签的时间、用户的属性数据、物品的属性数据等。但是本章为了集中讨论标签数据，只考虑上面定义的三元组形式的数据，即用户的每一次打标签行为都用一个三元组（用户、物品、标签）表示。 本章将采用两个不同的数据集评测基于标签的物品推荐算法。一个是Delicious数据集，另一个是CiteULike数据集。Delicious数据集中包含用户对网页的标签记录。它每一行由4部分组成，即时间、用户ID、网页URL、标签。CiteULike数据集包含用户对论文的标签记录，它每行也由4部分组成，即物品ID、用户ID、时间、标签。 4.3.1 实验设置本节将数据集随机分成10份。这里分割的键值是用户和物品，不包括标签。也就是说，用户对物品的多个标签记录要么都被分进训练集，要么都被分进测试集，不会一部分在训练集，另一部分在测试集中。然后，我们挑选1份作为测试集，剩下的9份作为训练集，通过学习训练集中的用户标签数据预测测试集上用户会给什么物品打标签。对于用户$u$，令$R(u)$为给用户$u$的长度为$N$的推荐列表，里面包含我们认为用户会打标签的物品。令$T(u)$是测试集中用户$u$实际上打过标签的物品集合。然后，利用准确率(precision)和召回率(recall)评测个性化推荐算法的精度。将上面的实验进行10次，每次选择不同的测试集，然后将每次实验的准确率和召回率的平均值作为最终的评测结果。 为了全面评测个性化推荐的性能，实验同时评测了推荐结果的覆盖率(coverage)、多样性(diversity)和新颖度。 关于多样性，在第1章中讨论过，多样性的定义取决于相似度的定义。在本章中，实验用物品标签向量的余弦相似度度量物品之间的相似度。对于每个物品$i$，item_tags[i]存储了物品$i$的标签向量，其中item_tags[i][b]是对物品$i$打标签$b$的次数，那么物品$i$和$j$的余弦相似度可以通过如下程序计算。 1234567891011121314def CosineSim(item_tags, i, j): ret = 0 for b,wib in item_tags[i].items(): if b in item_tags[j]: ret += wib * item_tags[j][b] ni = 0 nj = 0 for b, w in item_tags[i].items(): ni += w * w for b, w in item_tags[j].items(): nj += w * w if ret == 0: return 0 return ret / math.sqrt(ni * nj) 在得到物品之间的相似度度量后，通过如下公式计算一个推荐列表的多样性。$$Diversity = 1 - \frac {\sum_{i \in R(u)} \sum_{j \in R(u),j \neq i} \text{Sim(item_tags[i],item_tags[j])}}{\begin{pmatrix}\vert R(u) \vert \\2 \\\end{pmatrix}}$$ 如果用程序实现，代码如下：12345678910def Diversity(item_tags, recommend_items): ret = 0 n = 0 for i in recommend_items.keys(): for j in recommend_items.keys(): if i == j: continue ret += CosineSim(item_tags, i, j) n += 1 return ret / (n * 1.0) 推荐系统的多样性为所有用户推荐列表多样性的平均值。 至于推荐结果的新颖性，可以简单地用推荐结果的平均热门程度(AveragePopularity)度量。 对于物品$i$，定义它的流行度item_pop(i)为给这个物品打过标签的用户数。而对推荐系统，定义它的平均热门度如下：$$Average Popularity = \frac {\sum_u \sum_{i \in R(u)} \log(1 + \text{item_pop(i))}}{\sum_u \sum_{i \in R(u)}1}$$ 4.3.2 一个最简单的算法拿到了用户标签行为数据后，最简单的个性化推荐算法描述如下： 统计每个用户最常用的标签 对于每个标签，统计被打过这个标签次数最多的物品。 对于一个用户，首先找到他常用的标签，然后找到具有这些标签的最热门物品推荐给这个用户。 对于上面的算法，用户 $u$ 对物品 $i$ 的兴趣公式如下：$$p(u,i) = \sum_b n_{u,b}n_{b,i}$$ $B(u)$是用户$u$打过的标签集合，$B(i)$是物品$i$被打过的标签集合，$n_{u,b}$是用户$u$打过标签$b$的次数，$n_{b,i}$是物品$i$被打过标签$b$的次数。本章用SimpleTagBased标记这个算法。 在Python中，遵循如下规定： 用records存储标签数据的三元组，其中records[i] = [user, item, tag]； 用user_tags存储$n_{u,b}$，其中user_tags[u][b] = $n_{u,b}$； 用tags_items存储$n_{b,i}$，其中tags_item[b][i] = $n_{b,i}$ ； 如下程序可以从records中统计出user_tags和tag_items:12345678def InitStat(records): user_tags = dict() tag_items = dict() user_items = dict() for user, item, tag in records.items(): addValueToMat(user_tags, user, tag, 1) addValueToMat(tag_items, tag, item, 1) addValueToMat(user_items, user, item, 1) 统计出user_tags和tag_items之后，可以通过如下程序对用户进行个性化推荐：12345678910111213def Recommend(user): recommend_items = dict() tagged_items = user_items[user] for tag, wut in user_tags[user].items(): for item, wti in tag_items[tag].items(): #if items have been tagged, do not recommend them if item in tagged_items: continue if item not in recommend_items: recommend_items[item] = wut * wti else: recommend_items[item] += wut * wti return recommend_items 4.3.3 算法的改进1.TF-IDF前面这个公式倾向于给热门标签对应的热门物品很大的权重，因此会造成推荐热门的物品给用户，从而降低推荐结果的新颖性。另外，这个公式利用用户的标签向量对用户兴趣建模，其中每个标签都是用户使用过的标签，而标签的权重是用户使用该标签的次数。这种建模方法的缺点是给热门标签过大的权重，从而不能反应用户个性化的兴趣。这里我们可以借鉴TF-IDF的思想， 对这一公式进行改进：$$p(u,i) = \sum_b \frac{n_{u,b}}{\log(1+ n_b^{(u)})} n_{b,i}$$$n_b^{(u)}$记录了标签$b$被多少个不同的用户使用过。这个算法记为TagBasedTFIDF。通过TagBasedTFIDF在Delicious和CiteULike两个数据集上的离线实验结果，可知该算法在所有指标上相比SimpleTagBased算法都有提高。 同理，也可以借鉴TF-IDF的思想对热门物品进行惩罚，从而得到如下公式：$$p(u,i) = \sum_b \frac{n_{u,b}}{\log(1+n_b^{(u)})}\frac{n_{b,i}}{\log(1+n_i^{(u)})}$$$n_i^{(u)}$记录了物品$i$被多少个不同的用户打过标签。这个算法记为TagBasedTFIDF++。同样通过离线实验证明和TagBasedTFIDF算法相比，除了多样性有所下降，其他指标都有明显提高。这一结果表明，适当惩罚热门标签和热门物品，在增进推荐结果个性化的同时并不会降低推荐结果的离线精度。 2.数据稀疏性对于新用户或者新物品，$B(u) \cap B(i)$中的标签数量会很少。为了提高推荐的准确率，可能要对标签集合做扩展。进行标签扩展有很多方法，其中常用的有话题模型(topic model)，不过这里遵循简单的原则介绍一种基于邻域的方法。标签扩展的本质是对每个标签找到和它相似的标签，也就是计算标签之间的相似度。最简单的相似度可以是同义词。如果有一个同义词词典，就可以根据这个词典进行标签扩展。如果没有这个词典，可以从数据中统计出标签的相似度。如果认为同一个物品上的不同标签具有某种相似度，那么当两个标签同时出现在很多物品的标签集合中时，就可以认为这两个标签具有较大的相似度。对于标签$b$，令$N(b)$为有标签$b$的物品的集合，$n_{b,i}$为给物品$i$打上标签$b$的用户数，可以通过如下余弦相似度公式计算标签$b$和标签$b’$的相似度：$$sim(b,b’) = \frac{\sum_{i \in N(b) \cap N(b’)} n_{b,i} n_{b’,i}}{\sqrt{\sum_{i \in N(b)}n_{b,i}^2 \sum_{i \in N(b’)} n_{b’,i}^2} }$$实验表明，进行标签扩展确实能够提高基于标签的物品推荐的准确率和召回率，但可能会稍微降低推荐结果的覆盖率和新颖度。 3.标签清理不是所有标签都能反应用户的兴趣。同时，标签系统里经常出现词形不同、词义相同的标签。 标签清理的另一个重要意义在于将标签作为推荐解释。如果要把标签呈现给用户，将其作为给用户推荐某一个物品的解释，对标签的质量要求就很高。首先，这些标签不能包含没有意义的停止词或者表示情绪的词，其次这些推荐解释里不能包含很多意义相同的词语。 一般来说有如下标签清理方法： 去除词频很高的停止词； 去除因词根不同造成的同义词，比如recommender system和recommendation system； 去除因分隔符造成的同义词，比如collaborative_filtering和collaborative-filtering； 为了控制标签的质量，很多网站也采用了让用户进行反馈的思想，即让用户告诉系统某个标签是否合适。MovieLens在实验系统中就采用了这种方法。关于这方面的研究可以参考GroupLens 的Shilad Wieland Sen同学的博士论文(参见Shilad Wieland Sen的“ Nurturing Tagging Communities”) 。 4.3.4 基于图的推荐算法前面讨论的简单算法很容易懂，也容易实现，但缺点是不够系统化和理论化。因此考虑利用图模型做基于标签数据的个性化推荐。 首先，需要将用户打标签的行为表示到一张图上。图是由顶点、边和边上的权重组成的。而在用户标签数据集上，有3种不同的元素，即用户、物品和标签。因此，需要定义3种不同的顶点，即用户顶点、物品顶点和标签顶点。然后，如果我们得到一个表示用户$u$给物品$i$打了标签$b$的用户标签行为$(u,i,b)$，那么最自然的想法就是在图中增加3条边，首先需要在用户u对应的顶点$v(u)$和物品i对应的顶点$v(i)$之间增加一条边（如果这两个顶点已经有边相连，那么就应该将边的权重加1），同理，在$v(u)$和$v(b)$之间需要增加一条边，$v(i)$和$v(b)$之间也需要边相连接。 在定义出用户—物品—标签图后，可以用第2章提到的PersonalRank算法计算所有物品节点相对于当前用户节点在图上的相关性，然后按照相关性从大到小的排序，给用户推荐排名最高的$N$个物品。 用图模型解释前面的简单算法基于图模型重新思考前面的简单算法。 在那个算法中，用户对物品的兴趣公式如下：$$P(i|u) = \sum_b P(i|b)P(b|u)$$这个公式假定用户对物品的兴趣通过标签传递，因此这个公式可以通过一个比本节前面介绍的图更简单的图建模（记为SimpleTagGraph）。给定用户标签行为记录$(u,i,b)$，SimpleTagGraph会增加两条有向边，一条由用户节点$v(u)$指向标签节点$v(b)$，另一条由标签节点$v(b)$指向物品节点$v(i)$。从这个定义可以看到，SimpleTagGraph相对于前面提到用户—物品—标签图少了用户节点和物品节点之间的边。在构建了SimpleTagGraph后， 利用前面的PersonalRank算法，令$K = 1$，并给出不同边权重的定义，就等价于前面提出的简单推荐算法。 4.3.5 基于标签的推荐解释书中这部分首先介绍了豆瓣基于标签的推荐系统，其中豆瓣将推荐结果的可解释性拆分成两部分这个方法值得借鉴，详细内容见书。 GroupLens的研究人员Jesse Vig对基于标签的解释进行了深入研究(参见Jesse Vig、 Shilad Wieland Sen和 John Riedl的“Tagsplanations: Explaining Recommendations Using Tags”（ACM 2009 Article，2009）)。 和4.3.2节提出的算法类似，Jesse Vig将用户和物品之间的关系变成了用户对标签的兴趣(tag preference)和标签与物品的相关度(tag relevance)，然后作者用同一种推荐算法给用户推荐物品，但设计了4种标签解释的展示界面。 RelSort 对推荐物品做解释时使用的是用户以前使用过且物品上有的标签，给出了用户对标签的兴趣和标签与物品的相关度，但标签按照和物品的相关度排序。 PreSort 对推荐物品做解释时使用的是用户以前使用过且物品上有的标签，给出了用户对标签的兴趣和标签与物品的相关度，但标签按照用户的兴趣程度排序。 RelOnly 对推荐物品做解释时使用的是用户以前使用过且物品上有的标签，给出了标签与物品的相关度，且标签按照和物品的相关度排序。 PreOnly 对推荐物品做解释时使用的是用户以前使用过且物品上有的标签，给出了用户对标签的兴趣程度，且标签按照用户的兴趣程度排序。 然后，作者对用户设计了3种调查问卷。首先是关于推荐解释的调查问卷，作者问了如下3个问题： 推荐解释帮助我理解这部电影为什么会被推荐给我：对于这个问题用户认为 RelSort&gt; PrefOnly&gt;=PrefSort&gt;RelOnly。 推荐解释帮助我判定是否喜欢推荐的电影：对于这个问题用户认为 RelSort&gt;PrefSort&gt; PrefOnly&gt;RelOnly。 推荐解释帮助我判定观看这部电影是否符合我现在的兴趣：对于这个问题用户认为RelSort&gt;PrefSort&gt;RelOnly &gt;PrefOnly。 然后，作者调查了用户对不同类型标签的看法。作者将标签分为主观类（比如对电影的看法）和客观类（比如对电影内容的描述）。作者对每种类型的标签同样问了上面3个问题。 这个标签帮助我理解这部电影为什么会被推荐给我：用户认为客观类标签优于主观类标签。 这个标签帮助我判定是否喜欢推荐的电影：用户认为客观类标签优于主观类标签。 这个标签帮助我判定观看这部电影是否符合我现在的兴趣：用户认为客观类标签优于主观类标签。 从上面的结果可以发现，客观事实类的标签优于主观感受类标签。最后，作者询问了用户对4种不同推荐解释界面的总体满意度，结果显示PrefOnly &gt; RelSort &gt; PrefSort &gt; RelOnly。 总结问卷调查的结果，作者得出了以下结论： 用户对标签的兴趣对帮助用户理解为什么给他推荐某个物品更有帮助； 用户对标签的兴趣和物品标签相关度对于帮助用户判定自己是否喜欢被推荐物品具有同样的作用； 物品标签相关度对于帮助用户判定被推荐物品是否符合他当前的兴趣更有帮助； 客观事实类标签相比主观感受类标签对用户更有作用。 4.4 给用户推荐标签4.4.1 为什么要给用户推荐标签一般认为，给用户推荐标签有以下好处。 方便用户输入标签 从键盘输入标签会增加用户打标签的难度，推荐标签则可以降低难度，从而提高用户打标签的参与度。 提高标签质量 同一个语义不同的用户可能用不同的词语来表示。这些同义词会使标签的词表变得很庞大，而且会使计算相似度不太准确。而使用推荐标签时，可以对词表进行选择，首先保证词表不出现太多的同义词，同时保证出现的词都是一些比较热门的、有代表性的词。 4.4.2 如何给用户推荐标签推荐标签的方法中比较简单的有4种。第0种方法(最简单的方法)就是给用户$u$推荐整个系统里最热门的标签（这里将这个算法称为PopularTags）令tags[b]为标签$b$的热门程度，算法的实验方法如下： 12def RecommendPopularTags(user,item, tags, N): return sorted(tags.items(), key=itemgetter(1), reverse=True)[0:N] 第1种方法就是给用户$u$推荐物品$i$上最热门的标签（这里将这个算法称为ItemPopularTags）。令item_tags[i][b]为物品$i$被打上标签$b$的次数，这个算法的实现具体如下所示： 12def RecommendItemPopularTags(user,item, item_tags, N): return sorted(item_tags[item].items(), key=itemgetter(1), reverse=True)[0:N] 第2种方法是给用户$u$推荐他自己经常使用的标签（这里将这个算法称为UserPopularTags）。令user_tags[u][b]为用户$u$使用标签$b$的次数，这个算法的实现如下所示：12def RecommendUserPopularTags(user,item, user_tags, N): return sorted(user_tags[user].items(), key=itemgetter(1), reverse=True)[0:N] 第3种算法是前面两种的融合（这里记为HybridPopularTags），该方法通过一个系数(线性融合系数)将上面的推荐结果线性加权，然后生成最终的推荐结果。这个算法的实现代码如下： 123456789101112def RecommendHybridPopularTags(user,item, user_tags, item_tags, alpha, N): max_user_tag_weight = max(user_tags[user].values()) for tag, weight in user_tags[user].items(): ret[tag] = (1 – alpha) * weight / max_user_tag_weight max_item_tag_weight = max(item_tags[item].values()) for tag, weight in item_tags[item].items(): if tag not in ret: ret[tag] = alpha * weight / max_item_tag_weight else: ret[tag] += alpha * weight / max_item_tag_weight return sorted(ret[user].items(), key=itemgetter(1), reverse=True)[0:N] 注意在上面的实现中，在将两个列表线性相加时都将两个列表按最大值做了归一化，这样的好处是便于控制两个列表对最终结果的影响，而不至于因为物品非常热门而淹没用户对推荐结果的影响，或者因为用户非常活跃而淹没物品对推荐结果的影响。 4.4.3 实验设置和前面的实验一样，用同样的方法将数据集按照9∶1分成训练集和测试集，然后通过训练集学习用户标注的模型。需要注意的是，这里切分数据集不再是以user、item为主键，而是以user、item、tag为主键。为了更好的理解如何切分数据集，请参考下面的Python代码：1234567def SplitData(records, train, test): for user,item, tag in records: if random.randint(1,10) == 1: test.append([user,item,tag]) else: train.append([user,item,tag]) return [train, test] 对于测试集中的每一个用户物品对$(u,i)$，我们都可以推荐$N$个标签给用户$u$作参考。令$R(u,i)$为给用户$u$推荐的应该在物品$i$上打的标签集合，令$T(u,i)$为用户$u$实际给物品$i$打的标签的集合，然后可以利用准确率和召回率评测标签推荐的精度。 实验结果表明，ItemPopularTags具有最好的准确率和召回率。在$α$=0.8($\alpha​$是线性融合稀疏)的时候，HybridPopularTags取得了最好的准确度。而且这个精度超过了单独的ItemPopularTags和UserPopularTags算法的精度。考虑到近70%的精度已经很高了，因此很多应用在给用户推荐标签时会直接给出用户最常用的标 签，以及物品最经常被打的标签。 不过，前面提到的基于统计用户常用标签和物品常用标签的算法有一个缺点，就是对新用户或者不热门的物品很难有推荐结果。解决这一问题有两个思路。第一个思路是从物品的内容数据中抽取关键词作为标签。这方面的研究很多，特别是在上下文广告领域(参见Wen-tau Yih、Joshua Goodman和 Vitor R. Carvalho的“Finding Advertising Keywords on Web Pages”（ACM 2006 Article，2006）)。本书3.4节也介绍了生成关键词向量的一些方法。第二个思路是针对有结果，但结果不太多的情况。可以做一些关键词扩展，加入一些与现有结果相关的标签。实现标签扩展的关键就是计算标签之间的相似度。关于这一点， 4.3.3节已经进行了深入探讨。 4.4.4 基于图的标签推荐算法图模型同样可以用于标签推荐。在根据用户打标签的行为生成图之后，可以利用PersonalRank算法进行排名。但这次遇到的问题和之前不同。这次的问题是，当用户$u$遇到物品$i$时，会给物品$i$打什么样的标签。因此，可以重新定义顶点的启动概率，如下所示：$$r_{v(k)} =\begin{cases}\alpha &amp; {(v(k)= v(u))} \\1 - \alpha &amp; (v(k) = v(i)) \\0 &amp; \text{(其他)}\end{cases}$$只有用户$u$和物品$i$对应的顶点有非0的启动概率，而其他顶点的启动概率都为0。 在上面的定义中，$v(u)$和$v(i)$的启动概率并不相同，$v(u)$的启动概率是$\alpha$，而$v(i)$的启动概率是$1-\alpha$。 参数$\alpha$可以通过离线实验选择。 4.5 扩展阅读本章主要讨论了UGC标签在推荐系统中的应用。标签作为描述语义的重要媒介，无论是对于描述用户兴趣还是表示物品的内容都有很重要的意义。标签在推荐系统中的应用主要集中在两个问题上，一个是如何利用用户打标签的行为给用户推荐物品，另一个是如何给用户推荐标签。本章在深入分析用户标签行为的基础上对这两个问题进行了深入探讨。 关于标签的问题，最近几年在学术界获得了广泛关注。ECML/PKDD在2008年曾经推出过基于标签的推荐系统比赛(1)。 在这些研究中涌现了很多新的方法， 比如张量分解(2)(tensor factorization)、基于LDA的算法(3)、基于图的算法(4)等。不过这些算法很多具有较高的复杂度，在实际系统中应用起来还有很多实际的困难需要解决。GroupLens的研究人员给MovieLens系统做了很多标签方面的工作。Shilad Sen在论文(5)中研究了如何利用标签联系用户和物品并给用户进行个性化电影推荐。Jesse Vig在论文(6)中研究了如何利用标签进行推荐解释，他将用户和物品之间的关系转化为用户对标签的兴趣（tag preference） 以及标签和物品的相关度（tag relevance）两种因素。同时他们研究了如何对标签进行清理(7)，以及如何选择合适的标签进行解释。 (1):比赛介绍见 http://www.kde.cs.uni-kassel.de/ws/rsdc08/program.html。(2):参见Panagiotis Symeonidis、Alexandros Nanopoulos和Yannis Manolopoulos的“Tag recommendations based on tensor dimensionality reduction”（ACM 2008 Article，2008）。(3):参见Ralf Krestel、 Peter Fankhauser和Wolfgang Nejdl的“Latent dirichlet allocation for tag recommendation”（ACM 2009 Article，2009）。(4):参见Andreas Hotho、 Robert Jäschke、 Christoph Schmitz和Gerd Stumme的“Folkrank: A ranking algorithm for folksonomies”（Proc. FGIR 2006，2006）。(5):参见Shilad Wieland Sen、 Jesse Vig和John Riedl的“Tagommenders: Connecting Users to Items through Tags”（ACM 2009 Article，2009）。(6):参见Jesse Vig、Shilad Wieland Sen和John Riedl的“Tagsplanations: Explaining Recommendations Using Tags”（ACM 2009 Article，2009）。(7):参见Shilad Wieland Sen、F. Maxwell Harper、Adam LaPitz和John Riedl的“The quest for quality tags”（ACM 2007 Article，2007）。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（三）]]></title>
    <url>%2F2018%2F11%2F26%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第3章 推荐系统冷启动问题如何在没有大量用户数据的情况下设计个性化推荐系统并且让用户对推荐结果满意从而愿意使用推荐系统，就是冷启动的问题。本章简单介绍一下冷启动问题的分类，以及如何解决不同种类的冷启动问题。 3.1 冷启动问题简介冷启动问题(cold start)主要分3类。 用户冷启动 用户冷启动主要解决如何给新用户做个性化推荐的问题。 物品冷启动 物品冷启动主要解决如何将新的物品推荐给可能对它感兴趣的用户这一问题。 系统冷启动 系统冷启动主要解决如何在一个新开发的网站上（还没有用户，也没有用户行为，只有一些物品的信息）设计个性化推荐系统，从而在网站刚发布时就让用户体验到个性化推荐服务这一问题。 对于这3种不同的冷启动问题，有不同的解决方案。一般来说，可以参考如下解决方案。 提供非个性化的推荐。 非个性化推荐的最简单例子就是热门排行榜。 利用用户注册时提供的年龄、性别等数据做粗粒度的个性化。 利用用户的社交网络账号登录（需要用户授权），导入用户在社交网站上的好友信息，然后给用户推荐其好友喜欢的物品。 要求用户在登录时对一些物品进行反馈，收集用户对这些物品的兴趣信息，然后给用户推荐那些和这些物品相似的物品。 对于新加入的物品，可以利用内容信息，将它们推荐给喜欢过和它们相似的物品的用户。 在系统冷启动时，可以引入专家的知识，通过一定的高效方式迅速建立起物品的相关度表。 3.2 利用用户注册信息用户的注册信息分3种。 人口统计学信息 包括用户的年龄、性别、职业、民族、学历和居住地。 用户兴趣的描述 有一些网站会让用户用文字描述他们的兴趣。 从其他网站导入的用户站外行为数据 比如用户通过豆瓣、新浪微博的账号登录，就可以在得到用户同意的情况下获取用户在豆瓣或者新浪微博的一些行为数据和社交网络数据。 基于人口统计学特征的推荐系统其典型代表是Bruce Krulwich开发的Lifestyle Finder(参见论文Bruce Krulwich的“Lifestyle finder : intelligent user profiling using large scale demographic data”（1997）) 。书上这部分有关于该算法的简略介绍和评测，但并没有涉及该算法是具体如何根据人口统计学属性进行分类的，详情见书。 基于注册信息的个性化推荐流程基本如下： 获取用户的注册信息； 根据用户的注册信息对用户分类； 给用户推荐他所属分类中用户喜欢的物品。 基于用户注册信息的推荐算法其核心问题是计算每种特征的用户喜欢的物品。也就是说，对于每种特征$f$，计算具有这种特征的用户对各个物品的喜好程度$p(f, i)$。$p(f,i)$可以简单地定义为物品$i$在具有$f$的特征的用户中的热门程度：$$p(f,i)=\vert N(i) \cap U(f) \vert$$其中$N(i)$是喜欢物品$i$的用户集合，$U(f)$是具有特征$f$的用户集合。 上面这种定义可以比较准确地预测具有某种特征的用户是否喜欢某个物品。但是，在这种定义下，往往热门的物品会在各种特征的用户中都具有比较高的权重。也就是说具有比较高的$\vert N (i) \vert$的物品会在每一类用户中都有比较高的$p(f ,i)$。给用户推荐热门物品并不是推荐系统的主要任务，推荐系统应该帮助用户发现他们不容易发现的物品。因此，可以将$p( f , i )$定义为喜欢物品$i$的用户中具有特征$f$的比例：$$p(f,i) = \frac {\vert N(i) \cap U(f) \vert}{\vert N(i) \vert + \alpha}$$这里分母中使用参数$\alpha$的目的是解决数据稀疏问题。比如有一个物品只被1个用户喜欢过， 而这个用户刚好就有特征$f$，那么就有$p(f,i)$。但是，这种情况并没有统计意义，因此为分母加上一个比较大的数，可以避免这样的物品产生比较大的权重。 有两个推荐系统数据集包含了人口统计学信息， 一个是 BookCrossing 数据集。另一个是Lastfm数据集。 BookCrossing数据集:参见http://www.informatik.uni-freiburg.de/~cziegler/BX/Lastfm数据集：参见http://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/lastfm-360K.html 作者在这两个数据集上做实验验证，证明基于人口统计学特征的推荐系统准确率、召回率和覆盖率确实更高，而且利用的用户人口统计学特征越多，越能准确地预测用户兴趣，详情见书。 3.3 选择合适的物品启动用户的兴趣对于通过让用户对物品进行评分来收集用户兴趣，从而对用户进行冷启动的系统，它们需要解决的首要问题就是如何选择物品让用户进行反馈。 一般来说，能够用来启动用户兴趣的物品需要具有以下特点。 比较热门 因为用户需要知道这个物品是什么，才能对它们作出准确反馈。 具有代表性和区分性 启动用户兴趣的物品不能是大众化或老少咸宜的，因为这样的物品对用户的兴趣没有区分性。 启动物品集合需要有多样性 冷启动时，由于不清楚用户的兴趣，并且用户用户兴趣的可能性非常多，为了匹配多样的兴趣，为此需要提供具有很高覆盖率的启动物品集合，这些物品能覆盖几乎所有主流的用户兴趣。 上面这些因素都是选择启动物品时需要考虑的，但还需要考虑的是如何设计一个选择启动物品集合的系统？Nadav Golbandi在论文中(“Adaptive Bootstrapping of Recommender Systems Using Decision Trees”，下载地址为 http://research.yahoo.com/pub/3502) 探讨了这个问题，提出可以用一个决策树解决这个问题。首先，给定一群用户，Nadav Golbandi用这群用户对物品评分的方差度量这群用户兴趣的一致程度。如果方差很大，说明这一群用户的兴趣不太一致，反之则说明这群用户的兴趣比较一致。 令$\sigma_u \in U’$为用户集合$U’$中所有评分的方差，Nadav Golbandi的基本思想是通过如下方式度量一个物品的区分度$D(i)$:$$D(i) = \sigma_{u \in N^+(i)} + \sigma_{u \in N^-(i)} + \sigma_{u \in \bar N(i)}$$其中，$N^+(i)$是喜欢物品i的用户集合，$N^-(i)$是不喜欢物品i的用户集合，$\bar N(i)$是没有对物品$i$评分的用户集合。$ \sigma_{u \in N^+(i)}$是喜欢物品i的用户对其他物品评分的方差，$\sigma_{u \in N^-(i)}$是不喜欢物品$i$的用户对其他物品评分的方差，$\sigma_{u \in \bar N(i)}$是没有对物品$i$评分的用户对其他物品评分的方差。也就是说，对于物品$i$，Nadav Golbandi将用户分成3类——喜欢物品i的用户、不喜欢物品i的用户和不知道物品i的用户（即没有给i评分的用户）。如果这3类用户集合内的用户对其他的物品兴趣很不一致，说明物品i具有较高的区分度。Nadav Golbandi的算法首先会从所有用户中找到具有最高区分度的物品i，然后将用户分成3类。然后在每类用户中再找到最具区分度的物品，然后将每一类用户又各自分为3类，也就是将总用户分成9类，然后这样继续下去，最终可以通过对一系列物品的看法将用户进行分类。而在冷启动时，我们从根节点开始询问用户对该节点物品的看法，然后根据用户的选择将用户放到不同的分枝，直到进入最后的叶子节点，此时我们就已经对用户的兴趣有了比较清楚的了解，从而可以开始对用户进行比较准确地个性化推荐。 3.4 利用物品的内容信息物品冷启动需要解决的问题是如何将新加入的物品推荐给对它感兴趣的用户。 第2章介绍了两种主要的推荐算法——UserCF和ItemCF算法。首先需要指出的是，UserCF算法对物品冷启动问题并不非常敏感。因为，UserCF在给用户进行推荐时，会首先找到和用户兴趣相似的一群用户，然后给用户推荐这一群用户喜欢的物品。在很多网站中，推荐列表并不是给用户展示内容的唯一列表，那么当一个新物品加入时，总会有用户从某些途径看到这些物品，对这些物品产生反馈。那么，当一个用户对某个物品产生反馈后，和他历史兴趣相似的其他用户的推荐列表中就有可能出现这一物品，从而更多的人就会对这个物品产生反馈，导致更多的人的推荐列表中会出现这一物品，因此该物品就能不断地扩散开来，从而逐步展示到对它感兴趣用户的推荐列表中。但是，有些网站中推荐列表可能是用户获取信息的主要途径，比如豆瓣网络电台。那么对于UserCF算法就需要解决第一推动力的问题，即第一个用户从哪儿发现新的物品。只要有一小部分人能够发现并喜欢新的物品，UserCF算法就能将这些物品扩散到更多的用户中。解决第一推动力最简单的方法是将新的物品随机展示给用户，但这样显然不太个性化，因此可以考虑利用物品的内容信息，将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户。对于ItemCF算法来说，物品冷启动就是一个严重的问题了。因为ItemCF算法的原理是给用户推荐和他之前喜欢的物品相似的物品。ItemCF算法会每隔一段时间利用用户行为计算物品相似度表（一般一天计算一次），在线服务时ItemCF算法会将之前计算好的物品相关度矩阵放在内存中。因此，当新物品加入时，内存中的物品相关表中不会存在这个物品，从而ItemCF算法无法推荐新的物品。解决这一问题的办法是频繁更新物品相似度表，但基于用户行为计算物品相似度是非常耗时的事情，主要原因是用户行为日志非常庞大。而且，新物品如果不展示给用户，用户就无法对它产生行为，通过行为日志计算是计算不出包含新物品的相关矩阵的。为此，我们只能利用物品的内容信息计算物品相关表，并且频繁地更新相关表（比如半小时计算一次）。 一般来说，物品的内容可以通过向量空间模型(参见维基百科Vector Space Model词条)表示，该模型会将物品表示成一个关键词向量。如果物品的内容是一些诸如导演、演员等实体的话，可以直接将这些实体作为关键词。但如果内容是文本的形式，则需要引入一些理解自然语言的技术抽取关键词。图3-11展示了从文本生成关键词向量的主要步骤。对于中文，首先要对文本进行分词，将字流变成词流，然后从词流中检测出命名实体（如人名、地名、组织名等），这些实体和一些其他重要的词将组成关键词集合， 最后对关键词进行排名，计算每个关键词的权重，从而生成关键词向量。对于物品$d$，它的内容表示成一个关键词向量如下：$$d_i = \{ (e_1,w_1),(e_2,w_2), ···\}$$其中$e_i$是关键词，$w_i$是关键词对应的权重。如果物品是文本，我们可以用信息检索领域著名的TF-IDF公式计算词的权重：$$w_i = \frac {TF(e_i)}{\log DF(e_i)}​$$ 向量空间模型的优点是简单，缺点是丢失了一些信息，比如关键词之间的关系信息。不过在绝大多数应用中，向量空间模型对于文本的分类、聚类、相似度计算已经可以给出令人满意的结果。 在给定物品内容的关键词向量后，物品的内容相似度可以通过向量之间的余弦相似度计算：$$w_{ij} = \frac {d_i \cdot d_j}{\sqrt {\Vert d_i \Vert \Vert d_j \Vert}}$$在具体计算物品之间的内容相似度时，最简单的方法当然是对两两物品都利用上面的余弦相似度公式计算相似度，如下代码简单实现了这种方法：12345def CalculateSimilarity(D): for di in D: for dj in D: w[i][j] = CosineSimilarity(di, dj) return w D是文档集合。 但这种算法的时间复杂度很高。假设有$N$个物品，每个物品平均由$m$个实体表示，那么这个算法的复杂度是$O( N^2m)$。 在实际应用中，可以首先通过建立关键词—物品的倒排表加速这一计算过程，关于这一方法已经在前面介绍UserCF和ItemCF算法时详细介绍过了，所以这里直接给出计算的代码：12345678910def CalculateSimilarity(entity-items) w = dict() ni = dict() for e,items in entity_items.items(): for i,wie in items.items(): addToVec(ni, i, wie * wie) for j,wje in items.items(): addToMat(w, i, j, wie, wje) for i, relate_items in w.items(): relate_items = &#123;x:y/math.sqrt(ni[i] * ni[x]) for x,y in relate_items.items()&#125; 得到物品的相似度之后，可以利用上一章提到的ItemCF算法的思想，给用户推荐和他历史上喜欢的物品内容相似的物品。 既然内容相似度计算简单，能频繁更新，而且能够解决物品冷启动问题，那么为什么还需要协同过滤的算法?书中这部分在MovieLens和GitHub两个数据集上进行了实验，并加以说明，详情见书。 话题模型向量空间模型在内容数据丰富时可以获得比较好的效果。以文本为例，如果是计算长文本的相似度，用向量空间模型利用关键词计算相似度已经可以获得很高的精确度。但是，如果文本很短，关键词很少，向量空间模型就很难计算出准确的相似度。举个例子，假设有两篇论文，它们的标题分别是“推荐系统的动态特性”和“基于时间的协同过滤算法研究”。如果读者对推荐系统很熟悉，可以知道这两篇文章的研究方向是类似的，但是它们标题中没有一样的关键词。其实，它们的关键词虽然不同，但却是相似的。“动态”和“基于时间”含义相似，“协同过滤”是“推荐系统”的一种算法。换句话说，这两篇文章的关键词虽然不同，但关键词所属的话题是相同的。在这种情况下，首先需要知道文章的话题分布，然后才能准确地计算文章的相似度。如何建立文章、话题和关键词的关系是话题模型（topic model）研究的重点。 代表性的话题模型有LDA。关于LDA的详细理论介绍可以参考DM Blei的论文“Latent Dirichlet Allocation” (参见David M. Blei、 Andrew Y. Ng、 Michael I. Jordan的“ Latent dirichlet allocation”（Journal of Machine Learning Research 3， 2003）)。任何模型都有一个假设，LDA作为一种生成模型，对一篇文档产生的过程进行了建模。话题模型的基本思想是，一个人在写一篇文档的时候，会首先想这篇文章要讨论哪些话题，然后思考这些话题应该用什么词描述，从而最终用词写成一篇文章。因此，文章和词之间是通过话题联系的。LDA中有3种元素，即文档、话题和词语。每一篇文档都会表现为词的集合，这称为词袋模型(bag of words)。每个词在一篇文章中属于一个话题。令$D$为文档集合，$D[i]$是第$i$篇文档。$w[i][j]$是第$i$篇文档中的第$j$个词。$z[i][j]$是第$i$篇文档中第$j$个词属于的话题。 LDA的计算过程包括初始化和迭代两部分。首先要对$z$进行初始化，而初始化的方法很简单，假设一共有$K$个话题， 那么对第$i$篇文章中的第$j$个词， 可以随机给它赋予一个话题。同时，用$NWZ(w,z)$记录词$w$被赋予话题$z$的次数，$NZD(z,d)$记录文档$d$中被赋予话题$z$的词的个数。 123456foreach document i in range(0,|D|): foreach word j in range(0, |D(i)|): z[i][j] = rand() % K NZD[z[i][j], D[i]]++ NWZ[w[i][j], z[i][j]]++ NZ[z[i][j]]++ 在初始化之后，要通过迭代使话题的分布收敛到一个合理的分布上去。伪代码如下所示： 12345678910while not converged: foreach document i in range(0, |D|): foreach word j in range(0, |D(i)|): NWZ[w[i][j], z[i][j]]-- NZ[z[i][j]]-- NZD[z[i][j], D[i]]-- z[i][j] = SampleTopic() NWZ[w[i][j], z[i][j]]++ NZ[z[i][j]]++ NZD[z[i][j], D[i]]++ LDA可以很好地将词组合成不同的话题。 在使用LDA计算物品的内容相似度时，可以先计算出物品在话题上的分布，然后利用两个物品的话题分布计算物品的相似度。比如，如果两个物品的话题分布相似，则认为两个物品具有较高的相似度，反之则认为两个物品的相似度较低。计算分布的相似度可以利用KL散度(参见http://en.wikipedia.org/wiki/Kullback-Leibler_divergence) ：$$D_{KL}(p||q) = \sum_i p(i)ln \frac{p(i)}{q(i)}$$其中$p$和$q$是两个分布，KL散度越大说明分布的相似度越低。 3.5 发挥专家的作用书中这部分对个性化网络电台Pandora和电影推荐网站Jinni如何利用专家对物品进行标注，进而建立推荐系统作了介绍。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（二）]]></title>
    <url>%2F2018%2F11%2F24%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第2章 利用用户行为数据用户行为数据中蕴涵着很多不是那么显而易见的规律，而个性化推荐算法的任务就是通过计算机去发现这些规律，从而为产品的设计提供指导，提高用户体验。基于用户行为分析的推荐算法是个性化推荐系统的重要算法，学术界一般将这种类型的算法称为协同过滤算法。顾名思义，协同过滤就是指用户可以齐心协力，通过不断地和网站互动，使自己的推荐列表能够不断过滤掉自己不感兴趣的物品，从而越来越满足自己的需求。 2.1 用户行为数据简介用户行为数据的存在形式用户行为数据在网站上最简单的存在形式就是日志。网站在运行过程中都产生大量原始日志(raw log)，并将其存储在文件系统中。很多互联网业务会把多种原始日志按照用户行为汇总成会话日志(session log)，其中每个会话表示一次用户行为和对应的服务。比如，在搜索引擎和搜索广告系统中，服务会为每次查询生成一个展示日志(impression log)，其中记录了查询和返回结果。如果用户点击了某个结果，这个点击信息会被服务器截获并存储在点击日志(click log)中。 一个并行程序会周期性地归并展示日志和点击日志，得到的会话日志中每个消息是一个用户提交的查询、得到的结果以及点击。类似地，推荐系统和电子商务网站也会汇总原始日志生成描述用户行为的会话日志。 用户行为数据的分类用户行为在个性化推荐系统中一般分两种——显性反馈行为(explicit feedback)和隐性反馈行为(implicit feedback)。显性反馈行为包括用户明确表示对物品喜好的行为，主要形式就是评分和喜欢/不喜欢。和显性反馈行为相对应的是隐性反馈行为。隐性反馈行为指的是那些不能明确反应用户喜好的行为。最具代表性的隐性反馈行为就是页面浏览行为。按照反馈的明确性分，用户行为数据可以分为显性反馈和隐性反馈，但按照反馈的方向分，又可以分为正反馈和负反馈。正反馈指用户的行为倾向于指用户喜欢该物品，而负反馈指用户的行为倾向于指用户不喜欢该物品。在显性反馈中，很容易区分一个用户行为是正反馈还是负反馈，而在隐性反馈行为中，就相对比较难以确定。 显性反馈数据和隐性反馈数据的区别下图从几个方面比较了显性反馈数据和隐性反馈数据。 用户行为的表示方式下图给出了一种表示方式，它将一个用户行为表示为六部分，即产生行为的用户和行为的对象。行为的种类、产生行为的上下文、行为的内容和权重。很多时候我们并不使用统一结构表示所有行为，而是针对不同的行为给出不同表示。有时可能会忽略一些信息(比如上下文)，但有些信息不能忽略(比如产生行为的用户和行为的对象就是所有行为都必须包含的)。 数据集的分类不同的数据集针对不同的情况，根据所包含行为的不同将数据集进行分类，目前比较有代表性的数据集有如下几个： 无上下文信息的隐性反馈数据集 每一条行为记录仅仅包含用户ID和物品ID。Book-Crossing(参见“Book-Crossing Dataset”，地址为http://www.informatik.uni-freiburg.de/~cziegler/BX/) 就是这种类型的数据集。 无上下文信息的显性反馈数据集 每一条记录包含用户ID、物品ID和用户对物品的评分。 有上下文信息的隐性反馈数据集 每一条记录包含用户ID、物品ID和用户对物品产生行为的时间戳。Lastfm数据集(参见http://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/lastfm-1K.html) 就是这种类型的数据集。 有上下文信息的显性反馈数据集 每一条记录包含用户ID、物品ID、用户对物品的评分和评分行为发生的时间戳。Netflix Prize(参见http://netflixprize.com/) 提供的就是这种类型的数据集。 2.2 用户行为分析在利用用户行为数据设计推荐算法之前，研究人员首先需要对用户行为数据进行分析，了解数据中蕴含的一般规律，这样才能对算法的设计起到指导作用。 2.2.1 用户活跃度和物品流行度的分布长尾分布很多关于互联网数据的研究发现，互联网上的很多数据分布都满足一种称为Power Law(参见“浅谈网络世界的Power Law现象”，地址为http://mmdays.com/2008/11/22/power_law_1/) 的分布，这个分布在互联网领域也称长尾分布。$$f(x) = \alpha x^k$$1932年，哈佛大学的语言学家Zipf在研究英文单词的词频时发现，如果将单词出现的频率按照由高到低排列，则每个单词出现的频率和它在热门排行榜中排名的常数次幂成反比。这个现象表明，在英文中大部分词的词频其实很低，只有很少的词被经常使用。用户行为数据也蕴含着这种规律。令$f_u(k)$为对k个物品产生过行为的用户数，令$f_i(k)$为被k个用户产生过行为的物品数。那么，$f_u(k)$和$f_i(k)$都满足长尾分布。也就是说：$$f_u(k)= \alpha_u k^{\beta_u}$$ $$f_i(k)= \alpha_i k^{\beta_i}$$ 2.2.2 用户活跃度和物品流行度的关系用户越活跃，越倾向于浏览冷门的物品。仅仅基于用户行为数据设计的推荐算法一般称为协同过滤算法。 学术界对协同过滤算法进行了深入研究，提出了很多方法，比如基于邻域的方法（ neighborhood-based ）、隐语义模型（ latent factor model）、基于图的随机游走算法（random walk on graph）等。在这些方法中，最著名的、在业界得到最广泛应用的算法是基于邻域的方法， 而基于邻域的方法主要包含下面两种算法。 基于用户的协同过滤算法 基于物品的协同过滤算法 2.3 实验设计和算法评测2.3.1 数据集采用GroupLens提供的MovieLens数据集(数据集详细信息见 http://www.grouplens.org/node/73) 介绍和评测各种算法，并且忽略了数据集中的评分记录。 2.3.2 实验设计协同过滤算法的离线实验一般如下设计。首先，将用户行为数据集按照均匀分布随机分成M份，挑选一份作为测试集，将剩下的M-1份作为训练集。然后在训练集上建立用户兴趣模型，并在测试集上对用户行为进行预测，统计出相应的评测指标。为了保证评测指标并不是过拟合的结果，需要进行M次实验，并且每次都使用不同的测试集。然后将M次实验测出的评测指标的平均值作为最终的评测指标。 下面的代码描述了将数据集随机分成训练集和测试集的过程： 12345678910def SplitData(data, M, k, seed): test = [] train = [] random.seed(seed) for user, item in data: if random.randint(0,M) == k: test.append([user,item]) else: train.append([user,item]) return train, test 这里，每次实验选取不同的k（0≤k≤M-1）和相同的随机数种子seed，进行M次实验就可以得到M个不同的训练集和测试集，然后分别进行实验，用M次实验的平均值作为最后的评测指标。这样做主要是防止某次实验的结果是过拟合的结果（over fitting），但如果数据集够大，模型够简单，为了快速通过离线实验初步地选择算法，也可以只进行一次实验。 2.3.3 评测指标召回率和准确率计算方法和第一章预测准确度中TopN推荐部分一样 覆盖率同样与之前介绍的一致。如下代码可以用来计算推荐算法的覆盖率： 12345678910def Coverage(train, test, N): recommend_items = set() all_items = set() for user in train.keys(): for item in train[user].keys(): all_items.add(item) rank = GetRecommendation(user, N) for item, pui in rank: recommend_items.add(item) return len(recommend_items) / (len(all_items) * 1.0) 新颖度使用推荐列表中物品的平均流行度度量推荐结果的新颖度。如果推荐出的物品都很热门，说明推荐的新颖度较低，否则说明推荐结果比较新颖。 12345678910111213141516def Popularity(train, test, N): item_popularity = dict() for user, items in train.items(): for item in items.keys() if item not in item_popularity: item_popularity[item] = 0 item_popularity[item] += 1 ret = 0 n = 0 for user in train.keys(): rank = GetRecommendation(user, N) for item, pui in rank: ret += math.log(1 + item_popularity[item]) n += 1 ret /= n * 1.0 return ret 计算平均流行度时对每个物品的流行度取对数，这是因为物品的流行度分布满足长尾分布，在取对数后，流行度的平均值更加稳定。 2.4 基于近邻的算法基于邻域的算法分为两大类，一类是基于用户的协同过滤算法，另一类是基于物品的协同过滤算法。 2.4.1 基于用户的协同过滤算法(UserCF算法)基于用户的协同过滤算法是推荐系统中最古老的算法。这个算法的诞生标志了推荐系统的诞生。该算法在1992年被提出，并应用于邮件过滤系统，1994年被GroupLens用于新闻过滤。在此之后直到2000年，该算法都是推荐系统领域最著名的算法。 1.基础算法在一个在线个性化推荐系统中，当一个用户A需要个性化推荐时，可以先找到和他有相似兴趣的其他用户，然后把那些用户喜欢的、而用户A没有听说过的物品推荐给A。这种方法称为基于用户的协同过滤算法。基于用户的协同过滤算法主要包括两个步骤。 找到和目标用户兴趣相似的用户集合。 找到这个集合中的用户喜欢的，且目标用户没有听说过的物品推荐给目标用户。 步骤(1)的关键是计算两个用户的兴趣相似度。协同过滤算法主要利用行为的相似度计算兴趣的相似度。给定用户u和用户v，令$N(u)$表示用户u曾经有过正反馈的物品集合，令$N(v)$为用户v曾经有过正反馈的物品集合。可以通过如下的Jaccard公式简单计算用户u和用户v的兴趣相似度：$$w_{uv} = \frac{|N(u) \cap N(v)|}{|N(u) \cup N(v)|}$$或者通过余弦相似度计算：$$w_{uv} = \frac{|N(u) \cap N(v)|}{\sqrt{|N(u)||N(v)|}}$$实现余弦相似度可以利用如下的伪码： 123456789def UserSimilarity(train): W = dict() for u in train.keys(): for v in train.keys(): if u == v: continue W[u][v] = len(train[u] &amp; train[v]) W[u][v] /= math.sqrt(len(train[u]) * len(train[v]) * 1.0) return W 该代码对两两用户都利用余弦相似度计算相似度。这种方法的时间复杂度是$O(|U|*|U|)$，这在用户数很大时非常耗时。由于实际上很多用户户相互之间并没有对同样的物品产生过行为，即$|N(u)\cap N(v)| = 0 $，因此会将很多时间浪费在计算用户之间相似度上。换个思路，首先计算出$|N(u)\cap N(v)|\neq 0$的用户对$(u, v)$，然后再对这种情况除以分母$\sqrt{|N(u)||N(v)|}$。为此，首先建立物品到用户的倒排表，对于每个物品都保存对该物品产生过行为的用户列表。令稀疏矩阵$C[u][v]= N(u) \cap N(v)$ 。那么，假设用户u和用户v同时属于倒排表中K个物品对应的用户列表，就有$C[u][v]=K$。从而，可以扫描倒排表中每个物品对应的用户列表，将用户列表中的两两用户对应的$C[u][v]$加1，最终就可以得到所有用户之间不为0的$C[u][v]$。下面的代码实现了上面提到的算法： 12345678910111213141516171819202122232425def UserSimilarity(train): # build inverse table for item_users item_users = dict() for u, items in train.items(): for i in items.keys(): if i not in item_users: item_users[i] = set() item_users[i].add(u) #calculate co-rated items between users C = dict() N = dict() for i, users in item_users.items(): for u in users: N[u] += 1 for v in users: if u == v: continue C[u][v] += 1 #calculate finial similarity matrix W W = dict() for v, cuv in related_users.items(): W[u][v] = cuv / math.sqrt(N[u] * N[v]) return W 得到用户之间的兴趣相似度后，UserCF算法会给用户推荐和他兴趣最相似的K个用户喜欢的物品。如下的公式度量了UserCF算法中用户u对物品i的感兴趣程度：$$p(u,i)=\sum_{v \in S(u,K) \cap N(i)} w_{uv}r_{vi}$$其中，$S(u,K)$包含和用户u兴趣最接近的K个用户，$N(i)$是对物品i有过行为的用户集合，$w_{uv}$是用户u和用户v的兴趣相似度，$r_{vi}$代表用户v对物品i的兴趣，因为使用的是单一行为的隐反馈数据，所以所有的$r_{vi}=1$。 如下代码实现了上面的UserCF推荐算法： 1234567891011def Recommend(user, train, W): rank = dict() interacted_items = train[user] for v, wuv in sorted(W[u].items, key=itemgetter(1), \ reverse=True)[0:K]: for i, rvi in train[v].items: if i in interacted_items: # we should filter items user interacted before continue rank[i] += wuv * rvi return rank 参数K是UserCF的一个重要参数，它的调整对推荐算法的各种指标都会产生一定的影响。 准确率和召回率 选择合适的K对于获得高的推荐系统精度比较重要。推荐结果的精度对K也不是特别敏感，只要选在一定的区域内，就可以获得不错的精度。 流行度 K越大，参考的人越多，结果就越来越趋近于全局热门的物品。 覆盖率 K越大，则UserCF推荐结果的覆盖率越低。覆盖率的降低是因为流行度的增加，随着流行度增加，UserCF越来越倾向于推荐热门的物品，从而对长尾物品的推荐越来越少，因此造成了覆盖率的降低。 2.用户相似度计算的改进之前介绍的通过余弦相似度公式计算兴趣相似度，但是由于这个公式过于粗糙，于是需要改进该公式来提高UserCF的推荐性能。研究表明，用户对冷门物品采取与热门物品同样的行为更能说明他们兴趣的相似度。因此，John S. Breese在论文(参见John S. Breese、 David Heckerman和 Carl Kadie的论文“ Empirical Analysis of Predictive Algorithms for Collaborative Filtering”（Morgan Kaufmann Publishers，1998）)中提出了如下公式，根据用户行为计算用户的兴趣相似度：$$w_{uv} = \frac {\sum_{i \in N(u) \cap N(v)}\frac{1}{\log 1 + |N(i)|}}{\sqrt{|N(u)||N(v)|}}$$该公式通过$\frac{1}{\log 1 + |N(i)|}$惩罚了用户u和用户v共同兴趣列表中热门物品对他们相似度的影响。 将基于上述用户相似度公式的UserCF算法记为User-IIF算法。下面的代码实现了上述用户相似度公式。 1234567891011121314151617181920212223242526def UserSimilarity(train): # build inverse table for item_users item_users = dict() for u, items in train.items(): for i in items.keys(): if i not in item_users: item_users[i] = set() item_users[i].add(u) #calculate co-rated items between users C = dict() N = dict() for i, users in item_users.items(): for u in users: N[u] += 1 for v in users: if u == v: continue C[u][v] += 1 / math.log(1 + len(users)) #calculate finial similarity matrix W W = dict() for u, related_users in C.items(): for v, cuv in related_users.items(): W[u][v] = cuv / math.sqrt(N[u] * N[v]) return W 通过实验评测证明计算用户兴趣相似度时考虑物品的流行度对提升推荐效果的质量确实有帮助。 3.实际在线系统中使用UserCF的例子相比我们后面要讨论的基于物品的协同过滤算法(ItemCF)，UserCF在目前的实际应用中使用并不多。其中最著名的使用者是Digg，书中这部分介绍了Digg的推荐系统设计思路。 4.UserCF算法的缺点首先，随着网站的用户数目越来越大，计算用户兴趣相似度矩阵将越来越困难，其运算时间复杂度和空间复杂度的增长和用户数的增长近似于平方关系。其次，基于用户的协同过滤很难对推荐结果作出解释。 2.4.2 基于物品的协同过滤算法(ItemCF)基于物品的协同过滤（item-based collaborative filtering）算法是目前业界应用最多的算法。无论是亚马逊网，还是Netflix、Hulu、YouTube，其推荐算法的基础都是该算法。 1.基础算法ItemCF算法并不利用物品的内容属性计算物品之间的相似度，它主要通过分析用户的行为记录计算物品之间的相似度。该算法认为，物品A和物品B具有很大的相似度是因为喜欢物品A的用户大都也喜欢物品B 。 基于物品的协同过滤算法主要分为两步： 计算物品之间的相似度。 根据物品的相似度和用户的历史行为给用户生成推荐列表。 为了避免推荐出热门的商品，用下面的公式定义物品的相似度：$$w_{ij}=\frac {|N(i)\cap N(j)|} {\sqrt{|N(i)||N(j)|}}$$这个公式惩罚了物品j的权重，因此减轻了热门物品会和很多物品相似的可能性。 和UserCF算法类似，用ItemCF算法计算物品相似度时也可以首先建立用户—物品倒排表（即对每个用户建立一个包含他喜欢的物品的列表），然后对于每个用户，将他物品列表中的物品两两在共现矩阵C中加1。 详细代码如下所示：123456789101112131415161718def ItemSimilarity(train): #calculate co-rated users between items C = dict() N = dict() for u, items in train.items(): for i in users: N[i] += 1 for j in users: if i == j: continue C[i][j] += 1 #calculate finial similarity matrix W W = dict() for i,related_items in C.items(): for j, cij in related_items.items(): W[u][v] = cij / math.sqrt(N[i] * N[j]) return W 在得到物品之间的相似度后，ItemCF通过如下公式计算用户u对一个物品j的兴趣：$$p_{uj}=\sum_{i\in N(u) \cap S(j,K)} {w_{ji}r_{ui}} $$这里$N(u)$是用户喜欢的物品的集合，$S(j,K)$是和物品$j$最相似的$K$个物品的集合，$w_{ji}$是物品$j$和$i$的相似度，$r_{ui}$是用户$u$对物品$i$的兴趣。（对于隐反馈数据集，如果用户$u$对物品$i$有过行为，即可令$r_{ui}$ =1。）该公式的含义是，和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名。 该公式的实现代码如下所示。123456789def Recommendation(train, user_id, W, K): rank = dict() ru = train[user_id] for i,pi in ru.items(): for j, wj in sorted(W[i].items(), / key=itemgetter(1), reverse=True)[0:K]: if j in ru: continue rank[j] += pi * wj return rank ItemCF的一个优势就是可以提供推荐解释，即利用用户历史上喜欢的物品为现在的推荐结果进行解释。 如下代码实现了带解释的ItemCF算法：12345678910def Recommendation(train, user_id, W, K): rank = dict() ru = train[user_id] for i,pi in ru.items(): for j, wj in sorted(W[i].items(), / key=itemgetter(1), reverse=True)[0:K]: if j in ru: continue rank[j].weight += pi * wj rank[j].reason[i] = pi * wj return rank 参数K同样也是ItemCF算法中的一个重要参数。 精度(准确率和召回率) ItemCF推荐结果的精度也是不和K成正相关或者负相关的，因此选择合适的K对获得最高精度是非常重要的。 流行度 和UserCF不同，参数K对ItemCF推荐结果流行度的影响也不是完全正相关的。随着K的增加，结果流行度会逐渐提高，但当K增加到一定程度，流行度就不会再有明显变化。 覆盖率 K增加会降低系统的覆盖率。 2.用户活跃度对物品相似度的影响John S. Breese在论文中(参见John S. Breese、 David Heckerman和 Carl Kadie的“ Empirical Analysis of Predictive Algorithms for Collaborative Filtering”（Morgan Kaufmann Publishers ，1998）)提出了一个称为IUF(Inverse User Frequence)，即用户活跃度对数的倒数的参数，他认为活跃用户对物品相似度的贡献应该小于不活跃的用户，他提出应该增加IUF 参数来修正物品相似度的计算公式：$$w_{ij}=\frac{\sum_{u\in N(i)\cap N(j)} \frac{1}{\log1 + |N(u)|}}{\sqrt{|N(i)||N(j)|}}$$ 上面的公式只是对活跃用户做了一种软性惩罚，对于很多过于活跃的用户，为了避免相似度矩阵过于稠密，在实际计算中一般直接忽略他的兴趣列表，而不将其纳入到相似度计算的数据集中。 下面代码实现了改进后的算法，并将改进后的算法记为ItemCF-IUF：123456789101112131415161718def ItemSimilarity(train): #calculate co-rated users between items C = dict() N = dict() for u, items in train.items(): for i in users: N[i] += 1 for j in users: if i == j: continue C[i][j] += 1 / math.log(1 + len(items) * 1.0) #calculate finial similarity matrix W W = dict() for i,related_items in C.items(): for j, cij in related_items.items(): W[u][v] = cij / math.sqrt(N[i] * N[j]) return W 通过离线算法评测该算法证明，ItemCF-IUF在准确率和召回率两个指标上和ItemCF相近，但ItemCF-IUF明显提高了推荐结果的覆盖率，降低了推荐结果的流行度。从这个意义上说，ItemCF-IUF确实改进了ItemCF的综合性能。 3.物品相似度的归一化Karypis在研究中发现如果将ItemCF的相似度矩阵按最大值归一化，可以提高推荐的准确率(参见George Karypis的论文“ Evaluation of Item-based Top-N Recommendation Algorithms”)。其研究表明，如果已经得到了物品相似度矩阵w，那么可以用如下公式得到归一化之后的相似度矩阵$w’$：$$w_{ij}’ = \frac{w_{ij}}{max_j{w_{ij}}}$$归一化的好处不仅仅在于增加推荐的准确度，它还可以提高推荐的覆盖率和多样性。从实验结果可以看到，归一化确实能提高ItemCF的性能，其中各项指标都有了比较明显的提高。 2.4.3 UserCF和ItemCF的综合比较UserCF和ItemCF的应用领域比较及原因UserCF多被用于新闻推荐比如Digg，而ItemCF则在电子商务和书籍电影推荐方面得到广泛应用比如Amazon和Netflix。UserCF的推荐结果着重于反映和用户兴趣相似的小群体的热点，而ItemCF 的推荐结果着重于维系用户的历史兴趣。换句话说，UserCF的推荐更社会化，反映了用户所在的小型兴趣群体中物品的热门程度，而ItemCF的推荐更加个性化，反映了用户自己的兴趣传承。在新闻网站中，用户的兴趣不是特别细化，绝大多数用户都喜欢看热门的新闻。即使是个性化，也是比较粗粒度的。因此，个性化新闻推荐更加强调抓住新闻热点，热门程度和时效性是个性化新闻推荐的重点，而个性化相对于这两点略显次要。因此，UserCF可以给用户推荐和他有相似爱好的一群其他用户今天都在看的新闻，这样在抓住热点和时效性的同时， 保证了一定程度的个性化。 这是 Digg在新闻推荐中使用UserCF的最重要原因。UserCF适合用于新闻推荐的另一个原因是从技术角度考量的。因为作为一种物品，新闻的更新非常快，每时每刻都有新内容出现，而ItemCF需要维护一张物品相关度的表，如果物品更新很快，那么这张表也需要很快更新，这在技术上很难实现。绝大多数物品相关度表都只能做到一天一次更新，这在新闻领域是不可以接受的。而UserCF只需要用户相似性表，虽然UserCF对于新用户也需要更新相似度表，但在新闻网站中，物品的更新速度远远快于新用户的加入速度，而且对于新用户，完全可以给他推荐最热门的新闻，因此UserCF显然是利大于弊。但是，在图书、电子商务和电影网站，比如亚马逊、豆瓣、Netflix中，ItemCF则能极大地发挥优势。首先，在这些网站中，用户的兴趣是比较固定和持久的。而且这些网站中有一些活跃度很高的人，例如技术人员。一个技术人员可能都是在购买 技术方面的书，而且他们对书的热门程度并不是那么敏感，事实上越是资深的技术人员，他们看的书就越可能不热门。此外，这些系统中的用户大都不太需要流行度来辅助他们判断一个物品的 好坏，而是可以通过自己熟悉领域的知识自己判断物品的质量。因此，这些网站中个性化推荐的任务是帮助用户发现和他研究领域相关的物品。因此，ItemCF算法成为了这些网站的首选算法。 此外，这些网站的物品更新速度不会特别快，一天一次更新物品相似度矩阵对它们来说不会造成太大的损失，是可以接受的。同时，从技术上考虑，UserCF需要维护一个用户相似度的矩阵，而ItemCF需要维护一个物品相似度矩阵。从存储的角度说，如果用户很多，那么维护用户兴趣相似度矩阵需要很大的空间， 同理，如果物品很多，那么维护物品相似度矩阵代价较大。在早期的研究中，大部分研究人员都是让少量的用户对大量的物品进行评价，然后研究用户兴趣的模式。对于他们来说，因为用户很少，计算用户兴趣相似度是最快也是最简单的方法。但在实际的互联网中，用户数目往往非常庞大，而在图书、电子商务网站中，物品的数目则是比较少的。此外，物品的相似度相对于用户的兴趣一般比较稳定，因此使用ItemCF是比较好的选择。当然，新闻网站是个例外，在那儿，物品的相似度变化很快，物品数目庞大， 相反用户兴趣则相对固定（都是喜欢看热门的），所以新闻网站的个性化推荐使用UserCF算法的更多。 UserCF与ItemCF的性能比较及原因离线实验结果可见，ItemCF算法在各项指标上似乎都不如UserCF，特别是其推荐结果的覆盖率和新颖度都低于UserCF。似乎与之前所说的不符合。首先要指出的是，离线实验的性能在选择推荐算法时并不起决定作用。首先应该满足产品的需求，比如如果需要提供推荐解释，那么可能得选择ItemCF算法。其次，需要看实现代价，比如若用户太多，很难计算用户相似度矩阵，这个时候可能不得不抛弃UserCF算法。最后，离线指标和点击率等在线指标不一定成正比。而且，这里对比的是最原始的UserCF和ItemCF算法，这两种算法都可以进行各种各样的改进。一般来说，这两种算法经过优化后，最终得到的离线性能是近似的。 哈利波特问题亚马逊网的研究人员在设计ItemCF算法之初发现ItemCF算法计算出的图书相关表存在一个问题，就是很多书都和《哈利波特》相关。 也就是说，购买任何一本书的人似乎都会购买《哈利波特》。后来他们研究发现，主要是因为《哈利波特》太热门了，确实是购买任何一本书的人几乎都会购买它。回顾一下ItemCF计算物品相似度的经典公式：$$w_{ij}=\frac {\vert N(i)\cap N(j) \vert} {\sqrt{\vert N(i)||N(j)\vert}}$$这个问题的原因是，如果j非常热门， 那么上面公式的分子$N (i ) \cap N ( j )$就会越来越接近$N (i)$。 尽管上面的公式分母已经考虑到了$j$的流行度，但在实际应用中，热门的j仍然会获得比较大的相似度。 哈利波特问题有几种解决方案。第一种是在分母上加大对热门物品的惩罚，比如采用如下公式：$$w_{ij} = \frac {\vert N(i) \cap N(j) \vert}{\vert N(i)\vert^{1-\alpha} \vert N(j)\vert^{\alpha}}$$其中$\alpha \in [0.5,1]$。通过提高$\alpha$，就可以惩罚热门的j。 如果α＝0.5就是标准的ItemCF算法。从离线实验结果可以看到，α只有在取值为0.5时才会导致最高的准确率和召回率，而无论α＜0.5或者α＞0.5都不会带来这两个指标的提高。但是，如果看覆盖率和平均流行度就可以发现，α越大，覆盖率就越高，并且结果的平均热门程度会降低。因此，通过这种方法可以在适当牺牲准确率和召回率的情况下显著提升结果的覆盖率和新颖性（降低流行度即提高了新颖性）。上述方法还不能彻底地解决哈利波特问题。每个用户一般都会在不同的领域喜欢一种物品。两个不同领域的最热门物品之间往往具有比较高的相似度。这个时候，仅仅靠用户行为数据是不能解决这个问题的，因为用户的行为表示这种物品之间应该相似度很高。此时，我们只能依靠引入物品的内容数据解决这个问题，比如对不同领域的物品降低权重等。这些就不是协同过滤讨论的范畴了。 2.5 隐语义模型自从Netflix Prize比赛举办以来，LFM（latent factor model）隐语义模型逐渐成为推荐系统领域耳熟能详的名词。其实该算法最早在文本挖掘领域被提出，用于找到文本的隐含语义。 2.5.1 基础算法隐语义模型的核心思想是通过特征(latent factor)联系用户兴趣和物品。针对推荐问题除了UserCF、ItemCF算法，还有一种方法就是根据用户的兴趣进行分类。对于某个用户，首先得到他的兴趣分类，然后从分类中挑选他可能喜欢的物品。这个基于兴趣分类的方法大概需要解决3个问题： 如何给物品进行分类？ 如何确定用户对哪些类的物品感兴趣，以及感兴趣的程度？ 对于一个给定的类，选择哪些属于这个类的物品推荐给用户，以及如何确定这些物品在一个类中的权重？ 对于第一个问题的简单解决方案是找编辑给物品分类。但是，即使有很系统的分类体系，编辑给出的分类仍然具有以下缺点。 编辑的意见不能代表各种用户的意见。编辑的分类大部分是从书的内容出 发，而不是从书的读者群出发。 编辑很难控制分类的粒度。 编辑很难给一个物品多个分类。有的书不仅属于一个类，而是可能属于很多的类。 编辑很难给出多维度的分类。 编辑很难决定一个物品在某一个分类中的权重。 为了解决上面的问题，研究人员提出：为什么我们不从数据出发，自动地找到那些类，然后进行个性化推荐？于是，隐含语义分析技术（latent variable analysis）出现了。隐含语义分析技术因为采取基于用户行为统计的自动聚类，较好地解决了上面提出的5个问题。 编辑的意见不能代表各种用户的意见，但隐含语义分析技术的分类来自对用户行为的统计，代表了用户对物品分类的看法。隐含语义分析技术和ItemCF在物品分类方面的思想类似，如果两个物品被很多用户同时喜欢，那么这两个物品就很有可能属于同一个类。 编辑很难控制分类的粒度，但隐含语义分析技术允许我们指定最终有多少个分类，这个数字越大，分类的粒度就会越细，反正分类粒度就越粗。 编辑很难给一个物品多个分类，但隐含语义分析技术会计算出物品属于每个类的权重，因此每个物品都不是硬性地被分到某一个类中。 编辑很难给出多维度的分类，但隐含语义分析技术给出的每个分类都不是同一个维度的，它是基于用户的共同兴趣计算出来的，如果用户的共同兴趣是某一个维度，那么LFM给出的类也是相同的维度。 编辑很难决定一个物品在某一个分类中的权重，但隐含语义分析技术可以通过统计用户行为决定物品在每个类中的权重，如果喜欢某个类的用户都会喜欢某个物品，那么这个物品在这个类中的权重就可能比较高。 隐含语义分析技术从诞生到今天产生了很多著名的模型和方法，其中和该技术相关且耳熟能详的名词有pLSA、LDA、隐含类别模型（latent class model）、隐含主题模型（latent topic model）、矩阵分解（matrix factorization）。这些技术和方法在本质上是相通的，其中很多方法都可以用于个性化推荐系统。 LFM通过如下公式计算用户u对物品i的兴趣：$$Preference(u,i)=r_{ui}=p_u^Tq_i=\sum_{f=1}^F p_{u,k} q_{i,k}$$这个公式中$p_{u,k}$和$q_{i,k}$是模型的参数，其中$p_{u,k}$度量了用户u的兴趣和第k个隐类的关系，而$q_{i,k}$度量了第k个隐类和物品i之间的关系。 要计算这两个参数，需要一个训练集，对于每个用户u，训练集里都包含了用户u喜欢的物品和不感兴趣的物品，通过学习这个数据集，就可以获得上面的模型参数。 LFM在显性反馈数据（也就是评分数据）上解决评分预测问题并达到了很好的精度。不过本章主要讨论的是隐性反馈数据集，这种数据集的特点是只有正样本（用户喜欢什么物品），而没有负样本（用户对什么物品不感兴趣）。在隐性反馈数据集上应用LFM解决TopN推荐的第一个关键问题就是如何给每个用户生成负样本。 对于这个问题，Rong Pan在文章(参见“One-Class Collaborative Filtering”)中进行了深入探讨。他对比了如下几种方法。 对于一个用户，用他所有没有过行为的物品作为负样本。 对于一个用户，从他没有过行为的物品中均匀采样出一些物品作为负样本。 对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，保证每个用户的正负样本数目相当。 对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，偏重采样不热门的物品。 对于第一种方法，它的明显缺点是负样本太多，正负样本数目相差悬殊，因而计算复杂度很高，最终结果的精度也很差。对于另外3种方法，Rong Pan在文章中表示第三种好于第二种，而第二种好于第四种。 作者认为对负样本采样时应该遵循以下原则： 对每个用户，要保证正负样本的平衡（数目相似）。 对每个用户采样负样本时，要选取那些很热门，而用户却没有行为的物品。 下面的代码实现了负样本采样过程： 1234567891011121314def RandomSelectNegativeSample(self, items): ret = dict() for i in items.keys(): ret[i] = 1 n = 0 for i in range(0, len(items) * 3): # 将上限设为len(items) * 3，主要是保证正、负样本数量接近 item = items_pool[random.randint(0, len(items_pool) - 1)] if item in ret: continue ret[item] = 0 n + = 1 if n &gt; len(items): break return ret 在上面的代码中，items_pool维护了候选物品的列表，在这个列表中，物品i出现的次数和物品i的流行度成正比。items是一个dict，它维护了用户已经有过行为的物品的集合。因此，上面的代码按照物品的流行度采样出了那些热门的、但用户却没有过行为的物品。经过采样，可以得到一个用户—物品集$K = {(u,i)}$，其中如果$(u, i)$是正样本，则有$r_{ui}$ = 1，否则有$r_{ui}$ = 0 。然后， 需要优化如下的损失函数来找到最合适的参数p和q：$$C = \sum_{(u,i) \in K} (r_{ui} - \hat r_{ui})^2 = \sum_{(u,i) \in K}(r_{ui} - \sum_{k=1}^K p_{u,k}q_{i,k})^2 + \lambda \Vert p_u \Vert^2 + \lambda \Vert q_i \Vert^2$$这里$\lambda \Vert p_u \Vert^2 + \lambda \Vert q_i \Vert^2$用来防止过拟合的正则化项，$\lambda$可以通过实验获得。最小化上面的损失函数，可以利用随机梯度下降算法。该算法是最优化理论里最基础的优化算法，它首先通过求参数的偏导数找到最速下降方向，然后通过迭代法不断地优化参数。下面介绍优化方法的数学推导。 上面定义的损失函数里有两组参数$p_{u,k}$和$q_{i,k}$，随机梯度下降法需要首先对它们分别求偏导数，可以得到：$$\frac{\partial C}{\partial p_{uk}} = -2q_{ik} + 2\lambda p_{uk}$$ $$\frac{\partial C}{\partial q_{ik}} = -2p_{uk} + 2\lambda q_{ik}$$ 然后，根据随机梯度下降法，需要将参数沿着最速下降方向向前推进，因此可以得到如下递推公式：$$p_{uk}=p_{uk} + \alpha(q_{ik}-\lambda p_{uk})$$ $$q_{ik} = q_{ik} + \alpha (p_{uk} - \lambda q_{ik})$$其中，$\alpha$是学习速率(learning rate)，它的选取需要通过反复实验获得。 下面的Python代码实现了这一优化过程：12345678910111213141516171819def LatentFactorModel(user_items, F, N, alpha, lambda): [P, Q] = InitModel(user_items, F) for step in range(0,N): for user, items in user_items.items(): samples = RandSelectNegativeSamples(items) for item, rui in samples.items(): eui = rui - Predict(user, item) for f in range(0, F): P[user][f] += alpha * (eui * Q[item][f] - \ lambda * P[user][f]) Q[item][f] += alpha * (eui * P[user][f] - \ lambda * Q[item][f]) alpha *= 0.9def Recommend(user, P, Q): rank = dict() for f, puf in P[user].items(): for i, qfi in Q[f].items(): if i not in rank: rank[i] += puf * qfi return rank 经过离线实验评测证明，LFM确实可以实现通过用户行为将物品聚类的功能。 在LFM中，重要的参数有4个： 隐特征的个数F； 学习速率alpha； 正则化参数lambda； 负样本/正样本比例 ratio。 通过实验发现， ratio 参数对LFM的性能影响最大。随着负样本数目的增加， LFM 的准确率和召回率有明显提高。 不过当ratio&gt;10以后，准确率和召回率基本就比较稳定了。同时，随着负样本数目的增加，覆盖率不断降低，而推荐结果的流行度不断增加，说明ratio参数控制了推荐算法发掘长尾的能力。当数据集非常稀疏时，LFM的性能会明显下降，甚至不如UserCF和ItemCF的性能。 2.5.2 基于LFM的实际系统的例子雅虎的研究人员公布过一个使用LFM进行雅虎首页个性化设计的方案(参见Bee-Chung Chen、Deepak Agarwal、Pradheep Elango和Raghu Ramakrishnan的“Latent Factor Models for Web Recommender Systems”)。 雅虎的研究人员以CTR作为优化目标，利用LFM来预测用户是否会单击一个链接。为此， 他们将用户历史上对首页上链接的行为记录作为训练集。其中，如果用户u单击过链接i，那么就定义$(u, i)$是正样本，即$r_{ui}$ = 1。如果链接i展示给用户u，但用户u从来没有单击过，那么就定义$(u, i)$是负样本，即$r_{ui}$ = -1。然后，雅虎的研究人员利用前文提到的LFM预测用户是否会单击链接：$$\hat r_{ui} = p_u^T \cdot q_i$$ LFM模型在实际使用中有一个困难，那就是它很难实现实时的推荐。经典的LFM模型每次训练时都需要扫描所有的用户行为记录，这样才能计算出用户隐类向量$p_u$和物品隐类向量$q_i$。而且LFM的训练需要在用户行为记录上反复迭代才能获得比较好的性能。因此，LFM的每次训练都很耗时，一般在实际应用中只能每天训练一次，并且计算出所有用户的推荐结果。从而LFM模型不能因为用户行为的变化实时地调整推荐结果来满足用户最近的行为。为了解决传统LFM不能实时化，而产品需要实时性的矛盾，雅虎的研究人员提出了一个解决方案。 他们的解决方案分为两个部分。首先，他们利用新闻链接的内容属性（关键词、类别等）得到链接i的内容特征向量$y_i$。其次，他们会实时地收集用户对链接的行为，并且用这些数据得到链接i的隐特征向量$q_i$。然后，他们会利用如下公式预测用户u是否会单击链接i：$$r_{ui} = x^T_u \cdot y_i + p_u^T \cdot q_i$$ 其中，$y_i$是根据物品的内容属性直接生成的，$x_{uk}$是用户u对内容特征k的兴趣程度，用户向量$x_{u}$可以根据历史行为记录获得，而且每天只需要计算一次。而$p_u$、$q_i$是根据实时拿到的用户最近几小时的行为训练LFM获得的。因此，对于一个新加入的物品i，可以通过$ x^T_u \cdot y_i$估计用户u对物品i的兴趣，然后经过几个小时后，就可以通过$p_u^T \cdot q_i$得到更加准确的预测值。 2.5.3 LFM和基于邻域的方法比较LFM是一种基于机器学习的方法，具有比较好的理论基础。这个方法和基于邻域的方法（比如UserCF、ItemCF）相比，各有优缺点。下面将从不同的方面对比LFM和基于邻域的方法。 理论基础 LFM具有比较好的理论基础，它是一种学习方法，通过优化一个设定的指标建立最优的模型。基于邻域的方法更多的是一种基于统计的方法，并没有学习过程。 离线计算的空间复杂度 基于邻域的方法需要维护一张离线的相关表。在离线计算相关表的过程中，如果用户/物品数很多，将会占据很大的内存。假设有M个用户和N个物品，在计算相关表的过程中，我们可能会获得一张比较稠密的临时相关表（尽管最终我们对每个物品只保留K个最相关的物品，但在中间计算过程中稠密的相关表是不可避免的），那么假设是用户相关表，则需要$O(M * M)$的空间，而对于物品相关表，则需要 $O(N * N)$的空间。而LFM在建模过程中，如果是F个隐类，那么它需要的存储空间是$O(F * (M+N))$，这在M和N很大时可以很好地节省离线计算的内存。 离线计算的时间复杂度 假设有M个用户、N个物品、K条用户对物品的行为记录。那么，UserCF计算用户相关表的时间复杂度是$O(N * (K/N)^2)$，而ItemCF计算物品相关表的时间复杂度是$O(M * (K / M)^2)$。而对于LFM，如果用F个隐类，迭代S次，那么它的计算复杂度是$O(K * F * S)$。那么，如果$K / N &gt; F * S$，则代表UserCF的时间复杂度低于LFM ，如果$K / M&gt;F * S$，则说明ItemCF的时间复杂度低于LFM。在一般情况下，LFM的时间复杂度要稍微高于UserCF和ItemCF，这主要是因为该算法需要多次迭代。但总体上，这两种算法在时间复杂度上没有质的差别。 在线实时推荐 UserCF和ItemCF在线服务算法需要将相关表缓存在内存中，然后可以在线进行实时的预测。以ItemCF算法为例，一旦用户喜欢了新的物品，就可以通过查询内存中的相关表将和该物品相似的其他物品推荐给用户。因此，一旦用户有了新的行为， 而且该行为被实时地记录到后台的数据库系统中，他的推荐列表就会发生变化。而从LFM的预测公式可以看到，LFM在给用户生成推荐列表时，需要计算用户对所有物品的兴趣权重，然后排名，返回权重最大的N个物品。那么，在物品数很多时，这一过程的时间复杂度非常高，可达$O(M * N * F)$。因此，LFM不太适合用于物品数非常庞大的系统，如果要用，我们也需要一个比较快的算法给用户先计算一个比较小的候选列表，然后再用LFM重新排名。另一方面，LFM在生成一个用户推荐列表时速度太慢，因此不能在线实时计算，而需要离线将所有用户的推荐结果事先计算好存储在数据库中。因此，LFM不能进行在线实时推荐，也就是说，当用户有了新的行为后，他的推荐列表不会发生变化。 推荐解释 ItemCF算法支持很好的推荐解释，它可以利用用户的历史行为解释推荐结果。但LFM无法提供这样的解释，它计算出的隐类虽然在语义上确实代表了一类兴趣和物品，却很难用自然语言描述并生成解释展现给用户。 2.6 基于图的模型2.6.1 用户行为数据的二分图表示在研究基于图的模型之前，首先需要将用户行为数据表示成图的形式。本章讨论的用户行为数据是由一系列二元组组成的，其中每个二元组$(u, i)$表示用户u对物品i产生过行为。令$G(V,E)$表示用户物品二分图，其中$V = V_U \cup V_I$由用户顶点集合$V_U$和物品顶点集合$V_I$组成。对于数据集中每一个二元组$(u, i)$，图中都有一套对应的边$e(v_u,v_i)$，其中$v_u \in V_U$是用户u对应的顶点，$v_i \in V_I$是物品i对应的顶点。 2.6.2 基于图的推荐算法如果将个性化推荐算法放到二分图模型上，那么给用户u推荐物品的任务就可以转化为度量用户顶点$v_u$和与$v_u$没有边直接相连的物品节点在图上的相关性，相关性越高的物品在推荐列表中的权重就越高。 度量图中两个顶点之间相关性的方法很多，但一般来说图中顶点的相关性主要取决于下面3个因素： 两个顶点之间的路径数； 两个顶点之间路径的长度； 两个顶点之间的路径经过的顶点。 而相关性高的一对顶点一般具有如下特征： 两个顶点之间有很多路径相连； 连接两个顶点之间的路径长度都比较短； 连接两个顶点之间的路径不会经过出度比较大的顶点。 基于上面3个主要因素，研究人员设计了很多计算图中顶点之间相关性的方法(参见Fouss Francois、Pirotte Alain、Renders Jean-Michel和Saerens Marco的“Random-Walk Computation of Similarities between Nodes of a Graph with Application to Collaborative Recommendation”(IEEE Transactions on Knowl edge and Data Eng ineering, 2007))。本节将介绍一种基于随机游走的PersonalRank算法(参见Taher H .Haveliwala的“Topic-Sensitive PageRank”（WWW 2002, 2002）)。 假设要给用户u进行个性化推荐，可以从用户u对应的节点$v_u$开始在用户物品二分图上进行随机游走。游走到任何一个节点时，首先按照概率α决定是继续游走，还是停止这次游走并从$v_u$节点开始重新游走。如果决定继续游走，那么就从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的节点。这样，经过很多次随机游走后，每个物品节点被访问到的概率会收敛到一个数。最终的推荐列表中物品的权重就是物品节点的访问概率。 如果将上面的描述表示成公式，可以得到如下公式：$$PR(v) =\begin{cases}\alpha \sum_{v’ \in in(v)} \frac{PR(v’)}{\vert out(v’) \vert} &amp; (v \neq v_u) \\(1- alpha) + \alpha \sum_{v’ \in in(v)} \frac{PR(v’)}{\vert out(v’) \vert} &amp; (v = v_u)\end{cases}$$ 下面的代码简单实现了上面的公式： 123456789101112131415def PersonalRank(G, alpha, root): rank = dict() rank = &#123;x:0 for x in G.keys()&#125; rank[root] = 1 for k in range(20): tmp = &#123;x:0 for x in G.keys()&#125; for i, ri in G.items(): for j, wij in ri.items(): if j not in tmp: tmp[j] = 0 tmp[j] += 0.6 * rank[i] / (1.0 * len(ri)) if j == root: tmp[j] += 1 - alpha rank = tmp return rank 虽然PersonalRank算法可以通过随机游走进行比较好的理论解释，但该算法在时间复杂度上有明显的缺点。因为在为每个用户进行推荐时，都需要在整个用户物品二分图上进行迭代，直到整个图上的每个顶点的PR值收敛。这一过程的时间复杂度非常高，不仅无法在线提供实时推荐，甚至离线生成推荐结果也很耗时。 为了解决PersonalRank每次都需要在全图迭代并因此造成时间复杂度很高的问题，给出两种解决方案。第一种就是减少迭代次数，在收敛之前就停止。这样会影响最终的精度，但一般来说影响不会特别大。另一种方法就是从矩阵论出发，重新设计算法。 对矩阵运算比较熟悉的读者可以轻松将PersonalRank转化为矩阵的形式。令M为用户物品二分图的转移概率矩阵，即：$$M(v, v’) = \frac {1}{\vert out(v) \vert}$$进而迭代公式可以转化为：$$\begin{align}r&amp; = (1-\alpha)r_0 + \alpha M^Tr \\&amp; = (1-\alpha)(1-\alpha M^T)^{-1}r_0\end{align}$$ 因此，只需要一次$(1-\alpha M^T)^{-1}​$，这里$1-\alpha M^T​$是稀疏矩阵。关于如何对稀疏矩阵快速求逆，可以参考矩阵计算方面的书籍和论文(比如Song Li的“Fast Algorithms For Sparse Matrix Inverse Compuataions”（2009）)。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推荐系统实践读书笔记（一）]]></title>
    <url>%2F2018%2F11%2F23%2F%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9E%E8%B7%B5%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[第1章 好的推荐系统在研究如何设计推荐系统前，了解什么是好的推荐系统至关重要。只有了解了优秀的推荐系统的特征，我们才能在设计推荐系统时根据实际情况进行取舍。 本章分3个步骤回答这个问题： 首先介绍了什么是推荐系统、推荐系统的主要任务、推荐系统和分类目录以及搜索引擎的区别等； 然后按照不同领域分门别类地介绍目前业界常见的个性化推荐应用； 最后介绍推荐系统的评测，通过介绍评测指标给出“好”的定义，从而最终解答“什么是好的推荐系统”这个问题。 1.1 什么是推荐系统推荐系统产生的背景随着信息技术和互联网的发展，人们逐渐从信息匮乏的时代走入了信息过载(overload)的时代。在这个时代，无论是信息消费者还是信息产生着都遇到了很大的挑战：作为信息消费者，如何从大量信息中找到自己感兴趣的信息是一件非常困难的的事情；作为信息产生者，如何让自己生产的信息脱颖而出，受到广大用户的关注，也是一件非常困难的事情。推荐系统就是解决这一矛盾的重要工具。 推荐系统的任务推荐系统的任务就是联系用户和信息，一方面帮助用户发现对自己有价值的信息，另一方面让信息能够展现在对它感兴趣的用户面前，从而实现信息消费者和信息生产者的双赢。 推荐系统与搜索引擎的异同众所周知，为了解决信息过载的问题，最具代表的解决方案是分类目录(雅虎)和搜索引擎(谷歌)。最初的分类目录网站将著名的网站分门别类，从而方便用户根据类别查找网站，然而随着互联网规模的不断扩大，门户网站也只能覆盖少量的热门网站，越来越不满足用户的需求。因此搜索引擎诞生了。但是搜索引擎需要用户主动提供准确的关键词来寻找信息，因此不能解决用户的很多其他需求，比如用户无法提供准确的关键词时，搜索引擎就无能为力了。 和搜索引擎一样，推荐系统也是一种帮助用户快速发现有用信息的工具。但和搜索引擎不同的是，推荐系统不需要用户提供明确的需求，而是通过分析用户的历史行为给用户的兴趣建模，从而主动给用户推荐能够满足他们兴趣和需求的信息。因此从某种意义上说，推荐系统和搜索引擎对于用户来说是两个互补的工具。搜索引擎满足了用户有明确目的时的主动查找需求，而推荐系统能够在用户没有明确目的的时候他们发现感兴趣的新内容。 生活中常见的推荐过程以看电影为例： 向朋友咨询。这种方式在推荐系统中称为社会化推荐(social recommendation)，即让好友给自己推荐物品。 寻找与自己之前看过的电影在内容上相似的电影。这种推荐方式在推荐系统中称为基于内容的推荐(content-based filtering)。 查看排行榜，看看别人都在看什么电影又或者看看和自己兴趣相近的人看什么电影。这种方式称为基于协同过滤(collaborative filtering)的推荐。 从上面三种方法可以看出，推荐算法的本质是通过一定的方式将用户和物品联系起来，而不同的推荐系统利用了不同的方式。 1.2 个性化推荐系统的应用在互联网的各类网站中都可以看到推荐系统的应用，而个性化推荐系统在这些网站中的主要作用是通过分析大量用户行为日志，给不同用户提供不同的个性化页面展示，以提高网站的点击率和转化率。 尽管不同的网站使用不同的推荐系统技术，但总地来说，几乎所有推荐系统应用都是由前台的展示页面、后台的日志系统、推荐算法系统3部分构成。 1.2.1 电子商务著名的电子商务网站亚马逊(Amazon)是个性化推荐系统的积极应用者和推广者。Amazon的推荐系统融入到了其各类产品中，其中最主要的应用是个性化商品推荐列表和相关商品的推荐列表。 个性化推荐列表基于物品的推荐算法(item-based method)该算法给用户用户推荐那些和他们之前喜欢的物品相似的物品。 个性化推荐列表组成部分 推荐结果的标题、缩略图以及其他内容属性。 推荐结果的平均分。 推荐理由。并且允许用户修正这一推荐 基于好友的推荐算法该算法按照用户在Facebook的好友关系，给用户推荐他们的好友在亚马逊上喜欢的物品。基于该种推荐算法生成的推荐列表的组成部分与基于物品的推荐列表类似，只不过这里的推荐理由换成了喜欢过相关物品的用户好友的头像。 相关推荐列表Amazon有两种相关商品列表： 包含购买了这个商品的用户也经常购买的其他商品 包含浏览过这个商品的用户经常购买的其他商品 这两种相关推荐列表的区别就是使用了不同用户行为计算物品的相关性。 此外，相关推荐列表最重要的应用就是打包销售(cross selling)。 1.2.2 电影和视频网站代表公司Netflix、Youtube、Hulu。其中Netflix和Youtube的算法与Amazon的算法类似，也是基于物品的推荐算法，即给用户推荐和他们曾经喜欢的视频相似的视频。 1.2.3 个性化音乐网络电台个性化推荐的成功应用需要两个条件： 存在信息过载。因为如果用户可以很容易地从所有物品中找到喜欢的物品，就不需要个性化推荐了。 用户大部分时候没有特别明确的需求。因为用户如果有明确的需求，可以直接通过搜索引擎找到感兴趣的物品。 在这两个条件下，个性化网络电台无疑是最合适的个性化推荐产品。目前有很多知名的个性化音乐网络电台。国际上著名的有Pandora和Last.fm，国内的代表则是网易云音乐。这三种应用虽然都是个性化网络电台，但背后的技术却不太一样。 PandoraPandora背后的音乐推荐系统主要来自于一个叫做音乐基因工程的项目。Pandora的算法主要基于内容，其音乐家和研究人员亲自听了上万首来自不同歌手的歌，然后对歌曲的不同特性(比如旋律、节奏、编曲和歌词等)进行标注，这些标注被称为音乐的基因。然后，Pandora会根据专家标注的基因计算歌曲的相似度，并给用户推荐和他之前喜欢的音乐在基因上相似的其他音乐。 Last.fmLast.fm记录了所有用户的听歌记录以及用户对歌曲的反馈，在这一基础上计算出不同用户在歌曲上的喜好相似度，从而给用户推荐和他有相似听歌爱好的其他用户喜欢的歌曲。同时，Last.fm也建立了一个社交网络，让用户能够和其他用户建立联系，同时也能让用户给好友推荐自己喜欢的歌曲。和Pandora相比，Last.fm没有使用专家标注，而是主要利用用户行为计算歌曲的相似度。 音乐推荐的特点2011年的Recsys大会专门要求了Pandora和研究人员对音乐推荐系统进行了演讲。演讲人总结了音乐推荐的如下特点： 物品空间大； 消费每首歌的代价很小； 物品种类丰富； 听一首歌耗时很少； 物品重用率很高； 用户充满激情； 上下文相关； 次序很重要； 很多播放列表资源； 不需要用户全神贯注； 高度社会化； 上面这些特点决定了音乐是一种非常适合用来推荐的物品。因此，尽管现在很多推荐系统都是作为一个应用存在与网站中，比如Amazon的商品推荐和Netflix的电影推荐，但唯有音乐推荐系统可以支持独立的个性化推荐网站，比如Pandora、Last.fm和豆瓣网络电台。 1.2.4 社交网络社交网络中的个性化推荐主要应用于3个方面： 利用用户的社交网络信息对用户进行个性化的物品推荐； 信息流的会话推荐； 给用户推荐好友； 1.2.5 个性化阅读个性化阅读同样符合前面提出的需要个性化推荐的两个因素：首先，互联网上的文章很多，用户面临信息过载的问题；其次，用户很多时候并没有必须看某篇具体文章的需求，他们只是想通过阅读特定领域的文章了解这些领域的动态。 Google ReaderGoogle Reader是一款流行的社会化阅读工具。它允许用户关注自己感兴趣的人，然后看到所关注用户分享的文章。 Zite和Google Reader不同，个性化阅读工具Zite则是收集用户对文章的偏好信息。在每篇文章右侧，Zite都允许用户给出喜欢或不喜欢的反馈，然后通过分析用户的反馈数据不停地更新用户的个性化文章列表。 DiggDigg是一家著名的新闻阅读网站。Digg首先根据用户的Digg历史计算用户之间的兴趣相似度，然后给用户推荐和他兴趣相似的用户喜欢的文章。 1.2.6 基于位置的服务随着移动设备的飞速发展，用户的位置信息已经非常容易获取，而位置是一种很重要的上下文信息，基于位置给用户推荐离他近的且他感兴趣的服务，用户就更有可能去消费。 Foursquare基于位置的服务往往和社交网络结合在一起。其中Foursquare推出了探索功能，给用户推荐好友在附近的行为。 1.2.7 个性化邮件使对用户重要的邮件能够让用户优先浏览。 Tapestry目前在文献中能够查到的第一个推荐系统Tapestry就是一个个性化邮件推荐系统，它通过分析用户阅读邮件的历史行为和习惯对新邮件进行重新排序，从而提高用户的工作效率。 1.2.8 个性化广告个性化广告投放目前已经成为了一门独立的学科——计算广告，但该学科和推荐系统在很多基础理论和方法上是相通的，比如它们的目的都是联系用户和物品，只是在个性化广告中，物品就是广告。 个性化广告投放和狭义个性化推荐的区别个性化推荐着重于帮助用户找到可能令他们感兴趣的物品，而广告推荐着重于帮助广告找到可能对它们感兴趣的用户，即一个是以用户为核心，而另一个是以广告为核心。 个性化广告投放技术目前个性化广告投放技术主要分为3种： 上下文广告。通过分析用户正在浏览的网页内容，投放和网页内容相关的广告。代表系统是谷歌的Adsense。 搜索广告。通过分析用户在当前会话中的搜索记录，判断用户的搜索目的，投放和用户目的相关的广告。 个性化展示广告。我们经常在很多网站看到大量的展示广告(就是那些大的横幅图片)，它们是根据用户的兴趣，对不同用户投放不同的展示广告。 Yahoo发表了大量个性化广告方面的论文，而最成功的则是Facebook。 1.3 推荐系统评测一个完整的推荐系统一般存在3个参与方：用户、物品提供者和提供推荐系统的网站。同时好的推荐系统设计，能够让推荐系统本身收集到高质量的用户反馈，不断完善推荐的质量，增加用户和网站的交互，提高网站的收入。因此在评测一个推荐算法时，需要同时考虑三方的利益，一个好的推荐系统是能够令三方共赢的系统。在推荐系统的早期研究中，很多人将好的推荐系统定义为能够作出准确预测的推荐系统。但是，后来很多研究表明，准确的预测并不代表好的推荐。举个极端点的例子，某推荐系统预测明天太阳将从东方升起，虽然预测准确率为100%，却是一种没有意义的预测。所以，好的推荐系统不仅仅能够准确预测用户的行为，而且能够扩展用户的视野，帮助用户发现那些他们可能会感兴趣，但却不那么容易发现的东西。为了全面评测推荐系统对三方利益的影响，本章从不同角度出发，提出不同的指标。 1.3.1 推荐系统实验方法首先介绍计算和获得这些指标的主要实验方法。推荐系统中主要有3种评测推荐效果的实验方法，即离线实验(offline experiment)、用户调查(user study)和在线实验(online experiment)。 离线实验离线实验的方法离线实验的方法一般由如下几个步骤构成： 通过日志系统获得用户行为数据，并按照一定格式生成一个标准的数据集； 将数据集按照一定的规则分成训练集和测试集； 在训练集上训练用户兴趣模型，在测试集上进行预测； 通过事先定义的离线指标评测算法评测在测试集上的预测结果。 从上面的步骤可以看到，推荐系统的离线实验都是在数据集上完成的，也就是说它不需要一个实际的系统来供它实验，而只要有一个从实验系统日志中提取的数据集即可。 离线实验的优缺点这种实验方法的好处是不需要真实用户参与，可以直接快速地计算出来，从而方便、快速地测试大量不同的算法。它的主要缺点是无法获得很多商业上关注的指标，如点击率、转化率等，而找到和商业指标非常相关的离线指标也是很困难的事情。 用户调查用户调查是推荐系统评测的一个重要工具，很多离线时没有办法评测的与用户主观感受有关的指标都可以通过用户调查获得。 用户调查的方法用户调查需要有一些真实用户，让他们在需要测试的推荐系统上完成一些任务。在他们完成任务时，我们需要观察和记录他们的行为，并让他们回答一些问题。最后，我们需要通过分析他们的行为和答案了解测试系统的性能。 用户调查的优缺点它的优点是可以获得很多体现用户主观感受的指标，相对在线实验风险很低，出现错误后很容易弥补。缺点是招募测试用户代价较大，很难组织大规模的测试用户，因此会使测试结果的统计意义不足。此外，在很多时候设计双盲实验非常困难，而且用户在测试环境下的行为和真实环境下的行为可能有所不同，因而在测试环境下收集的测试指标可能在真实环境下无法重现。 在线实验在完成离线实验和必要的用户调查后，可以将推荐系统上线做AB测试，将它和旧的算法进行比较。 在线实验的方法AB测试是一种很常用的在线评测算法的实验方法。它通过一定的规则将用户随机分成几组，并对不同组的用户采用不同的算法，然后通过统计不同用户的各种不同的评测指标比较不同算法。 网站http://www.abtests.com/给出了很多通过实际AB测试提高网站用户满意度的例子，从中我们可以学习到如何进行合理的AB测试。 在线实验的优缺点AB测试的优点是可以公平获得不同算法实际在线时的性能指标，包括商业上关注的指标。AB测试的缺点主要是周期比较长，必须进行长期的实验才能得到可靠的结果。因此一般不会用AB测试测试所有的算法，而只是用它测试那些在离线实验和用户调查中表现很好的算法。其次，一个大型网站的AB测试系统的设计也是一项复杂的工程。 一般来说，一个新的推荐算法最终上线，需要完成上面所说的3个实验。 首先，需要通过离线实验证明它在很多离线指标上优于现有的算法。 然后，需要通过用户调查确定它的用户满意度不低于现有的算法。 最后，通过在线的AB测试确定它在我们关心的指标上优于现有的算法。 1.3.2 评测指标1.用户满意度 用户作为推荐系统的重要参与者，其满意度是评测推荐系统的最重要指标。但是，用户满意度没有办法离线计算，只能通过用户调查或在线实验方式获得。 用户调查获得用户满意度主要是通过调查问卷的形式。用户对推荐系统的满意度分为不同的层次。因此在设计问卷时需要考虑到用户各方面的感受，这样用户才能针对问题给出自己准确的回答。 在在线系统中，用户满意度主要通过一些对用户行为的统计得到。更一般的情况下，我们可以用点击率、用户停留时间和转化率等指标度量用户的满意度。 2.预测准确度 预测准确度度量一个推荐系统或者推荐算法预测用户行为的能力。 计算方法：在计算该指标时需要有一个离线的数据集，该数据集包含用户的历史行为记录。然后，将该数据集通过时间分为训练集和测试集。最后，通过在训练集上建立用户的行为和兴趣模型预测用户在测试集上的行为，并计算预测行为和测试集上实际行为的重合度作为预测准确度。 不同的研究方向有不同的预测准确度指标。 评分预测 预测用户对物品评分的行为称为评分预测。 评分预测的预测准确度一般通过均方根误差(RMSE)和平均绝对误差(MAE)计算。对于测试集中的一个用户u和物品i，令$r_{ui}$是用户u对物品i的实际评分，而$\hat r_{ui}$是推荐算法给出的预测评分，那么RMSE的定义为：$$RMSE = \frac {\sqrt{\sum_{u,i \in T} (r_{ui} - \hat r_{ui})^2}}{|T|}$$ MAE采用绝对值计算预测误差，它的定义为：$$MAE=\frac{\sum_{u,i \in T}|r_{ui}-\hat r_{ui}|} {|T|}$$ 假设我们用一个列表records存放用户评分数据，令records[i] = [u,i,rui,pui]，其中rui是用户u对物品i的实际评分，pui是算法预测出来的用户u对物品i的评分，下面代码实现了RME和MAE的计算过程。 12345def RMSE(records): return math.sqrt(sum([(rui - pui) * (rui - pui) for u,i,rui,pui in records])/float(len(records)))def MAE(records): return sum([abs(rui-pui) for u,i,rui,pui in records])/float(len(records)) 关于RMSE和MAE这两个指标的优缺点，Netflix认为RMSE加大了对预测不准的用户物品评分的惩罚(平方项的惩罚)，因而对系统的评测更加苛刻。研究表明，如果评分系统是基于基数建立的(即用户给的评分都是整数)，那么对预测结果取整可能会降低MAE的误差。 TopN推荐网站在提供推荐服务时，一般是给用户一个个性化的推荐列表，这种推荐叫做TopN推荐。TopN推荐的预测准确率一般通过准确率(precision)/召回率(recall)度量。$R(u)$是根据用户在训练集上的行为给用户作出的推荐列表，而$T(u)$是用户在测试集上的行为列表。那么，推荐结果的召回率定义为：$$Recall=\frac {\sum_{u \in U} |R(u) \cap T(u)|}{\sum_{u \in U} |T(u)|} $$推荐结果的准确率定义为：$$Precision=\frac {\sum_{u \in U} |R(u) \cap T(u)|}{\sum_{u \in U} |R(u)|} $$下面的Python代码同时计算出了一个推荐算法的准确率和召回率： 12345678910def PrecisionRecall(test, N): hit = 0 n_recall = 0 n_precision = 0 for user, items in test.items(): rank = Recommend(user, N) hit += len(rank &amp; item) # hit是推荐列表与行为列表相交的部分 n_recall += len(items) n_precision += N return [hit/(1.0*n_recall),hit/(1.0*n_precision)] 有的时候，为了全面评测TopN推荐的准确率和召回率，一般会选取不同的推荐列表长度N，计算出一组准确率和召回率，然后画出准确率/召回率曲线(precision/recall curve)。 关于评分预测和TopN推荐的讨论评分预测一直是推荐系统研究的热点，绝大多数推荐系统的研究都是基于用户评分数据的评分预测。这主要是因为，一方面推荐系统的早期研究组GroupLens的研究主要就是基于电影评分 数据MovieLens进行的，其次，Netflix大赛也主要面向评分预测问题。因而，很多研究人员都将 研究精力集中在优化评分预测的RMSE上。 对此，亚马逊前科学家Greg Linden有不同的看法。2009年, 他在Communications of the ACM 网站发表了一篇文章 (“What is a Good Recommendation Algorithm？”,参见http://cacm.acm.org/blogs/blog-cacm/22925-what-is-a-goodrecommendation-algorithm/fulltext/) ，指出电影推荐的目的是找到用户最有可能感兴趣的电影，而不是预测用户看了电影后会给电影什么样的评分。因此，TopN推荐更符合实际的应用需求。也许有一部电影用户看了之后会给很高的分数，但用户看的可能性非常小。因此，预测用户是否会看一部电影， 应该比预测用户看了电影后会给它什么评分更加重要。因此，本书主要也是讨论TopN推荐。 3.覆盖度覆盖度(coverage)描述一个推荐系统对物品长尾的发掘能力。覆盖率有不同的定义方法，最简单的定义为推荐系统能够推荐出来的物品占总物品集合的比例。假设系统的用户集合为$U$，推荐系统给每个用户推荐一个长度为N的物品列表$R(u)$。那么推荐系统的覆盖率可以通过下面的公式计算：$$Coverage=\frac{| \bigcup_{u \in U} R(u)|}{|I|}$$从上面的定义可以看到，覆盖率是一个内容提供商会关心的指标。一个好的推荐系统不仅需要有比较高的用户满意度，也要有较高的覆盖率。但是上面的定义过于粗略。覆盖率为100%的系统可以有无数的物品流行度分布。为了更细致地描述推荐系统发掘长尾的能力，需要统计推荐列表中不同物品出现次数的分布。如果所有的物品都出现在推荐列表中，且出现的次数差不多，那么推荐系统发掘长尾的能力就很好。因此，可以通过研究物品在推荐列表中出现次数的分布描述推荐系统挖掘长尾的能力。如果这个分布比较平，那么说明推荐系统的覆盖率较高，而如果这个分布较陡峭，说明推荐系统的覆盖率较低。在信息论和经济学中有两个著名的指标可以用来定义覆盖率。第一个是信息熵：$$H = -\sum_{i=1}^n p(i) \log p(i)$$这里$p(i)$是物品i的流行度除以所有物品的流行度之和。第二个是基尼系数(Gini Index)：$$G = \frac{1}{n-1} \sum_{j=1}^n (2j-n-1)p(i_j)$$这里$i_j$是按照物品流行度$p()$从小到大排序的物品列表中第j个物品。下面代码用来计算给定物品流行度分布后的基尼系数：1234567def GiniIndex(p): j = 1 n = len(p) G = 0 for item, weight in sorted(p.items(), key=itemgetter(1)): G += (2 * j - n - 1) * weight return G / float(n - 1) 社会学领域有一个著名的马太效应，即所谓强者更强，弱者更弱的效应。推荐系统的初衷是希望消除马太效应，使得各种物品都能被展示给对它们感兴趣的某一类人群。但是，很多研究表明现在主流的推荐算法（比如协同过滤算法）是具有马太效应的。评测推荐系统是否具有马太效应的简单办法就是使用基尼系数。如果G1是从初始用户行为中计算出的物品流行度的基尼系数，G2是从推荐列表中计算出的物品流行度的基尼系数，那么如果G2 &gt; G1，就说明推荐算法具有马太效应。 4.多样性为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域，即推荐结果需要具有多样性。多样性推荐列表的好处用一句俗话表述就是“不在一棵树上吊死”。尽管用户的兴趣在较长的时间跨度中是一样的，但具体到用户访问推荐系统的某一刻，其兴趣往往是单一的，那么如果推荐列表只能覆盖用户的一个兴趣点，而这个兴趣点不是用户这个时刻的兴趣点，推荐列表就不会让用户满意。反之，如果推荐列表比较多样，覆盖了用户绝大多数的兴趣点，那么就会增加用户找到感兴趣物品的概率。因此给用户的推荐列表也需要满足用户广泛的兴趣，即具有多样性。多样性描述了推荐列表中物品两两之间的不相似性。因此，多样性和相似性是对应的。假设$s(i,j) \in [0,1]$定义了物品i和j之间的相似度，那么用户u的推荐列表$R(u)$的多样性定义如下：$$Diversity=1-\frac {\sum_{i,j \in R(u),i \neq j} s(i,j)}{\frac{1}{2}|R(u)|(|R(u)|-1)}$$而推荐系统的整体多样性可以定义为所有用户推荐列表多样性的平均值：$$Diversity=\frac{1}{|U|} \sum_{u \in U}Diversity(R(u))$$从上面的定义可以看到，不同的物品相似度度量函数$s(i, j)$可以定义不同的多样性。如果用内容相似度描述物品间的相似度，我们就可以得到内容多样性函数，如果用协同过滤的相似度函数描述物品间的相似度，就可以得到协同过滤的多样性函数。 5.新颖性新颖的推荐是指给用户推荐那些他们以前没有听说过的物品。在一个网站中实现新颖性的最简单办法是，把那些用户之前在网站中对其有过行为的物品从推荐列表中过滤掉。O’scar Celma在博士论文“Music Recommendation and Discovery in the Long Tail”(参见“Music Recommendation and Discovery in the Long Tail”，地址为http://mtg.upf.edu/static/media/PhD_ocelma.pdf) 中研究了新颖度的评测。评测新颖度的最简单方法是利用推荐结果的平均流行度，因为越不热门的物品越可能让用户觉得新颖。因此，如果推荐结果中物品的平均热门程度较低，那么推荐结果就可能有比较高的新颖性。但是，用推荐结果的平均流行度度量新颖性比较粗略，因为不同用户不知道的东西是不同的。因此，要准确地统计新颖性需要做用户调查。最近几年关于多样性和新颖性的研究越来越受到推荐系统研究人员的关注。ACM的推荐系统会议在2011年有一个专门的研讨会讨论推荐的多样性和新颖性。 (参见“International Workshop on Novelty and Diversity in Recommender Systems”，地址为http://ir.ii.uam.es/divers2011/) 该研讨会的组织者认为，通过牺牲精度来提高多样性和新颖性是很容易的，而困难的是如何在不牺牲精度的情况下提高多样性和新颖性。关心这两个指标的读者可以关注一下这个研讨会最终发表的论文。 6.惊喜度惊喜度（serendipity）是最近这几年推荐系统领域最热门的话题。惊喜度和新颖度作为推荐系统的指标，它们之间的区别并非两个词在中文里含义的区别而是意义上的区别。可以举一个例子说明这两种指标的区别。假设一名用户喜欢周星驰的电影，然后我们给他推荐了一部叫做《临歧》的电影（该电影是1983年由刘德华、周星驰、梁朝伟合作演出的，很少有人知道这部有周星驰出演的电影），而该用户不知道这部电影，那么可以说这个推荐具有新颖性。但是，这个推荐并没有惊喜度，因为该用户一旦了解了这个电影的演员，就不会觉得特别奇怪。但如果我们给用户推荐张艺谋导演的《红高粱》，假设这名用户没有看过这部电影，那么他看完这部电影后可能会觉得很奇怪，因为这部电影和他的兴趣一点关系也没有，但如果用户看完电影后觉得这部电影很不错，那么就可以说这个推荐是让用户惊喜的。这个例子的原始版本来自于Guy Shani的论文(参见Guy Shani和 Asela Gunawardana的“Evaluating Recommendation Systems”) ，他的基本意思就是，如果推荐结果和用户的历史兴趣不相似，但却让用户觉得满意，那么就可以说推荐结果的惊喜度很高，而推荐的新颖性仅仅取决于用户是否听说过这个推荐结果。目前并没有什么公认的惊喜度指标定义方式，这里只给出一种定性的度量方式。上面提到，令用户惊喜的推荐结果是和用户历史上喜欢的物品不相似，但用户却觉得满意的推荐。那么，定义惊喜度需要首先定义推荐结果和用户历史上喜欢的物品的相似度，其次需要定义用户对推荐结果的满意度。前面也曾提到，用户满意度只能通过问卷调查或者在线实验获得，而推荐结果和用户历史上喜欢的物品相似度一般可以用内容相似度定义。也就是说，如果获得了一个用户观看电影的历史，得到这些电影的演员和导演集合A，然后给用户推荐一个不属于集合A的导演和演员创作的电影，而用户表示非常满意，这样就实现了一个惊喜度很高的推荐。因此提高推荐惊喜度需要提高推荐结果的用户满意度，同时降低推荐结果和用户历史兴趣的相似度。惊喜度的问题最近几年获得了学术界的一定关注，但这方面的工作还不是很成熟。相关工作可以参考Yuan Cao Zhang等的论文(参见Yuan Cao Zhang、Diarmuid Ó Séaghdha、Daniele Quercia和 Tamas Jambor的“Auralist: introducing serendipity into music recommendation.”)和Tomoko Murakami等的论文 (参见Tomoko Murakami、 Koichiro. Mori和Ryohei Orihara的“ Metrics for evaluating the serendipity of recommendationlists”)。 7.信任度对于基于机器学习的自动推荐系统，同样存在信任度（trust）的问题，如果用户信任推荐系统，那就会增加用户和推荐系统的交互。度量推荐系统的信任度只能通过问卷调查的方式，询问用户是否信任推荐系统的推荐结果。提高推荐系统的信任度主要有两种方法。首先需要增加推荐系统的透明度(transparency)(参见Henriette Cramer、Vanessa Evers、 Satyan Ramlal、 Maarten van Someren、Lloyd Rutledge、 Natalia Stash、Lora Aroyo和Bob Wielinga的“ The effects of transparency on trust in and acceptance of a content-based art recommender”) ， 而增加推荐系统透明度的主要办法是提供推荐解释。只有让用户了解推荐系统的运行机制，让用 户认同推荐系统的运行机制，才会提高用户对推荐系统的信任度。其次是考虑用户的社交网络 信息，利用用户的好友信息给用户做推荐，并且用好友进行推荐解释。这是因为用户对他们的 好友一般都比较信任，因此如果推荐的商品是好友购买过的，那么他们对推荐结果就会相对比较信任。关于推荐系统信任度的研究(参见Paolo Massa和 Paolo Avesani的“Trust-aware recommender systems”)主要集中在评论网站Epinion的推荐系统上。这是因为Epinion创建了一套用户之间的信任系统来建立用户之间的信任关系，帮助用户判断是否信任当前用户对某一个商品的评论。 8.实时性在很多网站中，因为物品（新闻、微博等）具有很强的时效性，所以需要在物品还具有时效性时就将它们推荐给用户。推荐系统的实时性包括两个方面。首先，推荐系统需要实时地更新推荐列表来满足用户新的行为变化。很多推荐系统都会在离线状态每天计算一次用户推荐列表，然后于在线期间将推荐列表展示给用户。这种设计显然是无法满足实时性的。与用户行为相应的实时性，可以通过推荐列表的变化速率来评测。如果推荐列表在用户有行为后变化不大，或者没有变化，说明推荐系统的实时性不高。实时性的第二个方面是推荐系统需要能够将新加入系统的物品推荐给用户。这主要考验了推荐系统处理物品冷启动的能力。 9.健壮性健壮性（即robust,鲁棒性）指标衡量了一个推荐系统抗击作弊的能力。算法健壮性的评测主要利用模拟攻击。首先，给定一个数据集和一个算法，可以用这个算法给这个数据集中的用户生成推荐列表。然后，用常用的攻击方法向数据集中注入噪声数据，然后利用算法在注入噪声后的数据集上再次给用户生成推荐列表。最后，通过比较攻击前后推荐列表的相似度评测算法的健壮性。如果攻击后的推荐列表相对于攻击前没有发生大的变化，就说明算法比较健壮。在实际系统中，提高系统的健壮性，除了选择健壮性高的算法，还有以下方法。 设计推荐系统时尽量使用代价比较高的用户行为。 在使用数据前，进行攻击检测，从而对数据进行清理。 10.商业目标不同的网站会根据自己的盈利模式设有不同的商业目标。因此，设计推荐系统时需要考虑最终的商业目标，而网站使用推荐系统的目的除了满足用 户发现内容的需求，也需要利用推荐系统加快实现商业上的指标。 11.总结对于可以离线优化的指标，作者的看法是应该在给定覆盖率、多样性、新颖性等限制条件下，尽量优化预测准确度。用一个数学公式表达，离线实验的优化目标是：​ 最大化预测准确度​ 使得 覆盖率 &gt; A​ 多样性 &gt; B​ 新颖性 &gt; C其中，A、B、C的取值应该视不同的应用而定。 1.3.3 评测维度除了应该考虑评测指标，还应考虑评测维度。增加评测维度的目的就是知道一个推荐算法在什么情况下性能最好。这样可以为融合不同推荐算法取得最好的整体性能带来参考。一般情况下，评测维度分为如下3种： 用户维度：主要包括用户的人口统计学信息、活跃度以及是不是新用户等。 物品维度：包括物品的属性信息、流行度、平均分以及是不是新加入的物品等。 时间维度：包括季节，是工作日还是周末，是白天还是晚上等。 如果能够在推荐系统评测报告中包含不同维度下的系统评测指标，就能帮我们全面地了解推荐系统性能，找到一个看上去比较弱的算法的优势，发现一个看上去比较强的算法的缺点。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次顿悟]]></title>
    <url>%2F2018%2F11%2F11%2F%E4%B8%80%E6%AC%A1%E9%A1%BF%E6%82%9F%2F</url>
    <content type="text"><![CDATA[最近一直都在搞怎么让百度收录我的Blog的问题，最后也没有解决，耽误了两三天的时间。为什么Google就能爬取Github Pages，百度就不行呢，忍不住去吐槽(这个事真是烦死我)，对了还有Coding也是个坑。 在解决这个期间也有所思考，并且得到一个顿悟(大喜)，就是人如果想成功就要在高维度上努力而不是低维度。 人的时间都是有限的，并且假设所有人的资质都是相同的(当然是不可能的)，如果能尽可能地节省时间，那么相比其他人就会走得更远。换句话说就是尽可能地让前进的步子迈得更大。说这话什么意思呢?举个例子，如果你高中三年努力考上了清华北大，可能就会比研究生考上清北的人节省出三四年甚至更多的时间。为什么？因为你高中同样花了三年的时间，大学花去了四年时间才和人家只花高中三年的人站在同一高度，有可能还低一些，那么人家是不是比你少花了三四年呢？拿三年换七年血赚啊，谁都明白这个道理。 上升一个层次再去思考这个问题。有的人本科阶段很努力每天都在研究编程，编程技术很厉害，就比如我。但另一些人会去研究论文，刷绩点，准备出国留学。两者的努力程度是一样的，如果两种人的目标是相同的，那么很明显后者到达目标的速度会明显比前者快很多，这就是努力层次的问题。前者是在低维度努力，而后者是在高纬度努力，类似于高处的人比低处的人看得更远。更形象地距举例就是一个人在高抬腿向前跑，而另一个人则是大跨步向前跑。为什么说前者是低维度而后者是高维度呢？因为前者所做的是有一定经验的人都能去做的，虽然短期可能会得到更现实的成就感，但从长远来看后者所做的开创性研究是不可替代的，更牛逼。 令人伤心地是之前的我就是第一种人，而我本科前两年的努力都是高抬腿跑。我已经落后很多了。但凡事都有两面性，好的一方面是现在的我意识到了这点，于是我坚定了我要考研清华的决心，只有这样我才能追回来一些时间。相比那些保研的同学我还有一个优势，就是别无选择，我不会因为目标的不确定而恍惚。 背水一战，向死而生。希望我自己能谨记这次顿悟，会受益匪浅。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中常用的内置函数]]></title>
    <url>%2F2018%2F11%2F09%2FPython%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Python中常用的内置函数Python内置函数(built-in)是随着Python解释器的运行而被创建的。在Python程序中，你可以随时调用这些函数，而且不需要定义。在开发过程中，合理地使用这些内置函数能极大地提升你的开发效率。 这篇文章是对我在开发过程中经常遇到的内置函数的用法总结。 enumerate()函数描述enumerate()函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合成一个索引序列，同时列出数据和数据下标，一般用于for循环中。 语法1enumerate(sequence, [start=0]) 参数 sequence: 一个序列、迭代器或其他可迭代对象。 start: 下标开始位置。 返回值返回enumerate(枚举)对象。 实例12345&gt;&gt;&gt;seasons = ['Spring', 'Summer', 'Fall', 'Winter']&gt;&gt;&gt; list(enumerate(seasons))[(0, 'Spring'), (1, 'Summer'), (2, 'Fall'), (3, 'Winter')]&gt;&gt;&gt; list(enumerate(seasons, start=1)) # 下标从 1 开始[(1, 'Spring'), (2, 'Summer'), (3, 'Fall'), (4, 'Winter')] 普通的for循环123456789&gt;&gt;&gt;i = 0&gt;&gt;&gt; seq = ['one', 'two', 'three']&gt;&gt;&gt; for element in seq:... print i, seq[i]... i +=1... 0 one1 two2 three for循环使用enumerate()1234567&gt;&gt;&gt;seq = ['one', 'two', 'three']&gt;&gt;&gt; for i, element in enumerate(seq):... print i, element... 0 one1 two2 three isinstance()函数描述isinstance()函数用来判断一个对象是否是一个已知类型，类似type()。 isinstance()和type()的区别： type()不会认为子类是一种父类类型，不考虑继承关系； isinstance()会认为子类是一种父类类型，考虑继承关系； 如果要判断两个类型是否相同推荐使用isinstance() 语法1isinstance(object, classinfo) 参数 object: 实例对象; classinfo: 可以直接或间接是类名、基本类型或者由它们组成的元组； 说明： 对于基本类型来说classinfo可以是： 1int, float, bool, complex, str(字符串), list, dict(字典), set, tuple 要注意的是，classinfo的字符串是str而不是string，字典也是简写dict。 实例： 1234arg=123isinstance(arg, int) #输出Trueisinstance(arg, str) #输出Falseisinstance(arg, string) #报错 返回值如果对象的类型与classinfo的类型相同则返回True，否则返回False。 实例1234567&gt;&gt;&gt;a = 2&gt;&gt;&gt; isinstance (a,int)True&gt;&gt;&gt; isinstance (a,str)False&gt;&gt;&gt; isinstance (a,(str,int,list)) # 是元组中的一个返回 TrueTrue type与instance的区别12345678910class A: pass class B(A): pass isinstance(A(), A) # returns Truetype(A()) == A # returns Trueisinstance(B(), A) # returns Truetype(B()) == A # returns False]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中的列表生成式]]></title>
    <url>%2F2018%2F11%2F05%2FPython%E4%B8%AD%E7%9A%84%E5%88%97%E8%A1%A8%E7%94%9F%E6%88%90%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Python中的列表生成式顾名思义，列表生成式就是用来生成列表的特定语法形式的表达式。列表生成式即List Comprehensions，是Python内置的非常简单却强大的可以用来创建list的生成式。 语法格式基础语法格式1[exp for iter_var in iterable] 工作过程 迭代iterable中的每个元素； 每次迭代都先把结果赋值给iter_var，然后通过exp得到一个新的计算值； 最后所有通过exp得到的计算值以一个新的列表的形式返回； 相当于： 123L = []for iter_var in iterable: L.append(exp) 带过滤功能的语法格式1[exp for iter_var in iterable if_exp] 工作过程 迭代iterable中的每个元素，每次迭代都先判断if_exp表达式是否成立，即判断将iter_var代入if_exp后表达式的结果，如果为真则进行下一步，如果为假则进行下一次迭代； 把迭代结果赋值给iter_var，然后通过exp得到一个新的计算值； 最后把所有通过exp得到的计算值以一个新列表的形式返回； 相当于： 1234L = []for iter_var in iterable: if_exp: L.append(exp) 循环嵌套的语法格式1[exp for iter_var_A in iterable_A for iter_var_B in iterable_B] 工作过程 迭代iterable_A中的每个元素，但是每迭代iterable_A中的一个元素，就把iterable_B中的所有元素都迭代一遍； 将每次迭代的变量iterable_var_A和iterable_var_B传入表达式exp(当然可以只传入两者之一)，计算出结果； 最后把所有通过exp得到的结果以一个新的列表的形式返回； 应用场景其实列表生成式是Python中的一种“语法糖”，也就是说列表生成式是Python提供的一种生成列表的简洁形式，应用列表生成式可以快速生成一个新的list。它最主要的应用场景是：根据已存在的可迭代对象推导出一个新的list。 使用实例我们可以对几个生成列表的要求分别通过“不使用列表生成式”和“使用列表生成式”来实现，然后做个对比总结。 实例1：生成一个从3到10的数字列表12345# 不使用列表生成式list1 = list(range(3, 11))# 使用列表生成式list2 = [x for x in range(3, 11)] 实例2：生成一个2n+1的数字列表，n为从3到10的数字1234567# 不使用列表生成式list3 = []for n in range(3, 11): list3.append(2*n + 1) # 使用列表生成式list4 = [2*n + 1 for n in range(3, 11)] 实例3：过滤出指定的数字列表中的值大于20的元素123456789L = [3, 7, 11, 14, 19, 33, 26, 57, 99]# 不使用列表生成式list5 = []for x in L: if x &lt; 20: list5.append(x) # 使用列表生成式list6 = [x for x in L if x &lt; 20] 实例4：计算两个集合的全排列，并将结果保存至一个新的列表中1234567891011L1 = ['香蕉', '苹果', '橙子']L2 = ['可乐', '牛奶']# 不使用列表生成式list7 = []for x in L1: for y in L2: list7.append((x,y)) # 使用列表生成式list8 = [(x,y) for x in L1 for y in L2] 实例5：将一个字典转换成由一组元组组成的列表，元组的格式为(key, value)12345678910D = &#123;'Tom': 15, 'Jerry': 18, 'Peter': 13&#125;# 不使用列表生成式list9 = []for k, v in D.items(): list9.append((k, v)) # 使用列表生成式list10 = []list10 = [(k, v) for k, v in D.items()] 可见，在一些情况下使用列表生成式确实要方便、简洁很多，使用一行代码就搞定了。 列表生成式与map、filter等高阶函数对比列表生成式的功能与之前文章提到的map()和filter()高阶函数功能很像，比如下面两个例子： 实例1：把一个列表中所有的字符串转换为小写，非字符串元素保留原样123456L = ['TOM', 'Peter', 10, 'Jerry']# 用列表生成式实现list1 = [x.lower() if isinstance(x, str) else x for x in L]# 用map()函数实现list2 = list(map(lambda x : x.lower() if isinstance(x, str) else x, L)) 实例2：把一个列表中所有的字符串转换为小写，非字符串元素移除1234567L = ['TOM', 'Peter', 10, 'Jerry']# 用列表生成式实现list3 = [x.lower() for x in L if isinstance(x, str)] # 注意：这里for x in L相对if isinstance的先后位置，与上一个示例相比较# 用map()和filter()函数实现list4 = list(map(lambda x: x.lower(), filter(lambda x: isinstance(x, str), L))) 对于大部分需求来讲，使用列表生成式和使用高阶函数都能实现。但是map和filter等一些高阶函数在Python3.x中的返回值类型变成了Iterator(迭代器)对象，这对于那些元素数量很大或无限的可迭代对象来说显然是更合适的，因为可以避免不必要的内存空间浪费。 引用文章： Python之列表生成式、生成器、可迭代对象与迭代器 - 云游道士 - 博客园 列表生成式 - 廖雪峰的官方网站]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中的装饰器]]></title>
    <url>%2F2018%2F11%2F04%2FPython%E4%B8%AD%E7%9A%84%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Python中的装饰器装饰器本质上是一个Python函数，它可以让其他函数在不需要做任何代码变动的前提下增加额外功能，装饰器的返回值也是一个函数对象。 它经常用于有切面需求的场景，比如：插入日志、性能检测、事务处理、缓存、权限校验等场景。装饰器是解决这类问题的绝佳设计，有了装饰器，我们就可以抽离出大量与函数功能无关的雷同代码并继续重用。概括地讲，装饰器的作用就是为已经存在对象添加额外的功能。 先看一个简单例子： 12def foo(): print('i am foo') 现在有一个新的需求，希望可以记录下函数的执行日志，于是在代码中添加日志代码： 1234import loggingdef foo(): print('i am foo') logging.info("foo is running") 如果有些函数也有类似的需求，怎么做？都写一个logging在函数内？这样就造成了大量雷同的代码，为了减少重复写代码，可以这么做，重新定义一个函数专门处理日志，日志处理完之后再执行真正的业务代码： 123456789101112def use_logging(func): logging.warning("%s is running" % func.__name__) func() def bar(): print('i am bar')use_logging(bar)# output:# WARNING:root:bar is running# i am bar 逻辑上不难理解，但这样的话，我们每次都要将一个函数作为参数传递给use_logging函数。而且这种方式已经破坏了原有的代码逻辑结构，之前执行业务逻辑时，执行运行bar()，但是现在不得不改成use_logging(bar)。那么有没有更好的方式呢？当然有，答案就是装饰器。 简单装饰器123456789101112131415def use_logging(func): def wrapper(*args, **kwargs): logging.warning("%s is running" % func.__name__) return func(*args, **kwargs) return wrapperdef bar(): print('i am bar') bar = use_logging(bar)bar()# output:# WARNING:root:bar is running# i am bar 函数use_logging就是装饰器，它把执行真正业务方法的func包裹在函数里面，看起来像bar被logging包起来，被装饰了。在这个例子中，函数进入和退出时，被称为一个横切面(Aspect)，这种编程方法称为面向切面的编程(Aspect-Oriented Programming)。 @符号是装饰器的语法糖，在定义函数的时候使用，避免再一次赋值操作。 12345678910111213141516171819def use_logging(func): def wrapper(*args, **kwargs): logging.warning("%s is running" % func.__name__) return func(*args) return wrapper@use_loggingdef foo(): print('i am foo') @use_loggingdef bar(): print('i am bar') bar()# output:# WARNING:root:bar is running# i am bar 如上所示，使用@符号我们就可以省去bar = use_logging(bar)这一句了，直接调用bar()即可得到想要的结果。如果我们有其他的类似函数，我们就可以继续调用装饰器来修饰函数，而不用重新修改函数或者增加新的封装。这样，我们就提高了程序的可重复利用性，并增加了程序的可读性。 装饰器在Python中使用如此方便都要归功于Python的函数能像普通的对象一样能作为参数传递给其他函数，可以被赋值给其他的变量，可以作为返回值，可以被定义在另一个函数内。 带参数的装饰器装饰器还有更大的灵活性，例如带参数的装饰器：在上面的装饰器调用中，比如@use_logging，该装饰器唯一的参数就是执行业务的函数。装饰器的语法云溪我们在调用时，提供其他参数比如@decorator(a)。这样，就为装饰器的编写和使用提供了更大的灵活性。 123456789101112131415161718def use_logging(level): def decorator(func): def wrapper(*args, **kwargs): if level == "warn": logging.warning("%s is running" % func.__name__) return func(*args) return wrapper return decorator@use_logging(level="warn")def foo(name='foo'): print("i am %s" % name) foo()# output:# WARNING:root:bar is running# i am bar 上面的use_logging是允许带参数的装饰器。它实际上是对原有装饰器的一个函数封装，并返回一个装饰器。我们可以将它理解为一个含有参数的闭包。当我们使用@use_logging(level=&quot;warn&quot;)调用的时候，Python能够发现这一层的封装，并把参数传递到装饰器的环境中。 类装饰器再来看看类装饰器，相比函数装饰器，类装饰器具有灵活度大，高内聚，封装性等优点。使用类装饰器还可以依赖类内部的__call__方法，当使用@形式将装饰器附加到函数上时，就会调用此方法。 12345678910111213141516171819class Foo(object): def __init__(self, func): self._func = func def __call__(self): print('class decorator running') self._func() print('class decorator ending') @Foodef bar(): print('bar') bar()# output:# class decorator running# bar# class decorator ending functools.wraps使用装饰器极大地复用了代码，但是它有个缺点就是原函数的元信息不见了，比如函数的docstring、__name__、参数列表，先看例子： 装饰器： 12345def logged(func): def with_logging(*args, **kwargs): print(func.__name__ + "was called") return func(*args, **kwargs) return with_logging 函数： 1234@loggeddef f(x): '''do some math''' return x + x * x 该函数完全等价于： 12345def f(x): '''do some math''' return x + x * xf = logged(f) 不难发现，函数f被with_logging替代了，当然它的docstring、__name__就变成了with_logging函数的信息了。 123456print(f.__name__)print(f.__doc__)# output:# with_logging# None 这个问题就比较严重了，好在我们有function.wraps，wraps本身也是一个装饰器，它能把原函数的元信息拷贝到装饰器函数中，这使得装饰器函数也有和原函数一样的元信息了。 12345678910111213141516171819from functools import wrapsdef logged(func): @wraps(func) def with_logging(*args, **kwargs): print(func.__name__ + "was called") return func(*args, **kwargs) return with_logging@loggeddef f(x): '''do some math''' return x + x * xprint(f.__name__)print(f.__doc__)# output:# f# do some math 内置装饰器@staticmethod、@classmethod、@property 装饰器的顺序： 1234@a@b@cdef f(): 等效于 1f = a(b(c(f))) 引用资料： 如何理解Python装饰器？ - 知乎]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中的Lambda函数及其用法]]></title>
    <url>%2F2018%2F11%2F01%2FPython%E4%B8%AD%E7%9A%84Lambda%E5%87%BD%E6%95%B0%E5%8F%8A%E5%85%B6%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Python中的Lambda函数及其用法Lambda函数又称为匿名函数，匿名函数就是没有名字的函数。有些函数如果只是临时一用，而且它的业务逻辑也很简单时，就可以将其定义为匿名函数。 匿名函数有个限制，就是只能有一个表达式，不用写return，返回值就是该表达式的结果。 用匿名函数有个好处，因为函数没有名字，不必担心函数名冲突。此外，匿名函数也是一个函数对象，也可以把匿名函数赋值给一个变量，再利用变量来调用该函数。 先来看个简单的lambda函数： 12&gt;&gt;&gt; lambda x, y : x + y&lt;function &lt;lambda&gt; at 0x102bc1c80&gt; x和y是函数的两个参数，冒号后面的表达式是函数的返回值，很明显这个匿名函数就是在求两个变量的和，但作为一个函数，没有名字如何使用呢？ 这里我们暂且给这个匿名函数绑定一个名字，这样使得我们调用匿名函数成为可能。 12345&gt;&gt;&gt; add = lambda x, y : x+y&gt;&gt;&gt; add&lt;function &lt;lambda&gt; at 0x102bc2140&gt;&gt;&gt;&gt; add(1,2)3 它等同于常规函数 1234567&gt;&gt;&gt; def add1(x, y):... return x+y...&gt;&gt;&gt; add1&lt;function add1 at 0x102bc1c80&gt;&gt;&gt;&gt; add1(1,2)3 lambda函数的使用场景(函数式编程)sorted函数例如：一个整数列表，要求按照列表中元素的绝对值大小升序排列。 123&gt;&gt;&gt; list1 = [3,5,-4,-1,0,-2,-6]&gt;&gt;&gt; sorted(list1, key=lambda x: abs(x))[0, -1, -2, 3, -4, 5, -6] 排序函数sorted支持接收一个函数作为参数，该参数作为sorted的排序依据，这里按照列表元素的绝对值进行排序。 当然，也可以通过普通函数来实现： 12345&gt;&gt;&gt; def foo(x):... return abs(x)...&gt;&gt;&gt; sorted(list1, key=foo)[0, -1, -2, 3, -4, 5, -6] 只不过是使用这种方式，代码看起来不够Pythonic而已。 lambda：这是Python支持的一种有趣的语法，它允许你快速定义单行的最小函数，可以用在任何需要函数的地方: 12345&gt;&gt;&gt; add = lambda x,y : x+y&gt;&gt;&gt; add(5,6)11&gt;&gt;&gt; (lambda x,y:x+y)(5,6)11 map,reduce,filter函数123456789101112# 求1~20的平方&gt;&gt;&gt; list(map(lambda x:x*x,range(1,21))) [1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400]# 求1~20之间的偶数&gt;&gt;&gt; list(filter(lambda x:x%2 == 0,range(1,21))) [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]# 求1~100之和,再加上10000&gt;&gt;&gt; from functools import reduce&gt;&gt;&gt; reduce(lambda x,y:x+y,range(1,101),10000)15050 闭包闭包：一个定义在函数内部的函数，闭包使得变量即使脱离了该函数的作用域也依然能被访问到。 看一个用lambda函数作为闭包的例子： 123456&gt;&gt;&gt; def add(n):... return lambda x:x+n # 将匿名函数作为返回值返回...&gt;&gt;&gt; add2 = add(5)&gt;&gt;&gt; add2(15)20 这里的lambda函数就是一个闭包，在全局作用域范围中，add2(15)可以正常执行且返回值为20。之所以返回20是因为在add局部作用域中，变量n的值在闭包的作用下也可以被访问到。 参考资料 匿名函数 - 廖雪峰的官方网站 深入理解Lambda函数及其用法 - 碧水幽幽泉 - 博客园]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中的高阶函数]]></title>
    <url>%2F2018%2F10%2F29%2FPython%E4%B8%AD%E7%9A%84%E9%AB%98%E9%98%B6%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Python中的高阶函数在熟悉了Python基础知识后，我们已经可以做一些脚本开发，或者简单的程序。然而，当我们开发较为复杂的程序时，仅使用基础知识内容就会显得比较吃力。这时，了解Python中的一些高级特性会使我们的开发过程变得简单和快乐。 在函数式编程中，我们可以将函数当做变量一样自由使用。一个函数接收另一个函数作为参数，这种函数称之为高阶函数(Higher-order-Functions)。 看一个简单的例子： 12def func(g, arr): return [g(x) for x in arr] 上面的代码中func是一个高阶函数，它接收两个参数，第一个参数是函数，第二个参数是数组，func的功能是将函数g逐个作用于数组arr上，并返回一个新的数组。比如，我们可以这样用： 123456789def double(x): return 2 * x def square(x): return x * xlist = [1, 2, 3, 4]arr1 = func(double, list) # arr1 = [2, 4, 6, 8]arr2 = func(square, list) # arr2 = [1, 4, 9, 16] 说到高阶函数，就不得不提到闭包，这里介绍一下Python中闭包的定义： 如果在一个内部函数里，对外部作用域(但不是全局作用域)的变量进行引用，那么内部函数就被认为是闭包(closure)。 就拿此例来说，内部函数double中包含了对函数func中局部变量list的引用，这就是闭包。 map reduce filter sorted是Python中较为常用的内置高阶函数，它们为函数式编程提供了不少便利。 说明：本文介绍的内置高阶函数的定义可能会因为Python版本的不同而有所不同，文章以Python3.x版本中的定义为标准。 mapmap函数的使用形式如下： 1map(function, iterable, ...) 注意：这里函数一定要作为map的第一个参数，而不是第二个参数，否则会产生报错。 解释：function函数会作用于可迭代对象的每一个元素，生成结果，并返回一个迭代器。更加具体一点说就是map函数接收两个参数，一个是函数，一个是Iterable，map将传入的函数依次作用到Iterable的每个元素，并把结果作为新的Iterator返回。 举例说明，比如我们一个函数f(x)=x^2，要把这个函数作用在一个list[1, 2, 3, 4, 5, 6, 7, 8, 9]上，就可以用map()实现。 现在，我们用Python代码实现： 123456&gt;&gt;&gt; def f(x):... return x * x...&gt;&gt;&gt; r = map(f, [1, 2, 3, 4, 5, 6, 7, 8, 9])&gt;&gt;&gt; list(r)[1, 4, 9, 16, 25, 36, 49, 64, 81] map传入的第一个参数是f，即函数对象本身。由于结果r是一个Iterator，Iterator是惰性序列，因此需要通过list()函数让它把整个序列都计算出来并返回一个list。 你可能会想，不需要map函数，写一个循环，也可以计算出结果： 1234L = []for n in [1, 2, 3, 4, 5, 6, 7, 8, 9]: L.append(f(n))print(L) 的确可以，但是，从上面的循环代码，能一眼看明白“把f(x)作用在list的每一个元素并把结果生成一个新的list”吗？明显可读性就差了很多。 所以，map作为高阶函数，体现了Python的设计原则优雅、明确、简单，事实上它把运算规则抽象化。因此，我们不但可以计算简单的f(x)=x2，还可以计算任意复杂的函数，比如，把list中的所有数字转化为字符串格式： 12&gt;&gt;&gt; list(map(str, [1, 2, 3, 4]))['1', '2', '3', '4'] 只需一行代码。 看一些简单的例子： 12345678910111213&gt;&gt;&gt; def square(x):... return x * x&gt;&gt;&gt; map(square, [1, 2, 3, 4])&lt;map at 0x106adfe48&gt;&gt;&gt;&gt; list(map(square, [1, 2, 3, 4]))[1, 4, 9, 16]&gt;&gt;&gt; list(map(lambda x: x * x, [1, 2, 3, 4])) # 使用 lambda[1, 4, 9, 16]&gt;&gt;&gt; list(map(lambda x, y: x + y, [1, 2, 3, 4], [5, 6, 7, 8]))[6, 8, 10, 12] 再来看个复杂一点例子： 1234567891011121314151617def double(x): return 2 * xdef triple(x): return 3 *xdef square(x): return x * xfuncs = [double, triple, square] # 列表元素是函数对象# 相当于 [double(4), triple(4), square(4)]value = list(map(lambda f: f(4), funcs))print(value)output:[8, 12, 16] 最后我想要说明一点，迭代器有一个特点，就是所有的迭代器对象都可以作为next()内置函数的参数调用，每调用一次，就按角标顺序返回一个值，还是用代码讲吧： 123456iter = map(lambda x: x * x, [1, 2, 3, 4])print(next(iter)) # 打印值为：1print(next(iter)) # 打印值为：4print(next(iter)) # 打印值为：9print(next(iter)) # 打印值为：16print(next(iter)) # 抛出StopIteration 异常 reducereduce函数的使用形式如下： 1reduce(function, iterable[, initializer]) 解释：reduce函数必须接受两个参数，先将iterable的前两个item传给function，即function(item1, item2)，函数的返回值和iterable的下一个item再传给function，即function(function(item1, item2), item3)，如此迭代，直到iterable没有元素，如果有initializer，则作为初始值调用。 也就是说： 12reduce(f, [x1, x2, x3, x4]) = f(f(f(x1, x2), x3), x4)# 列表中是以从左到右作为优先顺序 看一些例子，就能很快理解了。 12345678910111213&gt;&gt;&gt; from functools import reduce&gt;&gt;&gt; reduce(lambda x, y: x * y, [1, 2, 3, 4]) # 相当于 ((1 * 2) * 3) * 424&gt;&gt;&gt; reduce(lambda x, y: x - y, [8, 5, 1], 20) # ((20 - 8) - 5) - 16&gt;&gt;&gt; f = lambda a, b: a if (a &gt; b) else b # 两两比较，取最大值&gt;&gt;&gt; reduce(f, [5, 8, 1, 10])10&gt;&gt;&gt; def fn(x, y): # 把序列[1, 3, 5, 7, 9]变换成整数13579... return x * 10 + y...&gt;&gt;&gt; reduce(fn, [1, 3, 5, 7, 9])13579 filterfilter函数用于过滤元素，它的使用形式如下： 1filter(function, iterable) 解释：和map类似，filter也接收一个函数和一个序列。但和map不同的是，filter把传入的函数依次作用于每个元素，然后根据返回值是True还是False决定保留还是丢弃该元素。将function依次作用于iterable的每个item上，即function(item)，用function返回值为True的item构成iterator作为filter的最终返回值。 看一些例子。 12345678910&gt;&gt;&gt; even_num = list(filter(lambda x: x % 2 == 0, [1, 2, 3, 4, 5, 6]))&gt;&gt;&gt; even_num[2, 4, 6]&gt;&gt;&gt; odd_num = list(filter(lambda x: x % 2, [1, 2, 3, 4, 5, 6]))&gt;&gt;&gt; odd_num[1, 3, 5]&gt;&gt;&gt; list(filter(lambda x: x &lt; 'g', 'hijack'))'ac'&gt;&gt;&gt; filter(lambda x: x &lt; 'g', 'hijack')&lt;filter object at 0x1034b4080&gt; # python3 可见用filter这个高阶函数，关键在于正确实现一个“筛选”函数。 注意到filter函数返回的同样是一个Iterator，也就是一个惰性序列，所以要强迫filter完成计算结果，需要用list()函数获得所有结果。 sortedsorted函数用于对list进行排序，它的使用形式如下： 1sorted(iterable, *, key=None, reverse=False) 解释：sorted有两个可选参数，必须指定为关键字参数。将key指定的函数作用于iterable的每一个元素上，并根据key函数返回的结果进行排序，最终返回一个新的排序列表。key默认值为None，即直接比较元素大小。 reverse是一个布尔值。如果设置为True，则列表元素将按照比较结果相反的方式进行排序。 看一些例子： 12345678910&gt;&gt;&gt; sorted([36, 5, -12, 9, -21])[-21, -12, 5, 9, 36]&gt;&gt;&gt; sorted([36, 5, -12, 9, -21], key=abs)[5, 9, -12, -21, 36]&gt;&gt;&gt; sorted(['bob', 'about', 'Zoo', 'Credit'])['Credit', 'Zoo', 'about', 'bob']&gt;&gt;&gt; sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower)['about', 'bob', 'Credit', 'Zoo']&gt;&gt;&gt; sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower, reverse=True)['Zoo', 'Credit', 'bob', 'about'] 从上述例子可以看出，高阶函数的抽象能力是非常强大的，而且核心代码可以保持得非常简洁。 小结 可接受其他函数作为参数的函数称为高阶函数； map reduce filter sorted为函数式编程提供了不少便利，可使代码变得更简洁； 通过map()来对Iterable中的每个元素进行相同的函数处理最终返回一个Iterator。 reduce()类似栈的思想，先让栈顶的两个元素出栈作为函数的两个参数，再将函数的返回值入栈，然后再让栈顶两个元素出栈，不断循环下去，直到栈里没有元素为止。 filter()的作用是从一个序列中筛选出符合条件的元素。由于filter()使用了惰性计算，所以只有在取filter()结果的时候，才会真正筛选并每次返回下一个筛出的元素。 sorted()也是一个高阶函数。用sorted()排序的关键在于实现一个映射函数。 参考资料 高阶函数 - 廖雪峰的官方网站 map/reduce/filter - Python 之旅 - 极客学院Wiki 高阶函数 - Python 之旅 - 极客学院Wiki Python笔记(二)：高级特性之高阶函数 - 简书]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中@classmethod和@staticmethod的区别]]></title>
    <url>%2F2018%2F10%2F27%2FPython%E4%B8%AD%40classmethod%E5%92%8C%40staticmethod%E7%9A%84%E5%8C%BA%E5%88%AB%E7%9A%84%E5%89%AF%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Python中@classmethod和@staticmethod的区别接上一篇介绍Python中@staticmethod和@classmethod的用法的文章。虽然@classmethod和@staticmethod非常相似，但两个修饰符的使用情况仍略有不同。 从它们的使用上来看： @classmethod必须引用一个类对象作为第一个参数，即第一个参数需要是表示自身类的cls参数。同时@classmethod因持有cls参数，所以可以调用类的属性，类的方法，实例化对象等，避免硬编码。 @staticmethod则可以完全没有参数，但在@staticmethod中要调用到这个类的一些属性方法，只能直接类名.属性名或类名.方法名()。 示例1234567891011121314151617181920class Date(object): def __init__(self, day=0, month=0, year=0): self.day = day self.month = month self.year = year @classmethod def from_string(cls, date_as_string): day, month, year = map(int, date_as_string.split("-")) date1 = cls(day, month, year) return date1 @staticmethod def is_date_valid(date_as_string): day, month, year = map(int, date_as_string.split("-")) return day &lt;= 31 and month &lt;= 12 and year &lt;= 3999 date2 = Date.from_string("27-10-2018")is_date = Date.is_date_valid("27-10-2018") 解释让我们假设这样一个类的例子，用来处理日期信息(这将是我们的样板)： 12345class Date(object): def __init__(self, day=0, month=0, year=0): self.day = day self.month = month self.year = year 显然，这个类可以用来存储关于某些日期的信息(没有时区信息；假设所有日期都以UTC表示)。 这个类中有__init__，它是Python类实例的初始化方法，它接收参数作为类实例方法，具有第一个非可选参数self(作为对新创建实例的引用)。 Class Method我们有一些任务，通过使用@classmethod可以很好地完成它们。 假设我们想要创建许多Date类实例，其日期信息来自外部输入(编码格式为’dd-mm-year’的字符串)，并假设我们必须在项目源代码的不同位置执行此操作。 所以我们这里必须做到： 解析输入的字符串以接收日、月、年作为三个整数变量或由这些变量组成的三元组。 通过将上面求到的值传递给初始化调用来创建Date类实例。 代码看起来会是这样： 12day, month, year = map(int, string_date.split('-'))date1 = Date(day, month, year) 如果使用@classmethod修饰符写在类中，将会是： 1234567 @classmethod def from_string(cls, date_as_string): day, month, year = map(int, date_as_string.split('-')) date1 = cls(day, month, year) return date1date2 = Date.from_string('27-10-2018') 让我们更仔细地看看上面的代码实现，并回想一下我们做了什么？ 我们在一个地方实现了日期字符串解析函数，现在它可以重用。 将日期字符串解析函数封装在类中并且工作正常(当然你可以在其他地方实现日期字符串解析作为单个函数，但这个解决方案更适合OOP范例)。 cls是一个保存类本身的对象，而不是类的实例。这很酷😎，因为如果我们继承Date类，所有子类也会定义from_string()。 Static Method@staticmethod确实与@classmethod很相似，但@staticmethod不需要任何强制性参数(如类方法或实例方法)。 让我们看看下一个任务(下一个用例): 假设我们有一个日期字符串，我们想要以某种方式进行验证它是否符合要求的格式。此任务也需要封装在Date类中，但不需要实例化它。 这里使用@staticmethod就会很有效。让我们看一下代码： 1234567@staticmethoddef is_date_valid(date_as_string): day, month, year = map(int, date_as_string.split('-')) return day &lt;= 31 and month &lt;= 12 and year &lt;= 3999# usage:is_date = Date.is_date_valid('27-10-2018') 运行上述代码得到is_date是个boolen型变量，而非is_date_valid函数返回的day，month，year三个整型数据。 因此，我们可以从@staticmethod的使用中看到，我们无法访问类的内容——它基本上只是一个函数，在语法上称为方法，无法访问对象及其内部(字段和其他类方法)。而使用@classmethod却可以做到。 补充上面的文章已经很全面地总结了@classmethod和@staticmethod的区别。在这里我想强调当你创建构造函数时，你应该选择@classmethod而不是@staticmethod的另一个原因。在上面的例子中，使用@classmethod from_string()作为Factory，接收不符合__init__要求的参数创建Date类实例。使用@staticmethod可以完成同样的操作，如下面代码所示： 12345678910111213141516171819202122class Date: def __init__(self, month, day, year): self.month = month self.day = day self.year = year def display(self): return "&#123;0&#125;-&#123;1&#125;-&#123;2&#125;".format(self.month, self.day, self.year) @staticmethod def millenium(month, day): return Date(month, day, 2000)new_year = Date(1, 1, 2013) # Creates a new Date objectmillenium_new_year = Date.millenium(1, 1) # also creates a Date object. # Proof:new_year.display() # "1-1-2013"millenium_new_year.display() # "1-1-2000"isinstance(new_year, Date) # Trueisinstance(millenium_new_year, Date) # True 运行结果显示new_year和millenium_new_year都是Date类实例。 但是，如果仔细观察就会发现，millenium_new_year是以硬编码的方式创建的Date类实例。这意味着即使一个类继承Date类，该子类仍将创建普通的Date对象即父类对象，而不具有该子类本身的任何属性。请参阅以下示例代码： 12345678910111213class DateTime(Date): def display(self): return "&#123;0&#125;-&#123;1&#125;-&#123;2&#125; - 00:00:00PM".format(self.month, self.day, self.year)datetime1 = DateTime(10, 10, 1990)datetime2 = DateTime.millenium(10, 10)isinstance(datetime1, DateTime) # Trueisinstance(datetime2, DateTime) # Falsedatetime1.display() # returns "10-10-1990 - 00:00:00PM"datetime2.display() # returns "10-10-2000" because it's not a DateTime object but a Date object. Check the implementation of the millenium method on the Date class DateTime类继承Date类，因此具有Date类的millenium()方法。datetime2通过调用DateTime继承来的millenium()方法来创建DateTime类实例。然而代码却显示datetime2并不是DateTime类实例(isinstance(datetime2, DateTime) # False)。怎么回事？这是因为使用了@staticmethod修饰符。 在大多数情况下，这是你不希望出现的。如果你想要的是一个”完整“的类实例，并且是通过调用它的父类方法所创建的话，那么@classmethod就是你所需要的。 将Date.millenium()重写为(这是上述代码中唯一改变的部分)： 123@classmethoddef millenium(cls, month, day): return cls(month, day, 2000) 确保该类的创建不是通过硬编码。cls可以是任何子类，生成的对象将正确地成为cls的实例。我们来试试吧： 123456789datetime1 = DateTime(10, 10, 1990)datetime2 = DateTime.millenium(10, 10)isinstance(datetime1, DateTime) # Trueisinstance(datetime2, DateTime) # Truedatetime1.display() # "10-10-1990 - 00:00:00PM"datetime2.display() # "10-10-2000 - 00:00:00PM" 看吧，用@classmethod替代@staticmethod你不希望出现的情况就会消失。使用了@staticmethod修饰符定义构造函数就是问题出现的关键。 文章的内容有点多，可能需要花一些时间进行理解，最后提供一个小示例帮助大家加深记忆一下@classmethod和@staticmethod的主要不同。 1234567891011121314151617181920212223242526class A(object): bar = 1 def foo(self): print 'foo' @staticmethod def static_foo(): print 'static_foo' print A.bar @classmethod def class_foo(cls): print 'class_foo' print cls.bar cls().foo() A.static_foo()A.class_foo()output:static_foo1class_foo1foo 引用文章： 飘逸的python - @staticmethod和@classmethod的作用与区别 - mattkang - CSDN博客 python - Meaning of @classmethod and @staticmethod for beginner? - Stack Overflow]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中@staticmethod和@classmethod的用法]]></title>
    <url>%2F2018%2F10%2F27%2FPython%E4%B8%AD%40staticmethod%E5%92%8C%40classmethod%E7%9A%84%E7%94%A8%E6%B3%95%E7%9A%84%E5%89%AF%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Python中@staticmethod和@classmethod的用法一般来说，调用某个类的方法，需要预先生成一个实例，再通过实例调用方法。Java中有静态方法，可以使用类直接进行调用。Python中提供了两个修饰符@staticmethod和@classmethod以达到类似效果，使用它们就可以不需要实例化，直接类名.方法名()来调用。这有利于组织代码，把某些应该属于某个类的函数给放到那个类中，同时有利于命名空间的整洁。 @staticmethod@staticmethod声明方法为静态方法，直接通过类名.方法名()调用。经过@staticmethod修饰的方法，不需要self参数，其使用方法和直接调用函数一样。 1234567891011121314151617181920#直接定义一个test()函数def test(): print "i am a normal method!" #定义一个类，其中包括一个类方法，采用@staticmethod修饰 class T: @staticmethod def static_test(): # 没有self参数 print "i am a static method!" if __name__ == "__main__": test() T.static_test() T().static_test()output:i am a normal method!i am a static method!i am a static method! @classmethod@classmethod声明方法为类方法，直接通过类名.方法名()调用。经过@classmethod修饰的方法，不需要self参数，但是需要一个标识类本身的cls参数。 12345678910111213class T: @classmethod def class_test(cls): # 必须有cls参数 print "i am a class method" if __name__ == "__main__": T.class_test() T().class_test()output:i am a class methodi am a class method @classmethod另一个实用的用法：在不改变已经写好的类里面的方法的情况下，对输入的数据进行处理。 12345678910111213141516# 输出年月日，正常的情况下class demo1: def __init__(self, year=0, month=0, day=0): self.year = year self.month = month self.day = day def out_date(self): return "year: %d, month: %d, day: %d" % (self.year, self.month, self.day) year = 2018month = 10day = 27demo1 = demo1(year, month, day)print(demo1.out_date()) # year: 2018, month: 10, day: 27 1234567891011121314151617181920212223242526# 如果用户输入的是2018-10-27格式，需要在输出前处理一下，就可以使用classmethod达到想要的效果class demo2: def __init__(self, year=0, month=0, day=0): self.year = year self.month = month self.day = day def out_date(self): return "year: %d, month: %d, day: %d" % (self.year, self.month, self.day) @classmethod def pre_out(cls, date_string): year, month, day = map(int, date_string.split("-")) return cls(year, month, day) date = "2018-10-27"year = 2017month = 7day = 7try: demo2 = demo2.pre_out(date)except: demo2 = demo2(year, month, day) print(demo2.out_date()) # year: 2018, month: 10, day: 6 小结 @staticmethod不需要表示自身对象的self参数和自身类的cls参数，就跟使用函数一样。 @classmethod也不需要self参数，但第一个参数需要是表示自身类的cls参数。 在Python中类和实例都是对象，都占用了内存空间，合理使用@staticmethod和@classmethod修饰符，就可以不经过实例化直接使用类的方法了。 引用文章： Python @staticmethod@classmethod用法 - sinat_34079973的博客 - CSDN博客 飘逸的python - @staticmethod和@classmethod的作用与区别 - mattkang - CSDN博客 classmethod的两个实用用法 - 简书]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中super()函数的用法及其说明]]></title>
    <url>%2F2018%2F10%2F26%2FPython%E4%B8%ADsuper()%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%B3%95%E7%9A%84%E5%89%AF%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Python中super()函数的用法及其说明为了调用父类(超类)的一个方法，可以使用super()函数，比如： 12345678class A: def spam(self): print('A.spam')class B(A): def spam(self): print('B.spam') super().spam() # Call parent spam() super()函数的一个常见用法是在__init__()中确保父类被正确的初始化： 12345678class A: def __init__(self): self.x = 0class B(A): def __init__(self): super().__init__() self.y = 1 说明__init__()函数：定义类的时候，若是添加__init__()函数，那么在创建类的实例的时候，实例会自动调用这个方法，一般用来对实例的属性进行初始化。 super()的另外一个常见用法出现在覆盖Python特殊方法的代码中，比如： 1234567891011121314class Proxy: def __init__(self, obj): self._obj = obj # Delegate attribute lookup to internal obj def __getattr__(self, name): return getattr(self._obj, name) # Delegate attribute assignment def __setattr__(self, name, value): if name.startswith('_'): super().__setattr__(name, value) # Call original __setattr__ else: setattr(self._obj, name, value) 实际上，大家对于在Python中如何正确使用super()函数普遍知之甚少。你有时候会看到像下面这样直接调用父类的一个方法： 12345678class Base: def __init__(self): print('Base.__init__')class A(Base): def __init__(self): Base.__init__(self) print('A.__init__') 尽管对于大部分代码而言这么做没什么问题，但是在更复杂的涉及到多继承的代码中就有可能导致很奇怪的问题发生。比如，考虑下面的情况： 12345678910111213141516171819class Base: def __init__(self): print('Base.__init__')class A(Base): def __init__(self): Base.__init__(self) print('A.__init__')class B(Base): def __init__(self): Base.__init__(self) print('B.__init__')class C(A,B): def __init__(self): A.__init__(self) B.__init__(self) print('C.__init__') 运行这段代码后就会发现Base.__init__被调用两次，如图所示： 123456&gt;&gt;&gt; c = C()Base.__init__A.__init__Base.__init__B.__init__C.__init__ 可能两次调用Base.__init__()没什么坏处，但有时候却不是。另一方面，假设在代码中换成使用super()，结果就很完美了： 123456789101112131415161718class Base: def __init__(self): print('Base.__init__')class A(Base): def __init__(self): super().__init__() print('A.__init__')class B(Base): def __init__(self): super().__init__() print('B.__init__')class C(A,B): def __init__(self): super().__init__() # Only one call to super() here print('C.__init__') 运行这个新版本后，你会发现Base.__init__()方法只会被调用一次： 12345&gt;&gt;&gt; c = C()Base.__init__B.__init__A.__init__C.__init__ 所以说，super()是用来解决多重继承问题的，直接用类名调用父类方法在使用单继承的时候没问题，但是如果使用多继承，会涉及到查找顺序(MRO)、重复调用(钻石继承)等种种问题。 说明：MRO就是类的方法解析顺序表，其实也就是继承父类方法时的顺序表，下面会有更详尽的介绍。 为了弄清它的原理，我们需要花点时间解释下Python是如何实现继承的。对于你定义的每一个类，Python会计算出一个所谓的方法解析顺序(MRO)列表。这个MRO列表就是一个简单的所有基类的线性顺序表。例如： 123&gt;&gt;&gt; C.__mro__(&lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;class '__main__.B'&gt;,&lt;class '__main__.Base'&gt;, &lt;class 'object'&gt;) 为了实现继承，Python会在MRO列表上从左到右开始查找基类，直到找到第一个匹配这个属性的类为止。 而这个MRO列表的构造是通过一个C3线性化算法来实现的。我们不去深究这个算法的数学原理，它实际上就是合并所有父类的MRO列表并遵循如下三条准则： 子类会先于父类被检查 多个父类会根据它们在列表中的顺序被检查 如果对下一个类存在两个合法的选择，选择第一个父类 老实说，你所要知道的就是MRO列表中的类顺序会让你定义的任意类层级关系变得有意义。 当你使用super()函数时，Python会在MRO列表上继续搜索下一个类。只要每个重定义的方法统一使用super()并只调用它一次，那么控制流最终会遍历完整个MRO列表，每个方法也只会被调用一次。这也是为什么在第二个例子中你不会调用两次Base.__init__()的原因。 super()有个令人吃惊的地方是它并不一定去查找某个类在MRO中下一个直接父类，你甚至可以在一个没有直接父类的类中使用它。例如，考虑如下这个类： 1234class A: def spam(self): print('A.spam') super().spam() 如果你试着直接使用这个类就会出错： 1234567&gt;&gt;&gt; a = A()&gt;&gt;&gt; a.spam()A.spamTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 4, in spamAttributeError: 'super' object has no attribute 'spam' 但是，如果你使用多继承的话看看会发生什么： 1234567891011&gt;&gt;&gt; class B:... def spam(self):... print('B.spam')...&gt;&gt;&gt; class C(A,B):... pass...&gt;&gt;&gt; c = C()&gt;&gt;&gt; c.spam()A.spamB.spam 你可以看到在类A中使用super().spam()实际上调用的是与类A毫无关系的类B中的spam()方法。这个用类C的MRO列表就可以完全解释清楚： 123&gt;&gt;&gt; C.__mro__(&lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;class '__main__.B'&gt;,&lt;class 'object'&gt;) 在定义混入类的时候这样使用super()是很普遍的。 然而，由于super()可能会调用不是你想要的方法，你应该遵循一些通用原则。首先，确保在继承体系中所有相同名字的方法拥有可兼容的参数签名(比如相同的参数个数和参数名称)。这样可以确保super()调用一个非直接父类方法时不会出错。其次，最好确保最顶层的类提供了这个方法的实现，这样的话在MRO上面的查找链肯定可以找到某个确定的方法。 在Python社区内对于super()的使用有时候会引来一些争议。尽管如此，如果一切顺利的话，你应该在你最新的代码中使用它。Raymond Hettinger为此写了一篇非常好的文章，有兴趣的话可以去查查看，文章通过大量的例子向我们解释了为什么super()是极好的。 最后通过一个很好的实例帮助大家加深一下记忆： 12345678910111213141516171819202122class FooParent(object): def __init__(self): self.parent = 'I\'m the parent.' print ('Parent') def bar(self,message): print ("%s from Parent" % message) class FooChild(FooParent): def __init__(self): # super(FooChild,self) 首先找到 FooChild 的父类（就是类 FooParent），然后把类B的对象 FooChild 转换为类 FooParent 的对象 super(FooChild,self).__init__() print ('Child') def bar(self,message): super(FooChild, self).bar(message) print ('Child bar fuction') print (self.parent) if __name__ == '__main__': fooChild = FooChild() fooChild.bar('HelloWorld') 执行结果： 12345ParentChildHelloWorld from ParentChild bar fuctionI&apos;m the parent. 引用文章： Python super() 函数 | 菜鸟教程 8.7 调用父类方法 — python3-cookbook 3.0.0 文档]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo使用攻略：添加搜索功能]]></title>
    <url>%2F2018%2F10%2F26%2FHexo%E4%BD%BF%E7%94%A8%E6%94%BB%E7%95%A5%EF%BC%9A%E6%B7%BB%E5%8A%A0%E6%90%9C%E7%B4%A2%E5%8A%9F%E8%83%BD%E7%9A%84%E5%89%AF%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Hexo使用攻略：添加搜索功能本教程针对的是Mac环境 前言当博文越来越多的时候，标签和分类已经不能提供太大的作用，无法准确的定位到自己想要看的博文上去了，所以添加一个站内搜索功能是很有必要的。 Hexo适配多款搜索插件，个人感觉”Local Search”已满足日常需要，所以下面介绍为Hexo添加”Local Search”搜索插件的过程。 安装插件在命令行中cd到自己的hexo文件夹下(例：/Users/rilzob/hexo)，执行npm install hexo-generator-searchdb --save命令进行安装，等待安装完成。 修改站点配置文件修改当前目录下的_config.yml文件(例：/Users/rilzob/hexo/_config.yml)，新增以下内容到该文件内的任意位置。 123456# Searchsearch: path: search.xml field: post format: html limit: 10000 注意：每个冒号后面都有空格 修改主题配置文件修改主题目录下的_config.yml文件(例：/Users/rilzob/hexo/themes/xxx/_config.yml)，找到该文件内的 1234# Local search# Dependencies: https://github.com/flashlab/hexo-generator-searchlocal_search: enable: false 代码段，将其修改为： 1234# Local search# Dependencies: https://github.com/flashlab/hexo-generator-searchlocal_search: enable: true 即将enable: false修改为enable: true。 重新部署依旧在命令行中进行操作，在hexo文件夹下依次执行hexo g,hexo server和hexo deploy指令即可。这样搜索功能就添加成功了。 引用文章: 1.Hexo博客添加搜索功能 | IT范儿 2.hexo博客添加搜索功能 - qq_40265501的博客 - CSDN博客]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hexo使用攻略：添加分类及标签]]></title>
    <url>%2F2018%2F10%2F25%2FHexo%E4%BD%BF%E7%94%A8%E6%94%BB%E7%95%A5%EF%BC%9A%E6%B7%BB%E5%8A%A0%E5%88%86%E7%B1%BB%E5%8F%8A%E6%A0%87%E7%AD%BE%E7%9A%84%E5%89%AF%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Hexo使用攻略：添加分类及标签本教程针对的是Mac环境 Hexo创建”分类”选项生成”分类”页并添加type属性 打开命令行，cd进入博客所在文件夹。执行命令hexo new page categories，来新建一个页面，并命名为categories。成功后会提示：INFO Created: ~/hexo/source/categories/index.md 根据上面的路径找到index.md这个文件，打开后默认内容如下： 1234---title: categoriesdate: 2018-10-25 20:11:37--- 编辑新创建的页面，添加type: &quot;categories&quot;到内容中(注意，这些属性和属性值之间必须有一个空格)，主题将自动为这个页面显示所有分类，添加后是这样的： 12345---title: categoriesdate: 2018-10-25 20:11:37type: &quot;categories&quot;--- 保存并关闭文件。 给文章添加”categories”属性 打开需要添加分类的文章，为其添加categories属性。下方的categories: Python表示添加这篇文章到“Python”这个分类中。 注意：Hexo中一篇文章只能属于一个分类，也就是说如果在”Python”下方添加”-xxx”，Hexo不会产生两个分类，而是把分类嵌套，即该文章属于”Python“下的”-xxx“分类。 1234---title: Python中*args和**kwargs的用法总结categories: Python--- 回到hexo文件夹下，依次执行hexo g，hexo server和hexo deploy命令(重新部署)。 在Hexo菜单上添加分类选项 cd进/hexo/themes/hexo-theme-next-5.1.4文件夹内，编辑该目录下的_config.yml文件(把链接加上)，将源代码: 12345678910111213menu: home: / || home #about: /about/ || user #tags: /tags/ || tags #categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat# Enable/Disable menu icons.menu_icons: enable: true 改为: 12345678910111213menu: home: / || home #about: /about/ || user #tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat# Enable/Disable menu icons.menu_icons: enable: true 即将menu中的categories:/categories || th的注释去掉，然后保存并退出。 回到hexo文件夹下，依次执行hexo g，hexo server和hexo deploy命令，即可看到菜单栏中新增了一个Categories选项。 至此，成功给文章添加分类，点击Index上的Categories可以看到所有的分类情况，再点击该分类就可以看到该分类下的所有文章。当然，前提是添加了categories: xxx字段。 Hexo创建”标签”选项生成”标签”页并添加type属性 打开命令行，cd进入博客所在文件夹。执行命令hexo new page tags，来新建一个页面，并命名为tags。成功后会提示：INFO Created: ~/hexo/source/tags/index.md 根据上面的路径找到index.md这个文件，打开后默认内容如下： 1234---title: tagsdate: 2018-10-25 21:11:00--- 编辑新创建的页面，添加type: &quot;tags&quot;到内容中，主题将自动为这个页面显示所有分类，添加后是这样的： 12345---title: tagsdate: 2018-10-25 21:11:00type: &quot;tags&quot;--- 保存并关闭文件。 给文章添加”tags”属性 打开需要添加标签的文章，为其添加tags属性。下方的tags: Django表示添加这篇文章到“Django”这个标签中。 1234---title: Python中*args和**kwargs的用法总结tags: Django--- 回到hexo文件夹下，依次执行hexo g， hexo server和hexo deploy命令(重新部署)。 在Hexo菜单上添加标签选项 cd进/hexo/themes/hexo-theme-next-5.1.4文件夹内，编辑该目录下的_config.yml文件(把链接加上)，将源代码: 12345678910111213menu: home: / || home #about: /about/ || user #tags: /tags/ || tags #categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat# Enable/Disable menu icons.menu_icons: enable: true 改为: 12345678910111213menu: home: / || home #about: /about/ || user tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat# Enable/Disable menu icons.menu_icons: enable: true 即将menu中的tags: /tags/ || tags的注释去掉，然后保存并退出。 回到hexo文件夹下，依次执行hexo g，hexo server和hexo deploy命令，即可看到菜单栏中新增了一个tags选项。 引用文章： 1.Hexo使用攻略-添加分类及标签 | linlif-blog 2.hexo怎么在菜单上添加页面和分类呢？ - SegmentFault 思否 3.hexo next 为文章添加分类 | 学而后知不足]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Python中*args和**kwargs的用法总结]]></title>
    <url>%2F2018%2F10%2F25%2FPython%E4%B8%AD*args%E5%92%8C**kwargs%E7%9A%84%E7%94%A8%E6%B3%95%E6%80%BB%E7%BB%93%E7%9A%84%E5%89%AF%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Python中*args和**kwargs的用法总结一、基本概念Python支持可变参数，最简单的方法莫过于使用默认参数。 123456789101112131415def test_defargs(one, two=2): # 参数one没有默认值，two的默认值为2 print('Required argument:', one) print('Optional argument:', two) test_defargs(1)'''Required argument: 1Optional argument: 2'''test_defargs(1, 3)'''Required argument: 1Optional argument: 3''' 另一种达到可变参数(Variable Argument)的方法： 使用*args和**kwargs语法。 *args是可变的位置参数(postional arguments)列表； **kwargs是可变的关键词参数(keyword arguments)列表； 并且规定位置参数必须位于关键词参数之前，即*args必须位于**kwargs之前。 二、位置参数以下是用位置参数正确调用函数的实例： 12345678910def print_hello(name, sex): sex_dict = &#123;1: '先生', 2: '女士'&#125; print('Hello %s %s, welcome to Python World!' % (name, sex_dict.get(sex, '先生'))) # if no such a key, print '先生' print_hello('Chen', 2) # 位置参数要求先后顺序，对应name和sexprint_hello('Chen', 3) # 两个参数的顺序必须一一对应，且少一个参数都不可以'''Hello Chen 女士, welcome to Python World!Hello Chen 先生, welcome to Python World!''' 三、关键字参数用于函数调用，通过“键-值”形式加以指定。 使用关键字参数可以让函数更加清晰，容易使用，同时也清除了参数的顺序需求。 以下是用关键字参数正确调用函数的实例： 123print_hello('Chen', sex=1) # 有位置参数时，位置参数必须在关键字参数的前面# print_hello(1, name='Chen') # Python 3.x中这种写法是错误的print_hello(name='Chen', sex=1) # 关键字参数之间不存在先后顺序的,等价于print_hello(sex=1, name='Chen') 以下是错误的调用方式： 12# print_hello(name='Chen', 1) # 有位置参数时，位置参数必须在关键字参数前面# print_hello(sex=1, 'Chen') 四、可变参数顾名思义，可变参数就是传入的参数个数是可变的，可以是任意个。*args和**kwargs两者都是Python中的可变参数。 1.可变位置参数*argsPython中规定参数前带*的，称为可变位置参数，只是我们通常称这个可变位置参数为*args而已，叫其他的也是一样的。 以数学题为例，给定一组数字a，b，c……，请计算a^2 + b^2 + c^2 + ……。 要定义这个函数，必须确定输入的参数。由于参数个数不确定，我们可以首先想到把a，b，c……作为一个list或者tuple传进来，这样函数就可以定义为： 12345def calc(numbers): sum = 0 for n in numbers: sum = sum + n * n return sum 但是调用的时候，需要先组装出一个list或tuple： 1234&gt;&gt;&gt; calc([1, 2, 3])14&gt;&gt;&gt; calc([1, 3, 5, 7])84 所以，为了方便起见我们把函数的参数改为可变位置函数： 12345def calc(*numbers) # 可变位置参数 sum = 0 for n in numbers: sum = sum + n * n return sum 定义可变位置参数和定义一个list或tuple参数相比，仅仅在参数前面加了一个*号。在函数内部，参数numbers接收到的是一个tuple，因此函数代码完全不变。但是，调用该函数时，可以传入任意个参数，包括0个参数： 1234&gt;&gt;&gt;calc(1,2)5&gt;&gt;&gt;calc()0 如果已经有一个list或tuple，要调用一个可变位置参数怎么办？可以这么做： 123&gt;&gt;&gt;nums = [1, 2, 3]&gt;&gt;&gt;calc(nums[0], nums[1], nums[2])14 这种做法当然是可行的，问题是太繁琐了，所以Python允许在list或tuple前面加一个*，把list或tuple的元素变成可变位置参数传进去： 123&gt;&gt;&gt;nums = [1, 2, 3]&gt;&gt;&gt;calc(*nums)14 总而言之，*args用来表示函数接收可变长度的非关键字参数列表作为函数的输入。我们可以通过以下这个例子进一步理解*args: 123456def test_args(normal_arg, *args): print('first normal arg:' + normal_arg) for arg in args: print('another arg through *args:' + arg) test_args("normal", "python", "java", "C#") 上面代码的执行结果如下： 1234first normal arg: normalanother arg through *args : pythonanother arg through *args : javaanother arg through *args :C# 2.可变关键字参数**kwargs同理，Python中规定参数前带 的，称为可变关键字参数，通常用kwargs表示。 **kwargs表示函数接收可变长度的关键字参数字典作为函数的输入。当我们需要函数接收带关键字的参数作为输入的时候，应当使用**kwargs。我们可以通过以下的例子进一步理解**kwargs: 123456789def test_kwargs(**kwargs): if kwargs is not None: for key, value in kwargs.iteritems(): print("&#123;&#125; = &#123;&#125;".format(key,value)) # Or you can visit kwargs like a dict() object # for key in kwargs: # print("&#123;&#125; = &#123;&#125;".format(key, kwargs[key])) test_kwargs(name="python", value="5") 以上代码的执行效果如下： 12name = pythonvalue = 5 以上例子只是*args和**kwargs基本使用的例子。下面再给出一个用*args和**kwargs来定义能够接受列表输入和字典输入的函数的例子。 3.使用*args和**kwargs来调用函数比如我们有如下接受普通输入参数的函数： 123456def normal_func(arg1, arg2, arg3): print("arg1: " + arg1) print("arg2: " + arg2) print("arg3: " + arg3)normal_func("python", 1, 3) 使用*args和**kwargs来调用这个函数的代码如下： 1234567# 使用*argsargs_list = ("python", 1, 3)normal_func(*args_list)# 使用**kwargskwargs_dict = &#123;"arg3": 3, "arg1": "python", "arg2": 1&#125;normal_func(**kwargs_dict) 以上三段代码的输出均为： 123arg1: pythonarg2: 1arg3: 3 引用文章： 1.Python中的 *args 和 **kwargs - 简书 2.函数的参数 - 廖雪峰的官方网站 3.python参数传递的*args和**kwargs - 简书]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[通过Hexo将文章上传到git.io的方法]]></title>
    <url>%2F2018%2F10%2F21%2F%E9%80%9A%E8%BF%87Hexo%E5%B0%86%E6%96%87%E7%AB%A0%E4%B8%8A%E4%BC%A0%E5%88%B0git.io%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[通过Hexo将文章上传到git.io的方法 编辑文章，生成markdown文件，并将文章放到/hexo/source/_posts目录下，一个md文件对应一篇博客文章。 修改文章头部： 123456---title: #博客标题date: #博客发布时间tags: #博客分类标签categories: #博客目录--- 在命令行中cd到_posts目录下并执行hexo generate命令(生成静态页面)。 再执行hexo server命令(本地上传文章)，上传后可以到http://localhost:4000/ 预览博客效果。 最后执行hexo deploy命令，上传文章到github.io上就完成了。 其他Hexo命令： hexo clean（清空资源文件，可选操作） hexo g （重新生成资源文件） 引用文章: 1.Hexo 发布文章到git.io步骤 - 程序男的专栏 - CSDN博客 2.hexo发布文章到个人博客上 - wl67920126的博客 - CSDN博客]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Django中path和url的区别]]></title>
    <url>%2F2018%2F10%2F21%2FDjango%E4%B8%ADpath%E5%92%8Curl%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[Django中path和url的区别django中url和path都是配置路径，有什么不同？ from django.urls import path from django.conf.urls import url path和url是两个不同的模块，效果都是响应返回界面，path调用的是python第三方模块或框架，而url则是自定义的模块。 例如： 1234url(r'^login', views.login)def login(request): return render(request, 'login.html') 引用自：Django中path和url的用法总结 当然，主要问题在于版本，1.x版本用url，2.x版本用path。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[介绍]]></title>
    <url>%2F2018%2F04%2F25%2F%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[Rilzob的个人blog随便写，随便看 邮箱： watermirrosir@163.com]]></content>
  </entry>
</search>
